{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61666521",
   "metadata": {},
   "source": [
    "# `RankingPipeline`\n",
    "\n",
    "Dans ce script on teste la pipeline complète, permettant de paramétrer les méthodes de calcul des scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b395c80f",
   "metadata": {},
   "source": [
    "## Calcul des scores\n",
    "\n",
    "La méthode `run` lance le calcul des scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3074abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rank_comparia.pipeline import RankingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fceda6d",
   "metadata": {},
   "source": [
    "### Paramètres de `RankingPipeline`  \n",
    "\n",
    "- `method` : Méthode de classement utilisé : `elo_random`, `elo_ordered`, `ml`  \n",
    "- `include_votes` : Utilisation des données de votes  \n",
    "- `include_reactions` : Utilisation des données de réactions\n",
    "- `bootstrap_samples` : Nombres d'échantillons pour cacluler la version *Bootstrap* \n",
    "- `mean_how` : Moyenner par nombre de token générés ou par matchs effectués\n",
    "- `export_path` : le chemin vers le dossier dans lequel exporter les graphes et les scores finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af6e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/3a81e160fed75a8dccf44e59cb8a74c13b981a86 (last modified on Tue Sep 30 13:43:04 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/5a02c58f54f2db3fc51f076d24a840f04efa01fa (last modified on Tue Sep 30 13:43:20 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\",\n",
    "    include_votes=True,\n",
    "    include_reactions=True,\n",
    "    bootstrap_samples=5,\n",
    "    mean_how=\"token\",\n",
    "    export_path=Path(\"output\"),\n",
    "    token=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0e8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (76_861, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>conversation_pair_id</th><th>model_a</th><th>model_b</th><th>score</th><th>categories</th><th>model_a_active_params</th><th>model_b_active_params</th><th>total_conv_a_output_tokens</th><th>total_conv_a_kwh</th><th>total_conv_b_output_tokens</th><th>total_conv_b_kwh</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i32</td><td>list[str]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;44b0a0623402407e824406140bc686…</td><td>&quot;llama-3.1-8b&quot;</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>0</td><td>[&quot;Education&quot;, &quot;Culture &amp; Cultural geography&quot;, &quot;Arts&quot;]</td><td>8.0</td><td>35.0</td><td>2424.0</td><td>0.009133</td><td>1886.0</td><td>0.014252</td></tr><tr><td>&quot;b5852aa5c731485da6f6c4c97f7669…</td><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;, &quot;Daily Life &amp; Home &amp; Lifestyle&quot;]</td><td>200.0</td><td>44.0</td><td>353.0</td><td>0.021683</td><td>358.0</td><td>0.006315</td></tr><tr><td>&quot;72f2286fa3864291acb2765d7862af…</td><td>&quot;command-a&quot;</td><td>&quot;gemma-3-4b&quot;</td><td>1</td><td>[&quot;Business &amp; Economics &amp; Finance&quot;, &quot;Personal Development &amp; Human Resources &amp; Career&quot;, &quot;Food &amp; Drink &amp; Cooking&quot;]</td><td>111.0</td><td>4.0</td><td>5411.0</td><td>0.098602</td><td>5988.0</td><td>0.019201</td></tr><tr><td>&quot;ece864f089ba4a5a8f85354fa13199…</td><td>&quot;llama-3.3-70b&quot;</td><td>&quot;gpt-4.1-mini&quot;</td><td>0</td><td>[&quot;Education&quot;, &quot;Arts&quot;, &quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>70.0</td><td>70.0</td><td>3200.0</td><td>0.0399</td><td>2977.0</td><td>0.037119</td></tr><tr><td>&quot;f1c36cbc53e14a42a622481986c66c…</td><td>&quot;mistral-nemo-2407&quot;</td><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>0</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>12.0</td><td>32.0</td><td>484.0</td><td>0.002095</td><td>763.0</td><td>0.005445</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;e5a4c85a170d4fdd93c46cb24cf951…</td><td>&quot;o4-mini&quot;</td><td>&quot;deepseek-v3-0324&quot;</td><td>1</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>200.0</td><td>37.0</td><td>824.0</td><td>0.0506142</td><td>1075.0</td><td>0.050553</td></tr><tr><td>&quot;f38b7491b3544ae199194a588d64ae…</td><td>&quot;llama-3.1-8b&quot;</td><td>&quot;gemma-2-27b-it-q8&quot;</td><td>2</td><td>[&quot;Education&quot;, &quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>8.0</td><td>27.0</td><td>248.0</td><td>0.000934</td><td>5.0</td><td>0.000032</td></tr><tr><td>&quot;45122dc4707a415e937f8195011fda…</td><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>0</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>44.0</td><td>35.0</td><td>484.0</td><td>0.008538</td><td>983.0</td><td>0.007428</td></tr><tr><td>&quot;30f80489e9424a439de77b26c6a73d…</td><td>&quot;mistral-large-2411&quot;</td><td>&quot;lfm-40b&quot;</td><td>0</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>123.0</td><td>40.0</td><td>461.0</td><td>0.009177</td><td>31.0</td><td>0.000256</td></tr><tr><td>&quot;30e1173c41884a068a5d322621a8c3…</td><td>&quot;ministral-8b-instruct-2410&quot;</td><td>&quot;mistral-nemo-2407&quot;</td><td>2</td><td>[&quot;Education&quot;]</td><td>8.0</td><td>12.0</td><td>507.0</td><td>0.00191</td><td>271.0</td><td>0.001173</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (76_861, 11)\n",
       "┌────────────┬────────────┬────────────┬───────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ conversati ┆ model_a    ┆ model_b    ┆ score ┆ … ┆ total_con ┆ total_con ┆ total_con ┆ total_con │\n",
       "│ on_pair_id ┆ ---        ┆ ---        ┆ ---   ┆   ┆ v_a_outpu ┆ v_a_kwh   ┆ v_b_outpu ┆ v_b_kwh   │\n",
       "│ ---        ┆ str        ┆ str        ┆ i32   ┆   ┆ t_tokens  ┆ ---       ┆ t_tokens  ┆ ---       │\n",
       "│ str        ┆            ┆            ┆       ┆   ┆ ---       ┆ f64       ┆ ---       ┆ f64       │\n",
       "│            ┆            ┆            ┆       ┆   ┆ f64       ┆           ┆ f64       ┆           │\n",
       "╞════════════╪════════════╪════════════╪═══════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 44b0a06234 ┆ llama-3.1- ┆ gpt-4o-min ┆ 0     ┆ … ┆ 2424.0    ┆ 0.009133  ┆ 1886.0    ┆ 0.014252  │\n",
       "│ 02407e8244 ┆ 8b         ┆ i-2024-07- ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 06140bc686 ┆            ┆ 18         ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ b5852aa5c7 ┆ gpt-4o-202 ┆ mixtral-8x ┆ 1     ┆ … ┆ 353.0     ┆ 0.021683  ┆ 358.0     ┆ 0.006315  │\n",
       "│ 31485da6f6 ┆ 4-08-06    ┆ 22b-instru ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ c4c97f7669 ┆            ┆ ct-v0.1    ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 72f2286fa3 ┆ command-a  ┆ gemma-3-4b ┆ 1     ┆ … ┆ 5411.0    ┆ 0.098602  ┆ 5988.0    ┆ 0.019201  │\n",
       "│ 864291acb2 ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 765d7862af ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ece864f089 ┆ llama-3.3- ┆ gpt-4.1-mi ┆ 0     ┆ … ┆ 3200.0    ┆ 0.0399    ┆ 2977.0    ┆ 0.037119  │\n",
       "│ ba4a5a8f85 ┆ 70b        ┆ ni         ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 354fa13199 ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ f1c36cbc53 ┆ mistral-ne ┆ qwen2.5-co ┆ 0     ┆ … ┆ 484.0     ┆ 0.002095  ┆ 763.0     ┆ 0.005445  │\n",
       "│ e14a42a622 ┆ mo-2407    ┆ der-32b-in ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 481986c66c ┆            ┆ struct     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …     ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ e5a4c85a17 ┆ o4-mini    ┆ deepseek-v ┆ 1     ┆ … ┆ 824.0     ┆ 0.0506142 ┆ 1075.0    ┆ 0.050553  │\n",
       "│ 0d4fdd93c4 ┆            ┆ 3-0324     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 6cb24cf951 ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ f38b7491b3 ┆ llama-3.1- ┆ gemma-2-27 ┆ 2     ┆ … ┆ 248.0     ┆ 0.000934  ┆ 5.0       ┆ 0.000032  │\n",
       "│ 544ae19919 ┆ 8b         ┆ b-it-q8    ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 4a588d64ae ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 45122dc470 ┆ mixtral-8x ┆ gpt-4o-min ┆ 0     ┆ … ┆ 484.0     ┆ 0.008538  ┆ 983.0     ┆ 0.007428  │\n",
       "│ 7a415e937f ┆ 22b-instru ┆ i-2024-07- ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 8195011fda ┆ ct-v0.1    ┆ 18         ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 30f80489e9 ┆ mistral-la ┆ lfm-40b    ┆ 0     ┆ … ┆ 461.0     ┆ 0.009177  ┆ 31.0      ┆ 0.000256  │\n",
       "│ 424a439de7 ┆ rge-2411   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 7b26c6a73d ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 30e1173c41 ┆ ministral- ┆ mistral-ne ┆ 2     ┆ … ┆ 507.0     ┆ 0.00191   ┆ 271.0     ┆ 0.001173  │\n",
       "│ 884a068a5d ┆ 8b-instruc ┆ mo-2407    ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 322621a8c3 ┆ t-2410     ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴───────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d10db3",
   "metadata": {},
   "source": [
    "## Match_list()\n",
    "\n",
    "Cette fonction permet de construire la liste des matchs effectués dans l'arène. Chaque élément de la liste correspond à un match joué avec :\n",
    "- les deux modèles qui ont joué le match\n",
    "- l'issue du match : 0 si c'eslt modèle B qui gagne, 2 si c'est le modèle A qui gagne et 1 s'il y a égalité.\n",
    "- l'id de la conversation du match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e05ab48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match(model_a='llama-3.1-8b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='44b0a0623402407e824406140bc6862d-b1afa3a933a44474830f06aca0722980'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='b5852aa5c731485da6f6c4c97f76698b-bf3ab5e53d4c413c80cbc0156ad338d9'),\n",
       " Match(model_a='command-a', model_b='gemma-3-4b', score=<MatchScore.Draw: 1>, id='72f2286fa3864291acb2765d7862af5e-19e4bbebfced48e9ada080c6c3fb8b7a'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='ece864f089ba4a5a8f85354fa131996b-5bfb680f448d4de19b99c726a4062839'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='f1c36cbc53e14a42a622481986c66cf7-c7308f4b376b42d8b046836215de3250'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='157012f873ae435cb799aff73f9ff9c3-fcf2b33eeb0d41ccbd13ee09a3ecd71d'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='phi-4', score=<MatchScore.B: 0>, id='bd811067dc6a474e9855f74d16f1d5b1-29eaa9e4f13a42948ea31c80cbdeb51b'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='1bf1304c2da1429cbbaf2efe0581187e-ddaa856c6f4a4d6eb3767c3d0c18c78c'),\n",
       " Match(model_a='gemma-3-27b', model_b='command-a', score=<MatchScore.Draw: 1>, id='b472ca770fb34ece8baf63a6891b1c99-b7ceca49dc9a407eb1fbd70692bdaccd'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='e3a810bfd64143209e5a666cc87c24b7-90e9705355d24f7786a0fee074c24a04'),\n",
       " Match(model_a='llama-3.1-70b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='570699ee09754eb2be7cc74f04afbf9f-87152d18ebb1479ebd6d53ef5a7f361a'),\n",
       " Match(model_a='lfm-40b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='a3ca98b62f9e4e988023e952d19bc77d-2e37d955c79b4f55a60c468eb3e55487'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='03f2e7c1a7f344e8b210d1dca469bda3-b1630a30df44499daea240465d616a29'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='a5f2559d0d6f4aa2a9ccc469c87a6dc7-fc2092c630ad4193b5595076c9862aa3'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='3ea8ab2cbff24ffeaff9cd431e5c9e8c-31c43be1194c4df696fa263c333172c7'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='4992e469e02e4b8b8ca5a1201b087884-78aedc1822fa4e87af46178cb3d96ef7'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='70eb973174ef42dc8c3942651904ce4e-75217364d897492cb2fa5445714396bd'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='e4d8ea1418894fc4bd8a929503327c4c-f578297a7bcd428985cc595047bbf827'),\n",
       " Match(model_a='aya-expanse-8b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='c9fd1d22560e46d181190608eb5e9e60-29297020c48644fa9e3e750d66611173'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='9027cccc15c541bcb345cd22c20750dc-31fad7b6d36c497798325c17d3f8581b'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='c02b45e76de0491ca0ef28276b058a62-37001248612044269100dee191362254'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='5d8e03b8412b40c7bbc069606c55843e-cf7c2d024d7443848c6ee917067be460'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='44c037b32f704635869e62af94c750a0-36fce8becb924d478279fb24ca9da952'),\n",
       " Match(model_a='llama-3.1-405b', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='8ae240a103044ce4b040623de5a2d988-24f06d274847421db8cb7237c2d7b00e'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='22957cd2e429477087a1089c2011a5c1-82664588a18f4e71964c0256fca3d974'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='91d7ee619a9546dd8060b4f62ba41098-c86ddf7e72de463ba7f911264b60f6cf'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='07bd70be79ab4c05821bf6db2394e3b1-c2c1dfc06c004972abfc6babc7ac47fa'),\n",
       " Match(model_a='deepseek-r1', model_b='command-a', score=<MatchScore.B: 0>, id='55281c1ef37f415192d5b053b649c920-6005a7faa1334c6f911ca0330a15244c'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='grok-3-mini-beta', score=<MatchScore.B: 0>, id='e6149fc6919743038944b96f61836e2e-2089f2f945da419795ef28364d2d82bf'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='04b47c85f9c24b18a47d3df630f42df0-71ee4ff9524d4f449e750cea2c6d4d07'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='command-a', score=<MatchScore.Draw: 1>, id='0efa5e2a980b47c18d06d5ca2e871e62-fad33eb447dc41d08828a38e3f6b80a0'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='d4f099b0a41a49a98851646b66d06469-4c734084fcdb4c5f8d9766046ee6c3f5'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='phi-4', score=<MatchScore.B: 0>, id='a6fec376caca414a86e7d9bb9944cc77-0f84d90690114fe0b4e7ef3b2337bfff'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='42be9844b47e48ce81cdb86bfd51d282-06759d616f5f4ebcb6e9fd0bc962d547'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemma-3-27b', score=<MatchScore.Draw: 1>, id='9795d0178fe5415eae11fbca141cbbcc-7125a51fc606466bb279d6e460dabc01'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='f0b69a6c037643ef9bc990b14d21e19f-dbccd13f37144596ae42ee0708a9e4ed'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='341f1be02c4a40f4852780dabb88dc79-5b6f3383acc7419db204fc5f01db586f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='28caf252a256410382ddacdb1294d16b-56a933d89d694e04b72aba4277ddcf49'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='3c44abe347c4486087550e489502105a-dd962d0976f748acad72ed10ab3b0716'),\n",
       " Match(model_a='deepseek-r1', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='330a932318b64108955b180e48e72025-bf8b4548c3db4024bad5f4d7b1d57983'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='89ec38527286431aa8546a930e025ccd-180a2bce924f4bcd93ab043733579043'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='f75c574d2bbd468b84da888a5b0d8994-9353610dcdcc41b18c18b20402b46f08'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='0dd0ad3ace3a429bbb0874c422a9a14d-bf9a78d8bf47496d8ee2458b9d22f9d8'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='61815a811507406aabc9ac312e2d9971-b0340f1445594af6b7de9e887a0720e0'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='qwen2.5-32b-instruct', score=<MatchScore.B: 0>, id='1b3091ca8d0f4535a5caedac842945d5-247dc03b6c63455090100d223243af27'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='2400ceeb31d34bac873d80ef926d6994-02429ad245844a2aa513c263501d79c3'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='3ae3a600570d402ab1d782ecb82c9308-1f4dbdadb7664a75b356e7251cb1b3b9'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='f366a3e34a974d0993484fdd9500128f-7bd313887e8f4608b3140ecbac434600'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='ab87a5a6696c4d27a76d26437c3d86b8-10fcbc1b9f53462fb3ffe9248ca0469f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='559d4a2582de42c1a1252cb96ac36eab-ced14dc4916148f48850f05509917a5c'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='dadf619570fe4e47a8e135ef7962d2da-f26f5b6eaf19474fb9f5cc4fdd698ceb'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='6d9d3fbb6df44b73b921961b371be49b-d233710766844e0490e89a54a9f0c481'),\n",
       " Match(model_a='qwq-32b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='06b119aab5854abb9861b7b01337d75d-1475c7d12d2c462f967501babfe77abd'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='960c5d23a8564b5bb1ff93a945c2dcbc-e9840439470b438ea0de36e159ed031b'),\n",
       " Match(model_a='o3-mini', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='4f129e0a13884921a0c05e3fd72c1e7b-0fb151b95f9d44b69dca939d0fe58634'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='2ae66b8a33a14295af71e8751d5cf373-88f990cf0d764dde8dadd0d458d3be95'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='41cf83657ff84dddbd2ea7f68bfc3b43-bc56ff5a31f44000be9642c8a55d738e'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='3414c95491e149b9bff180ce5006eaf5-7507c77075e343ea8aaf6cf0dfa6ac5c'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='c0c8134f8f2242d89cd9063fa2a8697c-63a15d85c6d54d6ab565d2ad61d672ee'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='7d259ffb01984099904f9f298b638346-2908634df3dc48f3b4ddf02b6774c418'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='25abf4a53dc042d0a19072cdfeefa471-65ccf58156e24d8792f6d43d6a9f6b22'),\n",
       " Match(model_a='o3-mini', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='ce156f9e84cb45b2a1fc00fae99769d3-4146d87fab6849e6ab83122abc47b000'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='672320bd54d2492e94f036a616ba0453-d0183b74ab034a6e9307220074d04337'),\n",
       " Match(model_a='aya-expanse-8b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='c69f46bdde9243649b7581e0b62c3e68-26a96ae00a454db8850b95e752b65920'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='c07cdf61108f496c84b70394b1be8078-bbc74ccd13ea4792bfc6ae9ff247f725'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='ccaca054fe584ec9808c705da97b40db-2bf5efda3a1642a0a5af34e581e4ac63'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='1e3478253502437a9ca33df6b0fc0a79-af80459908164bd5a8ffc2687e8dd717'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='0789f4e55a224c4490c3b46f39b434c5-8135735208ed4799b86c91c79e5e729e'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='d1f72a76aa434d1a8f600c0792780860-5cd70dff3f714e9d9b288a6f5a0a7fae'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='5eebee13c38d4589a326a1edb8bbf9af-02aaff5f33474becb65f6b1cd32d1d25'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='phi-4', score=<MatchScore.Draw: 1>, id='3d17a19c792b4755af8dc46f00820063-3fcb5df2e54c46f2870b499bede976f8'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='2d21f5a9f64e46a9a87b6c337a5c2f3f-81cd3af0665345248147fe7038c265c0'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='phi-4', score=<MatchScore.B: 0>, id='da65d991b7be4949af92d79ee3b01653-2a463d75bdc24298a199fdd8fced3606'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='338eb6d352c9445084dfd464818faadd-e07bef9847fe483c8229b661933ccfcf'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='820491b437d84405a873d10b5b514f4d-6876c6db99de46b989f796a4f59c8901'),\n",
       " Match(model_a='lfm-40b', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='936e2d70b5c54e03bacef7480301c193-72aa3859d8324c72976660a2f5438ace'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='ad79146c7bdf48da9c69c687121bce4f-5016e6e3d63c4e6dadebd8bb686a6178'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='81aa9a257a64402891462d600c570988-9af78c41a5724b3784169933529f207f'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='7562281b7afa4dd4ad7a4f028a6b84c1-f90bee8e48954dfd9b214bd502c8fba5'),\n",
       " Match(model_a='aya-expanse-8b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='f3640ecc61b340c6849fdb11b0bd9100-fcf48e50b1b94bd7bb368a9c4e816499'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='ef0f200fbdce45fa921f6418339f61be-f74de885043b4538815eac53f4ccc536'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='3a34d2ca4699415ea567f17117eb51a5-d4257bb7206b4da4b7d53e14414abbd0'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='2fd56636a9bc4b198488a4fbae4888a7-cde21c03be984afaa101b216283a098e'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='6b41a945d6e543339bbee2bfdcc6b347-4b4bb4ec8f444ef4866fcf6477e6afde'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='60abad33135741128235386a33bb0e00-492dd23fc6aa42e2ad14b1b0af6023b7'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='316dd9cf938942189a8898e5397d15f4-34b19fe384324f608d282d581858989c'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='a847c5259d794b12a91860e30c940ce2-4d7a9e1a06df483fbac9f9f262e5ae32'),\n",
       " Match(model_a='llama-3.1-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='8ccf2287b1ff41d0bee53763eb2c6e32-90dcd49b823647b8b295b59464e0508a'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='phi-4', score=<MatchScore.A: 2>, id='7ed32a6e7f244803954f302a38a9f560-db1de04645484d73ba9405a010d5c050'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='1a1a451090f840869605ffad6ffa19ff-cc1beda9b2ac4de493b56cba2d9796dc'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='34e859fa19e44fb4b1cec9cce42e51ec-90f8ed678e4545a8a93dffdf9c5236d4'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='5fadb8bb7c5445a7a0ae0069939d6ef1-49e07d32d5a64da39e6fbbfcb0b7d19d'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='78389a7affcf49f09f49d50fde0908bd-f9ad5c7f0d0e4ae08d4ff3c5ea685675'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='326dd585f4e349268a1d2db01c4b29ad-3deeb8b8ea49473aa521e868f9bed688'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='743fc4ab6a3c4b42be1acf66ad1bd5f5-349ec3278c19438fbf7e72a97076954e'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='1caf7ed61a554eecbb5ee40d6ee2b3f2-ed3a59d7d52c469b9c80b8572968873a'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='a0c5dd807c9e4aea8f06258626819236-f7cd3b86e53a4ea0bac5f11a56b5a7b3'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='053ee42b66084670982c1d8ed0babd2c-553d86c0c54b4cfeb187701e34cb70f8'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-2-27b-it-q8', score=<MatchScore.B: 0>, id='bab8255182014b2bbe2ebb8a0b37edad-dfa3f643aa5d4d1ca71f9272cf49752b'),\n",
       " Match(model_a='gemma-3-27b', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='d173c435365c4a8bad24e1de23fc3ee1-cd2d25b4d7174c39bdfde97c87cf5a6e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='806f245194534d0b89b43da5515ea050-ad96976a4641447badfe3f053508ecef'),\n",
       " Match(model_a='o4-mini', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='7dc3fe6ec66546bd952e790fc8375d48-ce3c6d0ec72c4804877d0ebdb2e480d1'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='3033d631d7ff4121b902c369a8eb8ba6-9a719ab1fb9040c8bacb6087d06ced32'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='b8b915191db4437b82064b1b369aefdc-86eeb0e42fbc40709eb7062ff7c56dab'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='076bf86386af48adba025a41ba4dab19-99d3f5164cb0440d85f80a737f09e81b'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='92bf3177adce4ef883775dab09900319-e58a8b849d274bbf94381b0677390a34'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='command-a', score=<MatchScore.B: 0>, id='4024303da01445169953109e7f29fd6a-c3898efcd412451ca9f594a153c2838e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='01720d5cb4e2431fa22212bdef679ae0-0737bf0fd1714e34a9bd928daa809138'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='41603b6c846840aa93ca1757d53c142f-ca17cda22ea849c4a30979fccb87a22a'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='f0d6e0ebdcdc48e196b54c9479384f35-81afa43393954f7cad9311dcd033e09c'),\n",
       " Match(model_a='gemma-3-27b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='0ef2510450d74e6dbfbfa25b71add300-0de699a55325488093a24a336b1ba7a9'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='command-a', score=<MatchScore.B: 0>, id='95f8185bafb6432d9bf1b54f0173174a-ca68ca0f43664a0ab48c841cdf2e86df'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='080b92beed974ee995c743fe506ad801-83151d3c02a942e2a3cb73d73a583eee'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='74e1fc9945d147b6b65104871bbf5853-e2136da7bc414bc88b55c6943b7a3817'),\n",
       " Match(model_a='mistral-saba', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='b8103f2bc26b4f69b89c0b53ab7235e9-e841c4f39bb347bd8ec1a15b3f8f87d2'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='1f825b8101ab436291a8758b44e77b2f-6c1bcef42bf24b83a3d5505f07ba04ef'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='4087c66fd76e4f3c9b09c69d83a9ee0e-3324c54d19964db6ab339fa9aa6ae1a9'),\n",
       " Match(model_a='llama-3.1-405b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='53790ab67af847e5a77d15e82feecdb4-0595ed9f68dc4b8c9b8052314ac772a2'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='b7100171585d4b4a8cf6a7d4fb2f6b27-84c4c9004717402cbd76d5ebce9a2b67'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='40f4705470c0417f80ef7055b4b038aa-b06cb030787b473db19fe869015f2521'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='6cbecff94e584ccc969c928851fdc8a3-b7978a50bfcd48f4bf5f2c88321fe84c'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='d8871284bdc2475c9f4c3bfe6304874b-fe161cad8696410396dafaea4f2dbca0'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='b7723738b7664ed087cbd23794cd576e-0cd25dcf444f4b8889763e0608bab2d7'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwq-32b', score=<MatchScore.A: 2>, id='cff06400e7e64e6ea66206a3d0177b2f-35d4680b334e4ec3aa1da4bf80f8750e'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='e1e323df14d442b3a5f78b4a911fdb46-b5b4b08ad17749f4bc167a47660439d9'),\n",
       " Match(model_a='qwq-32b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='fed33cb434194703910884bc21d0ce26-26a910dde5bf48048b33b81fa1b47a5e'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='edb493ba6e0e4dac95aa13b21bbabb95-4f1a2d11cd7c4cd2a18a8f3824a0ff91'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='64a602995acd4322b6ecbe18b6f3b790-a247e3aa1de342eca140f6d11f5125e5'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='376f714ff3794c8489811c3b9139081f-dd1a91f392c44d54a97c3288c5122991'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='b9e6a28213b649828d4f52443ae409a7-3151d61281194f37a1a27c38cd2da2b1'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='94e0ce4e0b2a402fb819463d43d8d419-cb52f766b9704f12a400067798859212'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='4397d5c8ae964656be22ff9c5b3676f0-8b29e3e19dc8472c898962732944bac2'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='1e721098f3fd4f6b80d9f7485a7e38fb-a1284bce37e84803b0ebb726c7ab0f60'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='fefa83f033114909893ddd2044b115c4-04bb568569ac42a19f6d9d45b9522aeb'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='9e9fed2eaedd4962afd3368034d886fe-32aae4a22cad49db954aa77814ae3c3a'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='2c09f523b2484fc29e1b8ce76939b84c-19cbcf17ea214d3bab5ff9fcf49dc3bd'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='ce5834b4bfb143d8a2dec5e0084e8788-bf7b520def544dcfb06a3b8c0f170993'),\n",
       " Match(model_a='mistral-large-2411', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='9c0bf0cdbbcb49b890c10a0aa23782ac-b1318a3cacd54828b67beb27e85c4cf9'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='a97f0eaac4f64e4982525898af6f44b8-66c478ebee9b4cffaba34db3b1c0c7d2'),\n",
       " Match(model_a='llama-3.1-8b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='e063f8658b1b4ce9bca5b3c9f814436b-4b7c9734d8b94c21bf65fc8a1fa39dd4'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='75aa033860ca4e45ad49fef5566e982d-3928a7b7faf14a9cbf884c989f655661'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='914aa8a938fd45febd1bacf5965851b0-7a2eeea36b364019a40455e1be639257'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='5a41bf98507143dfbba8e38c8258d8f0-6a99d56ad5ed497a84ae63de43ace627'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='bf2e289b1a174b2891376b228062b861-f773b2d2db6c445abf065c2948273ae3'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='55ae485bde53477fb3f3081d3ffc4b79-22611a4fee394a2b81c282dca5753557'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='llama-4-scout', score=<MatchScore.Draw: 1>, id='35bf925be729438cb88bceffb37835de-917c34a586894bfc93518c4c024ce2c1'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='fe9a403be7b74f5797135cb1f97eb286-df7ce41e87ad4bf491ea185e65ec161a'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='f038a580490249ec8360557050e60aef-e6d74c1166504b519c833b880fc9ae9f'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='bd87c4e1bf864cfab36e54b861eab31e-c2b800e0055846f381f2132b317273f6'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='9a8680d3732242a3ad1947ff17d508d8-b7d0368d07044736958db80be9e1cca2'),\n",
       " Match(model_a='qwq-32b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.B: 0>, id='2a54011e8d324e0cada8138b4bdccf16-43229ed961dd45999442911f0a3af620'),\n",
       " Match(model_a='phi-4', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='d3f1a8b436084067a2ed2ea11ac2e5a8-639d7b9bc2c54f18b0afadbca87042d6'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='4b3a255036cd4d32b6b6deca43c91986-3206ca1670d74c3ead3a52120cc44701'),\n",
       " Match(model_a='phi-4', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='f3a8e4b4c5f54a3cb0a748d8ebdc4ad5-d2c34caaf07643f894a965123d3c2ee9'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='cbc52b3ba5ee43cd8cf0127fd53bacc5-04339f3157ee482b95be2bcd424cf2eb'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='be6022db3289484182a050f50d22bbb2-0830e089f30940a8b252083bdb07b33d'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='caa865a7222047968b391d8e642a000b-82aea5b2c19046159d7dbbc0d9203c65'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='c7a0cdcd0bd249bf8f4d2a85d18ba68c-578a8fd14d4e49929b8bca3577023cf6'),\n",
       " Match(model_a='mistral-large-2411', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='2ea618af213b4f359ae0ab4e1a067f4f-91c049c2f93d477ab1be17e0d81c904a'),\n",
       " Match(model_a='o3-mini', model_b='qwq-32b', score=<MatchScore.Draw: 1>, id='9f674c5b4f254d23a2d8a16b27bc7491-e2f2b8624fd94d4c8eb409f78106aa67'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='d958606ab777436b88f0cf054238497f-326da67cdcd3474f8e9a32e3411e816b'),\n",
       " Match(model_a='gemma-3-12b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='f7643869ddec4cb8b6c78d5d293d64c3-75603b82043f4248af8b420e791f7669'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='d8da559c648a4113811b92a53e149e7c-17b7e59ba203432eb10be18958308749'),\n",
       " Match(model_a='lfm-40b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='a227b44059f0448cb81546e024ddad27-d8f47c36dea342dea83683b048c81d02'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='8c3e1129765449f596cbc3919fcdfe0b-c4e3e29ec59d4febabf90078242c07b5'),\n",
       " Match(model_a='phi-4', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='e780f3316a404d37b4a49e0b36468533-dc95af0a4cf744f3bd67af1a6b08f4ce'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='phi-4', score=<MatchScore.B: 0>, id='c1e236f45cf54bfd936f5c4048dfdb43-081c797837cf4f77b0167a14b90158d2'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='43f497a4a58244d7862f67a5c1ab0509-c49d3b9392594086965ef84fcb86d60d'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='4677636769604d89bd5f87859548d36e-8de55d5cdb954157944c45a107c0d824'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='e386290a48d24167a4a964ea80077c8a-ef2b7339addb42038bd4be360b19f0da'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='00549053139b495cae9ffb0a76760463-31ebe8534a554711bf2dad6ede6c5566'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='167a03f200434ee09ad2754360ee3d87-41cb84920d0544a28ccf86f999970bc1'),\n",
       " Match(model_a='gemma-3-4b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='a91ee68df42b4925882e90afae8cafac-96c4b37623694744aa686ff2ece766a0'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='8b5fe75fe1024d8d87ff4559ba16ba58-871f92d26f014ae6aaceb21875c39306'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='4d3287ac226d47cea8acd6de9089a5f0-0673b9ca9b5340d6ab11e4d8249cb1d1'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='11ef34b726774b5a80c3c52d95d00044-4dc55732ee024913a864be775bc95475'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='fadbe6a7b989415dbbc32970f82dd7cf-3463ed7245974363b2cd159374b6d44f'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='00bdd5db4bb24daca52dfbfe0fc2097e-22960602a74a44c4b7c8efb0e7ce09f7'),\n",
       " Match(model_a='o4-mini', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='5cf7807dd4a340d2915450be22556877-95539e60e0b6427cb6bab6b83e7e3968'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='360fcb335eb34ab1acbce3fc9f4ab1b6-5eb2fb6297d548a297f790237f5040be'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='15d072e591b64ac68f7c0ba90c3dfe3c-719cf6523d30401c8388590cb336048b'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='52c4ef59d1fe42559568113aa88a8aac-553140924e5447288f1a1f7dfe7a9ef1'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='6692a4aa52b449d9a9c4a91c3b445b4b-b2edcf73aed7482c9aa55fd46be4b765'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='35e33173a26247aa947dc2a201b4292c-8e8ff983160f4365ba56627d149d9c59'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='ca4d99f8091540fea9c0066e872728a8-0a3f8462e9604b789469bdc8e8fcd485'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='1b69b3c6ae4f4d80a7209b7f7e980117-35b72156617d42d193d79f994c5a08eb'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='dbf0ec999da449dea91d43f5e5f7437f-c3b0089cbc9e46558783f2991b697977'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='5491a6f5b92245f4a16bede55678f7cc-61e5997a64c14a6a8fef8c55cb4f4a05'),\n",
       " Match(model_a='command-a', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='8ef17748a4034339aa59ceabc212ecf8-c68790f0802d4a99b8e6c363ab31bde0'),\n",
       " Match(model_a='llama-3.1-405b', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='e5457ceda2004920a60e1afc0a8e003d-678a1353d5d443aa922e6109cf6f7122'),\n",
       " Match(model_a='gemma-3-12b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='d6bd33813a2b4b13a073c928d14c7b5f-505be0c515304084acbab54d7aee3c77'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='3ddf62f02f3249248493837e75b0b2dd-f2bc0254eaaf4ecdb51c62a2380ff97e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='e0b0732cc77347c1b5e77461308dadca-4fdaaa4685de4906a5591b2825681028'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='a8fd0f944b2f4f5aa54fbb4180654795-246fd177b0f745d6b9e3a7f3382a634e'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='c36667bca233465b987ce480744d0ac6-497d9fd16f0441a88f90e3ff70d9bb19'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='ddbca5931c744b5a88022e895a5df537-e1c8446ab9454ba19592c37e51db3ecc'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='bc2cb5e70b7d4af782e85703878874c1-ca60f4e3a1254bb5936cf94d02c4389c'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='93bc79e523de495388323701ba37a36c-d7bf967f79c442f68852c97767a9d822'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='0866bab3b7854274a734e95302d2fe22-224a2cd9672143baab3b4c8619f11053'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='4e297bf445d14904bd8161a7f6970bc6-95923a98c3004597ae5ca891d3a2bbb0'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='aa965728be344c85a3daa7e89e7262f0-dce8d473a78443f0aaff0ecc7abc9247'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='956f57abdcd14a9e8575a19661855f28-4b4e846b97d441a3a337cc5886dd33c1'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='b570232f236c453eb73e2b063054bc74-5f1610a7009c4f1a9f62c6f23273f6ba'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='a8a1002687b74d5591bdb795c4d66056-d5773037b835480b9544dd7c484acb41'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='command-a', score=<MatchScore.A: 2>, id='931ae2a8349f48f2b7c79fa56f2e530d-e56ab9fee5934358a357ee730980539b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='bde4cb77773341efb6d50d9c89afbf26-544c70ae2dcb453b8dbf0445d43d825b'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o3-mini', score=<MatchScore.A: 2>, id='5fbfd29f1bc24a7a968c710c3caf98bd-d72e510359ee474b8519211867c6760c'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='0621765e00eb4b49b8fd5f08e4b3308a-b46001f6be384829a61a92112b572796'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='283ecce16c9442d59e1cefc034ef3ead-6d25e037d7e34b7da6025cf2c50f8f38'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='8b1e0b2c55ec460bba3a359e712caa5a-93fe95102b8a4f808e68eb82ca1de627'),\n",
       " Match(model_a='lfm-40b', model_b='gemma-2-27b-it-q8', score=<MatchScore.A: 2>, id='3908cac9f173440ba7477049ef142042-45030930854a4d4996892868996f6046'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='cd0bbbd2e56841cea434485fb878a1fa-bc2c37c210624dd18be5c2bd762df6c4'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='d268abee49f143c4ba997effebbc2da7-e349e6b30f2b449db166f0fcfa5c728e'),\n",
       " Match(model_a='llama-3.1-8b', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='187d852bf84f490798058d29641f2f7b-02ee9e23c5c84621adfd283f98404a66'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='d9d230febb484c79afe2bc3a952cb5b3-db250b0a63d04ac5bd0fd912f183f485'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='f451c4eb33c34b2dbde063b6e585738d-d7b0e6da2f5542119b1bb433e530752c'),\n",
       " Match(model_a='phi-4', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='84d4015982304aa49f85c347405b6ecc-61ba41c334c14385ad0b3cff33311d77'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='b44327c8ba9b411eb06a72dae5de8b54-44a42baf732d49b19d823a7f31fb8cb6'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='cc375e5388d340d09319f7d00e46a6e8-80b57ca11a334a9a8fe0eb15a8cb04e2'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='8750bd4a409f40c39be800aaa97b09b8-02eb2e98643149a78dbb8deb384b23bb'),\n",
       " Match(model_a='qwq-32b', model_b='gemma-3-12b', score=<MatchScore.A: 2>, id='c38a7626884b4c20b0e6dfdbf11e4be9-05421ae4883d436980992176c1224f27'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='61cc634bc40643c68fb062645ede6014-3644083365124775b6198a92abc04b61'),\n",
       " Match(model_a='lfm-40b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='446c51c63849496b8efe5299b77c13a5-f4979297431b4da18ff679348eaecc18'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='75a7afc97d2b464cbee4ae1a4ef4553c-ba993c666e0b4468846c01e186332ecb'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='edb5dbca7671497799f0a75bc3de929d-d69f116ab851487db6a01866cbe35e7e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='4b02725244f84f219cfbd6f97a67b2e7-5d6b4c3d3a3a45039de2bccdc60c4ea5'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.B: 0>, id='6a08f90015d143aba5e798468ea02632-0563f5431b5d4319918e0a0a27c1f268'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='11c0a5433ca5440b943a69caecdffca2-53177475afd440e6aba662d2d2660b04'),\n",
       " Match(model_a='phi-4', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='ef132590e77f49efbcd020485b9d7a24-4e05fc3c356245bda46a643b7e2a6390'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='af9c6ad314be4b8b8db9387b74f5fd00-da8d60a9f05943ba91264b3eaa28192c'),\n",
       " Match(model_a='qwen2-7b-instruct', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='95d03885692049d2b1e00aa83c69c5d7-a6a43016ecc840cabac7ee4ff9e9e798'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-saba', score=<MatchScore.Draw: 1>, id='d022aa43ad1344598d8bb3b01bbf5238-80949ceb95e84aa18f7332f601b4a57f'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='ead391b1295940e3ba99c65115c6eeba-f4c1524789494d769fb3fa42f4de4ec2'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='69efe45356654195b6413a51fd0f7025-03333fbb15e1401abbd810b5289eaf66'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='693e67bc1f024227b6294a178b9b907b-086bfa2db2c0412388981fb388de459d'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='fbfaf9db4a18436bb8a13cb5cda1ef6d-f42323cad2f24ec4adb81a9df951ddb8'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='01be794a574b40a69caa5d774a5a4697-4c8d2f4fed55407584b344f60b90422e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-4-scout', score=<MatchScore.B: 0>, id='7b71303e583740a58be909c0f8bcf148-c9b20de73ef0471b83ddbb3ff25cbe83'),\n",
       " Match(model_a='mistral-large-2411', model_b='phi-4', score=<MatchScore.Draw: 1>, id='6c0e912f502f4a78a9afedadb8cf5910-e71b5a629e724acabffcbe62e7f47ac0'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='8736e26a2e594aa78ccc688db1df02a1-c8c8da8e92ef4bd58dcad7c6cba1a786'),\n",
       " Match(model_a='llama-3.3-70b', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='b3033d7a771f4c90b45f8d753186906f-8c9b631fc1ed4241bdceed3694ee2ccf'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-27b-it-q8', score=<MatchScore.A: 2>, id='09f04d7ace114bfd81def3a7f5e057f1-c30ad13694ee4002bb61cec3f0dd1da2'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='d3b04944c3a04bc7a17786844a81eef2-b4839e009b944730809985b429173e3f'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='6435f848c2c843ffb909ca4734d133cc-010cf8a47abe430d9dd8b8f0e086fca1'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='b7067d39cf01472090804f9c9ad11e5b-bcb35c7da22a413b834113f0239ae534'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='c3eeccbed3cd41129681ffb89f6a18d3-12a357531107405393cc4da154e3e6cf'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='bdea49c1cd934934b18f61cbb80336ed-f4903ece30f048c8a054183d58354985'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='f094d00be5e54a84aee3d018a1109048-b57ad08d5d0b47379266c4abef1eb834'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='70ca439003f744ef9c5da431c19c1002-88ebbf73b7e24073bb3743de42846050'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='4a0d2b23f5e648e9b257c5299b17acdb-cf00ab7316cc4cb7842703616f0df17e'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='0773c64677d94bdcbc5acf646dc32b73-c5f17d2370374be48061ec9d723d0e82'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='a63bcbaac137412393c01bac670febe0-50cb3bdc225740a8a3878c4bb17533b8'),\n",
       " Match(model_a='llama-3.3-70b', model_b='aya-expanse-8b', score=<MatchScore.Draw: 1>, id='7e0a32bc1f0142b1886c749b0f659dad-a57be9ca1619450aa07aaf6363b165ed'),\n",
       " Match(model_a='gemma-3-27b', model_b='mistral-saba', score=<MatchScore.Draw: 1>, id='02b5e500c60045ecb9f1280ff2ab7c08-34df321042934d4fa30ba8e85157c36f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='40db36bbdf964234a1cc48b6bb862683-d2f8f4adc326470e8ae3a0b79d0ea525'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='84904e33c2144fcdbe97246a923d1ff9-f44dd30127224ddc8109cf60d8888401'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='6863706f77ed473fad1601f53de6e5a3-445d6504be69478a9369453c740e6b40'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='bcadf6e628544b00899691d3aa6d0a88-e6a39678b35640efae76968037f94aee'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='mistral-saba', score=<MatchScore.Draw: 1>, id='4f4afcbb76544de59344d058e867663f-e0b67d97d9854380a0c34c6c0e72ebfd'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='9df3e11a8e8f44c3886679cc0e90f18f-d87490b26e0b4c608f775d83db5cf233'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='99c487e556114966b36ae9cb4af3b923-c2cb884bfcbe422c9546ae16594196e8'),\n",
       " Match(model_a='gemma-3-12b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='a85ba2bc019546e7a71a3a5347c5105e-fbd23757b4b44d4f89a930931dff1b67'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='lfm-40b', score=<MatchScore.A: 2>, id='b98eda01e12b4797aeac04fa86aa19f2-40a29373097a4c40bbd387e5e343bca0'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='f4bb4ba6c46d4ce7b13122fe351b9692-b1a42892d1dc41b4a32116184388fb3f'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='61b2876aa697402d9da0a7094afc52a3-f4f830c5b27a480e9a9df8e197bc028f'),\n",
       " Match(model_a='phi-4', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='8deef9133b474ccc99270014a4947f9e-e587216c9a584ed08f1d92eedc37b6b5'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='108b2575554945a98a257e8499b06185-7ac5ad6311254450ae15510c010954c8'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='580c4d1f22dd4ef8a7997a460b16b03c-677acdcb26fc448096d9894d89897735'),\n",
       " Match(model_a='llama-3.1-405b', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.B: 0>, id='bf3c41fb79874e388f9df807e2a51588-bdd423e900084f259b6c3b78fd599020'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='0b57ced71e014f57bbb485da7fc6ebec-e90903dde967409a94d1c418ea941137'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='36d3a6480bd2431cb3e6c6391645aad7-9c098e8304f841d784fb94e60cfcda5e'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='7a2dc387534a45d6ab7b7c143ef67254-f9538e81caa24b539a1f13da01ffcc44'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='command-a', score=<MatchScore.A: 2>, id='022265279a5a4c8f800542196b71dc87-4045503c166f46c4a77230acb5827594'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='c21545cc9af04fb393b08fb5ae99fb69-65d5560eec964b5f87951d4d54b49130'),\n",
       " Match(model_a='o3-mini', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='4288b0e058e0403c90915630e21c6b01-e3c298d25fe849fe8921f90f652b8a0f'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='a994b637c0124106b0166a8c9a1b6f46-095750081f284c3e848bb4f65d9ca5ab'),\n",
       " Match(model_a='o3-mini', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='402041d03b944cf3acb553dcf3ddcabe-95d6606f04e64f8aa3cac9d66ab597e2'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='c0e1d32f0e8f4bc49f3ea10506f33506-9c8626419e764df1a7912c1c30234140'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='8b2ed0f424ec4a5cac952ab0f20f7aca-5c4d5acdba5e4453b2a35faa15eef442'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='1de6f2e0419448baae6a126fbf142dfa-d82f454342224fc0b1b33db8726c972c'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='b9fc360b74084a8f9481d768c997cc46-d39d3af2f3ea42fabf024ebe422db43b'),\n",
       " Match(model_a='deepseek-r1', model_b='qwq-32b', score=<MatchScore.A: 2>, id='27b027b85f2f472fa627c39c956af08e-aea62c53d5ec42389ef9dd3523ec937b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='c569db30a05f40cdbfeac8a6fbaccc95-68a50bc8a17b46caba52c226596133d6'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='7162264200fc4fbd9ae70483c889ea18-1c972bbb358745239649e67d5f095f40'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='3d49ca1d501e44fa959069789afb6df5-204441e9c7c24039acdfa41184ae0e1c'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='c6531c5eb968477fb95274ad88966d8d-13313350f334434797dba18ec0e13b20'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='7d8c2b80abda475990c5ca498a75e3b4-b82ced387ee04a1f8fb7b4f3c1f31c6d'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='277555e34cac46d4b57a435b00df9ebc-5a6bb3403cd441a0a273cd1bb05d5a0d'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='d708e6d827b54699b92fc7fa5991cf50-83e45401dae944cab4007f2b8fab5872'),\n",
       " Match(model_a='o4-mini', model_b='grok-3-mini-beta', score=<MatchScore.A: 2>, id='4749d036af2f4a4d850b2d8efd05f21d-1073eacd3cb448b7bdc965460805a8e4'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='20cd3140a2d04ff7a3af9cebe622f7cc-52c762a1a910433196f9e1bf2f306a5b'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='88053393f89745669d45a8cf74a287a3-afed212fd42e4e989de304e306f7ad95'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='88a86e679d7940459d549f76a8cea216-8d7d35650f6349259fc74a39ba4a6d74'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='09e7ab325749447cb6887d29da744b23-13f0363e274546ba9f651abf1d8f2693'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='710e90ef787342afa9eb75f503c13863-0f3125c53d2548bf90539820625b91f2'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='aacf863f1d2a435fa6f7756525c30f08-d0085c199a2c4f48a258746af702d90d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='2f439c3eff934cd489b6181463c902e7-c93353cb41474b0bbbd96a7bccb5cc61'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='5fbb074493e140029331fba77391272f-8940ca7052c5499fb2f81a979aa792a5'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gpt-4.1-nano', score=<MatchScore.Draw: 1>, id='7ae36b5086004c21a4c749bf2c61ff3e-467c5c5301a3485ab9d1911932777e6e'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='598472a8f6d44669b25046b7dcbcdac5-fa89dd0f537d449baf9f802c4d691e7c'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='be5f0463fab34774b80c5536dea3526f-e4402e297f7543f59742b4788d7b72c7'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='ab4b64b2766d46dfb59d45d20c2f6e2e-369165564137451d8787ade6a20a0d87'),\n",
       " Match(model_a='llama-3.1-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='917791fc774741b58da5b1149904d793-7b73cb18554e4e159f873f78f9c198da'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='ee863a36b1564acba22d508a903500a9-e184d64bc96044d1ac364fcb716353ca'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='d30cbea33d7d49aab504598f452076f3-92a748277752488a9118825ede888f24'),\n",
       " Match(model_a='llama-3.1-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='63326fe0e90f4265b4d70bb9d0b22041-e976e3d149d742da81c56152c7f44d44'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='2fdc503dc02e46d282c07a03f5c5533c-7e1da330e8624e0091f914104c5c5776'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='267b8b5e1ca64d39879a4d3f15adfff0-c6ab7c6620184b5c92f50942f4a0681e'),\n",
       " Match(model_a='llama-3.3-70b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='3a83d054742241629dbf7cdadc430fa9-16801687d402470ba9fa4db690e4056e'),\n",
       " Match(model_a='phi-4', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='e06c6f9da0244b6f8321dad43515f431-9c9c032ec19845dcb1ce74ec53453304'),\n",
       " Match(model_a='mistral-saba', model_b='llama-4-scout', score=<MatchScore.B: 0>, id='b0489d5c98024f1fbbf71e38f57bbe86-6fa8922d33e24e4d845803778d661177'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='4619b83c66694b59ac3552b1befc3ff5-44aeb9f251f6423bbe1c6178d33c4bfb'),\n",
       " Match(model_a='llama-3.3-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='291e0636643c4abeb2689522f8e6cdb6-326aa6cf1b8848b2954517015439366a'),\n",
       " Match(model_a='llama-4-scout', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='5318dbcb186a486ab6573b42a35bdfb9-1420a45e02d24c65939012c1526c0c8c'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='ccd5fe7059ed4a16a504a85ff1e380b0-d0157087d41f4b7b9eeec0b3fa7c7d21'),\n",
       " Match(model_a='phi-4', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='eb0bfe5be33d41d2a64f7a844018a888-1340a279bcd741e79db13e48d3d6e4a9'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='badea92692f8488285abb4b4d0722168-21cba0efbbf74f05b0d5d8b8abb2a554'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='bdf6e0916a9d477cba5845cbdacb18b4-752e6419e6de4b74bce9b2366d51f912'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='e0a06ec54cf14399a25514061a625f6f-dfc4070b37b645fd94e06d8001c1b277'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='0b56ecc12b7c48cabdd7cce71ee2e061-fa2ace75ebfe4cc6b7519b99245b7a23'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='362453d9fa514a319bceab2bbb3c41e1-1df487becb0a4e81b540952945b7a706'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='aa43c34ba53545d3bc6e3f8ffe7fd8f4-f7f931874bab43a3984a4127249ba8a3'),\n",
       " Match(model_a='gemma-3-27b', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='c0cf6849856d4f39954dd84868ab8995-cf94fd690fd945e0bbbc878bf9e2a1e1'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='c2665d4b5d4f436d8749d84c5ce2c9ce-f9b30eedccc5497784d8f13a3caa034a'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='be748bc851bd4e4d8c024cfca5567b61-60f0f511375d4a6299843d97dfb37af7'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='d9c8906affb8488aac3de025fc5e2519-1cf70eb58fcf4891bc9c5aa555ad71c3'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='0ed2fe05a71f44f7b53628b6a8617209-b8bd9b00295a4b1180365f0f1fefdc98'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='b7a94401834f49ff996b3c3a5c4b8e10-78ad440d9e9a474bb4f3cd178e5e484e'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='0a7558200cd04743b6add4d243ad59c9-5ad9a91a85a440f9afc560732b3c2406'),\n",
       " Match(model_a='deepseek-r1', model_b='gemma-3-27b', score=<MatchScore.Draw: 1>, id='2dede87d177648d58653f087bd07c619-a9434d6853dc4c1b94b5707defa884bc'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='2948138341c04ecf840b681ed4a9103d-41d9be12d2c24a3e853af7f8c6db46e6'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='20949ac63aff4ea783767ad981742e44-30ad674a791f4ebdb65eb7d784080126'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='4c17fdcbea01427f9b70083d3eacfa2b-0e1ebc07e2364ba19a068db8a22bed23'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='4d067dc795a04958b6fa679a5e25c703-22ac707fab454e79a84df8c9a69872b2'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='4facb9bf780640a5984539e7fdf7f610-1d7e9571a60746fdb4d935f8ef8d96e7'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='78531d99ecb2486eac42a9ed1832208a-bbc88039ba8046fd860c6635ba3fa865'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='e4d88963aa45448db5950fc0ec89db4a-b70169545ccd45d7ade4367b902c9377'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='44cd341856cf4450b0d72b12dccdcf9e-a45b17a5dbfd423f9a4036d4e06a0e87'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='6c7a28d86a574c87bc91a34500388f94-db00e81738954041baa9d757c6db8d0e'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='ef9765b2c336491da42d6b2365a80a7f-90468041a6834078aa1222399be3e3ac'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='463df8a99d0d45dc8e9643b21cd08982-4131e3aa178b47f3a959f0992e81169b'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='868e1378d2524c46ac287b70605af65d-4389f7d565a4497d8b6e0fc40a16f45c'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='1938412ab93341bc905385738278f243-ed1c8bbd2466477f9bfeed5363c338a4'),\n",
       " Match(model_a='llama-4-scout', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='e25c81eab6914d3e8d9a87735f143f32-e6c391a577884da0ba13d7107973e278'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='command-a', score=<MatchScore.Draw: 1>, id='ef3ce546519349b0a96b9d2337e73e9c-b5412e1db7524aa8841e089767fbf7bd'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='a016714feb56433399429a05e8557375-fbd64e1cd4f645dead4a02f9b652ccad'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='dfcdd21e0d4f4ce59b64af539cb72506-91c1c513e6b04b0689df1c355c1573ef'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='cfe8b0b2204e46e8a04e287669a2f848-6311e55e16954e30963a30162cd71fb0'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='bd26303d87934ac492bc309a6f7be03b-90576b78701d4928910edcc50902fd43'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='8d51120b323a4a6d853010591490f458-69ba44260504497c87fab39ab8a2c078'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='3c60f5da61284b66a8f372780eed40ba-d982f6196e6a40a8bb276f28b6e0c122'),\n",
       " Match(model_a='llama-3.1-405b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='c083d301e54d40c3a9818f74a121bbc9-025a36666312421eb1d1a3d3b2d9c692'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='0924ade285f94e7a9df2bc45cf372d7f-fbac2fc9a7fc4248abf19b9450b90d7e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='af31e48cae5a493db60af8fee32ce80a-f806e3c8ee51402aaf3f41bafbff695a'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='31011273498b44a08e4566160ca50bb9-046986cf35bb4592b36c9f17ce25a0d4'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='36feba5b8f754993bb71b21143802946-f32bbe78c6a44237b657707d3b776513'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='fa68469c546c42eeb5faef0790999390-e68d8e78a12f41a1b9658f5292acb7d0'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='7be65c5f5a914bf1948f025ecf20995b-9136d8573ed5411a930400da449d01b7'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='b24506508af74294badb645075922cca-9ef55aef59604fbdbc7924fc224c7579'),\n",
       " Match(model_a='lfm-40b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='5115ca7463b145f3a3f7b464838cd83e-5ffd96f14ebf472aa906bfb209f3435f'),\n",
       " Match(model_a='llama-3.1-70b', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='3452d0d5b1854e7e926b54d7852da9a3-b1e9e899460c4ea8844ebc576b97614f'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='3161de376fdd40c0b86e418c48e55626-470b0993e4a14586bf10046379a6df86'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='7bee101a7869467c88fee3077b927842-f58953d3634642eb92c974256eae7e3d'),\n",
       " Match(model_a='deepseek-r1', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='5645b5ccaf6c4aa29c4106fdde278dca-4bf3bea81a28466789f6cfcc6a4f6fa6'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='a6a99458065d4df883d2ac85c204f3b8-bbfdf97228174f289da0d08a0a1b703f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='ea87e3c39ac548da8e2716bc0f364860-5cc567cbdff74eeeaa03defb7a7d372e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='aya-expanse-8b', score=<MatchScore.Draw: 1>, id='946833af58d841269341f9425096eb1a-524d818841e2457e8b99948855d88ed4'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='b09f9f8cd7584d058d33e2f769cdfbb3-0eb88771791443b6b74e39db1f182aa0'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='lfm-40b', score=<MatchScore.B: 0>, id='eafb2c321fb74994b259d36596041eae-a0d359b122d0486c962ff1fc28add85e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='8907907c3b004e21b7c5db8b3f7fbb71-3c6968dadb094c649f3826ac2fba807f'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='a6ff8ba433d04fd9a54111216541e031-e513ddf432104585a07a849c7de636f7'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='1d5c229d62e9432286f3230ba58a82c4-4b45c638d4ac4b7e90f96b2b11c0e1b7'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gemma-3-12b', score=<MatchScore.A: 2>, id='feb58d0699be408d80d9159a3841d196-bb5bf6ec77e3413f9bb60185c636da91'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='179e69dfa9fd4062b41b6c55d2503860-fdb036ffa2eb469bb14c4ddf0ab75bfe'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='4ef5ebffe837467596644695ceb4bf9a-3dc4e58911ed49a193d991b025904a52'),\n",
       " Match(model_a='deepseek-r1', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='74513b481f7a44dbb1c7b62a1b06d6d2-4734f0e05dd24bd2aad3eea4598e568b'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='47a56452e833423cb4018e7a15fec6eb-4e1f9ba4faa14ed8a9a41ccda80dca89'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='68a1e73a9458456d8b6de608ac3412e8-f5c36338e9c14c07a3641c110eb5a545'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-3-4b', score=<MatchScore.Draw: 1>, id='a97a7d9a420c4c05b7d47992f541e2ff-0fcd259df67d4025b524518932649c20'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='592cc418da5044bcb5d58fe88534d3e1-d9a41ba8fc0f4032bb073a3910202416'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='131a715f98b84618a76fc53981187e95-cea27f4a84a9470b975efd0d705b0b74'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='2a316c1da0654a79bdb2006a7040aeee-a26a5163fd0a4ef89113cf025ee81e98'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='470f2eae150f4e86842063ea57a7ab6e-4732c6770bd5499584dda34ef5fe4daf'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='b2cd3ec2dfd54383ac5e96a614c5f307-45bcfd3defd44bdebf5a6482d4972189'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='733ff9135bf04a129f1d3dc73193df99-f905485ed0c6412eb2ad961813a9b482'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='3cf609bf3abc470baf29d1a467920192-0647dbb96e6746cea495459d281d3d4c'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='c2f57750279a4e50b6695b6f12c83708-f0964ccc1a5c487ebb6286d688f4e07f'),\n",
       " Match(model_a='deepseek-r1', model_b='qwq-32b', score=<MatchScore.A: 2>, id='d700d583718b407c9babe7843fa251a9-35f887bd5dc849519a1a26762dd36fda'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='bd2435f2d2174432b5f88c71250d8a73-d8ce901a8fb049e1812d27fdf134b8c5'),\n",
       " Match(model_a='llama-3.3-70b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='32eaef340b8349029b80b06a411d6be2-769ea9a84bb1448ab0b64202344e9fed'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='qwq-32b', score=<MatchScore.A: 2>, id='18929a80e4ae4bae9c361b16281bf0d9-e753eab7476f47fd996db97622a0de24'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='3098b90408714db09866750a36776fd9-52c77d0365ed47ae8abcf48bfbdcacbb'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='67bf4fbe49204ce6a9c6d1136bed3d51-b7fff7cae00b4fb88178e8619e0631ce'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='b17ae0a2ca4f4353b0721634928cae0b-6f4a1e3c6dcd4650bbbb27f45cfdf74e'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='79d9a84c02984312b2c22471a4a6e144-964059e3d46d4565b869fbee8e3aa4a9'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='ee1b6e1bce314d99888cb67eddbf752e-a8ccd07a76314eb3b7796bb564ef3944'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='phi-4', score=<MatchScore.B: 0>, id='6334e23ec6a348abb7299f62e9418cf9-1707ab966ad144cb9c6c60d78dbe4a5d'),\n",
       " Match(model_a='command-a', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='8987a8a072fb43abb9ab60e2306e4b66-41534c3dca6347619d6dcf2e0b917a53'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='0a2c6094de6c4bf6b42e6f1aed6351ea-68591cc0d92b4b75bbe716e9e2735d66'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='e6c31bb10d854acca29ce57f362b5850-bc42c4b7abaf4c55a7e0afc517499ad0'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='deepseek-v3-0324', score=<MatchScore.A: 2>, id='a4b8ec25c0c84743bc7460e00920c49f-972fb31df36e41b1a8feb2cc8f70c78d'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='5af76fdba93f4837aa530b81e0433a7e-01fcd7002ebd47efa539132352769854'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='55ad8f34c38e41ffb024501bf9324eed-ef32ba33d1f546eb9e967ad1705f23d7'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='cddea30fe86e4041ba16c5280377f688-d238c4ba72c44bb2a9128bc4d600195a'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='e7a54f362d324ff99d48fb27b08ef328-fb94d2a6d16e44018e85a5ec41952af4'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='8a37ff46fea9416baff762886f7b73a7-c05ac3a8f59f4b9191fe1537b50d7e18'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='4edb69d65d7b4a53bbe91a5d294e6608-f5bb5314a4394b82991d668158d9304c'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='3cc72b99f090469cb5aafd3be8bb10ae-8e7c8d78f89c41d0900a62ff89968d26'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='48eb789ad1a24fb78beb041a68efe72c-6cb60f77b3604584868fab67aba2823e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='ff820bfc8b634d6f9ea9fb8bd3d99404-103aee6a7046445091cce1d59f916fb6'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='a6a76d7b89fb4bfb9773659c83675501-86540f15b870431b825dd8d53df5a40c'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='30863e054d4444e9a1adb36d11909404-1c513ea3bab64e939f6433e581b1a863'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='22156965aaf648838b3a6b2451ddce61-c99db2d2c3cb4ee9ae2757319985889a'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='685117072c724d3b910d0a76b4aa1d69-bc4bf223733a4d228d775bfaf4906f20'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='e0ec075b5f1f412a8918048b29a5ed81-9c95b32f3fe24da2bcb6bb212d1c43d9'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='ab5985ef847e4ba88e8ab0876c89f12e-3d502f6f1c8b4f379f56bc04a2bf546e'),\n",
       " Match(model_a='qwq-32b', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='4aba7ca1822f46c6b9b7da934377752b-ed482ef9b1fe43f7a49746f892888545'),\n",
       " Match(model_a='llama-4-scout', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='8e3b0b8d129c4b65ac116a5e7e8efa3e-4f4eb9a98f3f49f1b9b91cf07fb530dc'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='febd0362ef414aa1acb08a0c71a00e19-1395926b10124584942239e0a332df20'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='0aae3edf6ed44d73ba0cf6d2ac9dc36c-07f6ba37bde349f49ba0b764c37a96a5'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='b1194a45680b43e6a2831ff5d1da3ddf-bb445035ca634113b07da5e4fd89f415'),\n",
       " Match(model_a='llama-3.1-405b', model_b='phi-3.5-mini-instruct', score=<MatchScore.Draw: 1>, id='37b3fdbe0e704a9e81dabdbd9d2a1688-dd8c0f409aff4317a525ff46f35e67ca'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='a08ea7c54e76449e8db705f81c33a6d9-2472228cabfd412c9211cbb5acebfbd4'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='871802999c414bf0a16998bcae1eab8c-a87dd5b3106940458b5fc7b2e78500f7'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='f1c88b397dd447208e2c9b50827af8ae-3a3383c4f6ff4134b742680b68a28676'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemma-3-4b', score=<MatchScore.Draw: 1>, id='3f5179aa5fb749f094f0b7a340ebf925-1b2a4fde9cb342be8adfb2fdbbc64f8a'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='f2e018962bd94dc19177c3bdc0065008-6a2a135047f7461995701cf5ac3487ad'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='31a994a69e9844e5907b747b25a88680-bcf144b5a238410aba5097f0a65580f9'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='37e01c8233c3405b9709132cc5e1e344-735ab37ad88d4fa095c0de9957661b32'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2-7b-instruct', score=<MatchScore.A: 2>, id='220994c0278d41ac9a6117efade0bb86-cf0b58d1d687484c96a5ca3909eb899c'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='b7df8ef5e7244125b91b1dff4f857caa-0b650f8c2e8949268f11ee00c452fe52'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='2184004975e3484ea264941853e976de-edff7fb53a88408fa9ac0fb2dbad999b'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='257423f22bac4805bbaedfb20ff580da-33820fb4021642efb42be2142dad2acb'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemma-3-12b', score=<MatchScore.A: 2>, id='ede02fa6350a4482a5bc0b3b5d47dac4-c56f8107016a4d5493347c993d106b40'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='2bce3ab2a847488da2aa9bf2a75b90f7-cf9884a9b5094a0bb727b9a530623786'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='f53aca9e4df343d3816898d4356f39f4-151ca68866c946fbbf1a80e3fd8e15fa'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='3fb627dc299e48fe91c8538f82ee8c65-c2d283fb23f24d0cbae331a07541729d'),\n",
       " Match(model_a='gemma-3-4b', model_b='o3-mini', score=<MatchScore.B: 0>, id='61a98b3fd3824edba5b2ab958313d7fd-b9ca540c5e0647ae903b00068f05d232'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='6bc7768174de43f89530a77dbf1d64c1-181ac02124ab4650897b0e40b6ad0223'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='577912de9d8c4186a169d952347bee23-7155af43bb3147b18e71c5ffca130c2e'),\n",
       " Match(model_a='llama-3.1-8b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='0ef57e23964b42caafe5113d8b0b8045-d0889475b888474b92aa0652a77cfc7a'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='3957bb48d72844a4b723b2b20801f87d-7f55167a801a455e9370d295111138e6'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='9fe420ca622f458693e14a1f84612e84-5fa39f6d416343b68cce3dce829be7f7'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='06f7eecff6914aff96269481ea0fb832-99d058c28b2b4e3ca49d82476130008a'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='3636b2b733934ab9b18fb90e0cceeed7-4142ef4a62cb47539d8163c757d3665e'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='a05d15a19a5b42b5a10f32cf53f150d1-224de00c92bf4647ac94d5137e3c5a0e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='ded2fac8df9d49fd945ed862dfac46e3-0f09cc5936344f47860fb2829487d399'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='cc22ba8007c34bcb986dbfdec0f2261b-7889845aa71949c4aa06f555dae0826e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='phi-4', score=<MatchScore.A: 2>, id='086491a4907044539860f408f0cd02af-dc8cbba3921c4ef9b7bfa1aede5a281a'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='3f13014e7a63470b88c3ae8354b2bc78-19990238fe224b6fb814f952235bfb4d'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='fe725195ab26449c8910156cdbf84735-92b4e45b65554e368ecd403536d449d4'),\n",
       " Match(model_a='llama-3.1-405b', model_b='command-a', score=<MatchScore.B: 0>, id='8f79efc716f540618d6c9742a5cf3763-91b1bef3e0194b47b99c8c71810464e9'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='888c41f0f58448859cf75d219bb00390-8e2af453d1bb4bda803cdd1565385d63'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='b9df723265044e61a9804a8ac7b7a483-1110042dfeb247c29d48e7c57f314edb'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='3d68d6a3ccbc45169bd0a4eea7749ee0-70574e4377f04910aca258c047fe300c'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='a03cef08b36045dc9678799ba7cec259-d9c1099a2eae464798a29963fac17b71'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='ec814569c1c64100a4f2e7f02cfe067d-aa48006a35dd4884a6e6731f93d86fa0'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='5a9f85eef1b44785ac85a803f609ef48-f912989b67e5418f8d38cfa53fa358eb'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='lfm-40b', score=<MatchScore.A: 2>, id='2c6b7c2bf673489ca81cb7610f3b2b2a-3027d99ccbff43ff9db7d15d4bfb51f4'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='bcd9ccd719c14edfa221a86f9c96944f-865c80b6ed924daba37eb8cc60e0c874'),\n",
       " Match(model_a='llama-4-scout', model_b='mistral-saba', score=<MatchScore.A: 2>, id='1cf5f41514a64d66a7b17ad2d8860657-b7ac173b01434161b64613903940a2bf'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='aeb682ae70654e2ea159595b802db849-5f0b410bd5cf415288bab8cf37979794'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='1142f62e319342b5b82ca795456abaad-aafc0681ae9243338f3a9790abad3927'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemma-3-12b', score=<MatchScore.A: 2>, id='66f0e838b27f4f2b82ccf98b6bb6b8b3-732b194e620e41068cfa3cc82bb4ce7d'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='10fa493a13e84793a7e908404fc348a8-96487b55d29244e88a56da212d70ac12'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='c813226e159440a8a56c3b631bc50f6d-0ea3c1a1d61d43ea85568bdc15d1eda2'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='5c76e537c06542b69ebcaf7fe383ba27-198582bfb2c046a79809557acbdbf6c1'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='a4584a003b8b4bd08cb6429000583adf-c0b8b5dbb3f74dc6b6be39ab9def592c'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='93c28640cfa5407dbd72d201e328f2e3-fb75395f1dee42beb76c810d04004d8e'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='3b9d1b8fc699415da876f040de6cb9d2-839e94b85518493e8da3c77310534a2c'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='e8408515c9614f93b276cb57c1eff60d-fbdfa16c693e463a9f22f5ed6e4f82bd'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='7fab564b9e5b4ef49a4ec7c9cc5e0fb4-5f8f259d12dd486fae809b6c9289e4ee'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='ac3ab61aa51a4c05b4c897f137ed3fa4-889d8b7b0be2424b882dcd5713d9e387'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='42064fbb88ee4d5caf6418c2dbb65949-47ba3da6155b423fb98aaf24cc923875'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='0d4f377a34f34c8fbaabf2ad168a4442-aa521207679a468b850151a29f957ecb'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='5ae9fb7fd1a046c8a74a95ce0cc4bc3f-79587639a9bc45a0a3acdef5a7493cb3'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='9d034aa4215b4a55aa447b2829548a80-69ae3dab03044a23961cae93c178a875'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4.1-nano', score=<MatchScore.Draw: 1>, id='1fe242f02e454b039b258add3d31bf80-f38b9cd752e14fed9bc1a2a6b733443a'),\n",
       " Match(model_a='gemma-3-12b', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='d9f80e911a9b44af855839efb6d70f39-4ce251f768ba4bd8b7361b5ab9a76120'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='67b3cf5eeebe4d30b7a63fbdc9294068-69910b80ca4241399e36903ae6aee0da'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='121b53f4b22f49c28003b3b72780c066-154e9b9cdc324850b9473432b3abf5a8'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='777e0b6af3054560bf5ca78bcababa4f-741a375082604c0eb1c1e1aaca40d1dd'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='7f47feac7f704ad38bda7bd973e99f00-3afab9fe0a164d2ba6dd90bcdee06cf5'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='7dae174a9c6b40ddbe72c7245cbb4892-e404825c834042c38caace1e8e13a234'),\n",
       " Match(model_a='gemma-3-27b', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='deb29190dd624ff196c7d22f6bcb659f-8080225d6129454383aa21c4a937b256'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='e0df1dd549a94814b8954d5b9798ac61-4bfe905993fb42779aa3515ae8ab7eff'),\n",
       " Match(model_a='llama-3.1-70b', model_b='aya-expanse-8b', score=<MatchScore.Draw: 1>, id='e24543513ac049268ec6a7d9db4bff1f-051b1185c32b4391b82e02829b0911d6'),\n",
       " Match(model_a='llama-4-scout', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='88b5feb9b83a4a48a4c393e4dc5610d1-dba334ee37ea4f13843782c56c3e4e42'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='phi-4', score=<MatchScore.A: 2>, id='3353d1c0d2434e38bec1d4cb4f76bd8d-acbcb49499fc43f4a8316900aa167cb6'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='3a82c9c7705644299ac8065a68625983-3afca147521f4126a641ffae2680a106'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='4efbf49431294ca4a06d156abe512d8f-3deba8f1bfb84f059941a01103c4d177'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='bf595d78a0794db5ade884201a79a2aa-eee7f2559ece4e9d9bd249392a03505f'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='a279050b02d54b698de682f22d92d5d5-4b81a136c8eb4e4c9bfe8be6881bdb3f'),\n",
       " Match(model_a='mistral-large-2411', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='bd3f5358eec74ce28604772f6b70c56e-32ca68ca28624617ae9693b4bdd86f6a'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='f08139818c444294a258917b83bc4d73-bfe8bca7ef7a41369ea0903870bb3bd6'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='39d7b17ea7fb4191b7509a53e644a236-08745b3076414b828d4d63711a9b350e'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='080be136b2134ee788ccf488597d8351-04553096609148c4be5d3edca8a3e589'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='1ca4390a761741baac06c8a8fc6eb67f-f9e491c60ea94eec88001d1848985f96'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='5e496f21501f4291a18f056cdbe6611f-20c3a08d0f4241d6ac4ec253adf99e67'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='b5578eb70fea4423a05659e1f59f7c29-5b1c6226fdfb45849d77ec9475ad903d'),\n",
       " Match(model_a='phi-4', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='436e11eb628a48cd89bbe1e2c8bb2c58-fed5fe9190f947d9a26b45e7345876f0'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='329652d3f3c74858b72574bbcb5bd608-a71f918d4645433fa3a8d70f78db6867'),\n",
       " Match(model_a='qwq-32b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='d959f93b37024c92ad40fe3d2457005d-c4a0682a51d24f6a9fb9ad38f452bbf3'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.B: 0>, id='5cf78bc0a9da457fa42251ecf3301461-69141ff64fa34cdfa7f1a1dddedcd70b'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='22ff4155ad7b4d91bca38cfe0e04cdf9-c2f84f822b5c4730ae744359a96184ff'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='c52ca4bee70242f5b62356e88c7addee-0917f5f855ea4ef7a871cb9c20176504'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='5fb4355a70ad4b158b1f5d836b9b5ed9-7cb3ba4c54f246e1bf365d657bf73f40'),\n",
       " Match(model_a='command-a', model_b='deepseek-v3-0324', score=<MatchScore.A: 2>, id='ca98be5bb1504cc8a78ee307920f5277-120f55892e574f6ab2238a93715c3b1b'),\n",
       " Match(model_a='gemma-3-12b', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='98efbc5d6647406784e713539c34ae41-b44a87f4f0854c08a493160c571fc1a1'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='877b0ef8876446eda35f82bd7b322401-ec4d9711022a4f5f973139d92c46aa65'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='9cf7366d60b94fbc9e31cdb6e1b8fe95-7cb3bc3e20574ef782376a0f472ed7d1'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='5a96f57bea3a4ee0ba8cb095dc8b18f5-f6b8f4bb18fc49948dad819550f73274'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='794717537fc54f0da8b84c606bc94eb7-1ce3dfdef9fd415fb96e0316d2661380'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='e51fdb56a5be486590ebc30c33002c70-ad5cfe99c07941f2917f58f16d6f3a2a'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='7b692ee6f645498789a406f4bca3ade9-9aecfdb530bb429b94724b25d7b86522'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='5d251294f8d64d38857e89969286892a-ed85bee7237647ae82fafcddbcb90d72'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='033cb12bd2364ba19ac83ddd8458d7e7-38d5b9f2e77b47c9aac0ba7ec2705096'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='be62320e81024e82aa5d77b573da9ae0-d4a50e44a60e4dce9be2ac4d2a0686bb'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='ae824ea8ef824ecda481d8989c64ca72-03276a95edac4ee585eb9f282d79b423'),\n",
       " Match(model_a='gemma-3-12b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='04ec70808c3045b0bae7d4bfb743a9ef-2009c0e97dab45eab46a5cd1431c0bcc'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='20d506c59d144b958443de0c356ace75-8346de809de741c3a3b7abff1f527ab1'),\n",
       " Match(model_a='gemma-3-12b', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='9f60655d3a9e44f4afaf6f6004dde3ee-6935e3932a99402a9133c17a40ed491e'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='e9f97dc4a5474f6080fdca8655405fb9-b6efb06a84cd4f8f88e8a2b77f9907c7'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='c5413ec29917433c9286cd428989b39b-ececf1f55116492f8c75410721921d24'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='344143e1c493441fa56e2422c6074ea1-9eeabf8cea054978b65d8e788853f853'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='ca607df9431d4c42990df17acd982a72-796b1729583c4c8f9849c959f685607f'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='6a74d07de5124e3f8f072df9b0d85a56-657effd147124e0ca093b533a348ff2f'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='e4b9cb7c9bc4431d90653dbfee210d2f-6fcdf828cd7b41519feeaa48c37e6115'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='c37a0ca27e9f4a399873446cdb34de5e-e7e5a4debccc4deabc72504eeb5cdc73'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='0222a46082fa4da5903ca996c5eb4a6e-dc0aaad918204687a03cb21a28f0a9f4'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='2ad452fe519542cd9bb000ac6a4dc5cd-58b630c31b354db1b33d349385c1762b'),\n",
       " Match(model_a='llama-3.1-405b', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='c9d4c06fb1824056a91e7852baaf5ec8-c0243d17714b4f3cad0432e83994ce43'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='7247b03a4d694e8687f237845cfcec90-20e41fb4b2b840fb8825de6fa6cc356e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='7795cf76996149caa6656c2e3bbeba14-7a6b5f59aa7d46ab9d6757d3f1590684'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='o4-mini', score=<MatchScore.A: 2>, id='ca43eaf493c04cd0ad4e5340ec979b64-a34560e945cc4d9b91ea48915f0a4065'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='369e867d09e844febe3caf4648d204e9-7d4d5c8fc0b04367bd37daa3d69cc998'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='2fed86d2743a48a797e2f88cd19db4ac-a2cdb23979924dbd877ab60e70c0c002'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='c0584fb3aac34b36ad78fa1dfafe4a13-e10b1f9ea2544be39c70a622dae06c36'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='f97badd7c5ee4049a450bbcac536716c-9f45005ed05340839495e774fc4c38db'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='61218f0789254d498208e4f2a047f8c7-4012d7af6ac24b57a69276f392b4af1b'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='96cfd1ca18c6412093dd24b1651e965e-e7ae30c3d5b54b08ac44298b21873bbb'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='f706256816ca4fe7a04917485c81521c-41891afce20c4dbe87208da741b0f5ca'),\n",
       " Match(model_a='gemma-3-27b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='46cf5e6f2f5e424ca22d2999216da143-e09bb3b916f24438be3d245777cd2e91'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-r1', score=<MatchScore.Draw: 1>, id='9529d24552f24d448f6d9bbea8633172-8bd6cea2085445dc85c021a812c2ef2a'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='c95099c6041d4644afe39d394dfd2eca-ae1f0eea893a4689aa06e863801d00ac'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='d905d04452db4751b9284fb05bcca995-3feea0f7e1e743649df3a6d6e36eaafd'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='c170a6be935f48efa3965a1e62f6f38a-79bd2dfe36f740199c0056ea163fe748'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='9153a724f0754ee0a28b4ca038dabaee-0089a0f3e0724235b4921023419b3167'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='565fefd8495b4b0cab2787d81bd111f9-09ba84a9e5d54137a745a00fe1411684'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='e9dc9147105e4a8b81845aea3c2b8123-aaeecc1471c745db99cdbb4868deb51b'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='d2a385f8e9944f4481fad23881561cd8-d0cec398fbcf4597adfe29ec1425be8a'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='8337e841a5ae425e850d74db6f50ced6-71c0bbd78e7b41cb9e247c8940a870f1'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='a307f3dd79a442c1a0984e098cb5316d-d02e04c5ad9e433fb8a82d776185419d'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='aya-expanse-8b', score=<MatchScore.A: 2>, id='8673f53636ef496e9d76c6ccd3f69fe1-8a257167ab4a4810b392971411ba84b5'),\n",
       " Match(model_a='deepseek-r1', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='629e99268e89401ead1999c8730cbb00-9ec3d6ae429d4a5a9fd2b651c964178a'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='9db775b2de3b423f9fcc173bf91b9add-7ff1aaa376824b6b83e99b5e2f96d25a'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='b0af75baf5954ee28e2ade060a101ebc-3b9c2f36fad84c7bb8b2f9f88ffde7e3'),\n",
       " Match(model_a='phi-4', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='f50db54f735d44de905c807c500a3e31-d24c8b5c4b6a4417920ce4fa87cd37cd'),\n",
       " Match(model_a='command-a', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='4252dfd35901470eb12657df0cbdc94a-103c53c81c6745f098e74742186da4eb'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='345f60a1cd3b407288474845e247ebcf-d3dd6bcb2b444c29939c4225ab249c6d'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='2cb4df0a68894b3c8fc062b855ef5d25-8150588cb5e6463c921eca5e47bf18a9'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='353d8099a1ce4059a227f3c97808dd31-e0a873e64a9a48e69dcf3be008329871'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='34a8640ab6f14319bda370cd8b9ef0c2-11629062da414134850aec76bff0aed9'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='268247da47084dca96414a76e5be11a4-12ca944eca7145359d2663560341c556'),\n",
       " Match(model_a='llama-3.1-70b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='61af42846caf491f8ee812b25aff4c07-fc13314edc5c4728bbefb490720b2506'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='b4895d56f7454c1bb6337dd7f96d4837-a7b535ecdc2245229c76ac96b83d2e17'),\n",
       " Match(model_a='qwq-32b', model_b='gemma-3-27b', score=<MatchScore.Draw: 1>, id='6dff72152aaf428e96dd1af315e5f782-84d99435e2bb4a41b10d0fab196e94dd'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='ff89846518cf4f0bb413187fe491504b-27d80b8cfe6b4d75876d0923607da06f'),\n",
       " Match(model_a='o3-mini', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='2e2e456b1fff468c9eb7ce5d40b42d4f-12a41cbcb73c4e439ec949989a7e1095'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='ed11382865d0496d8357732513ece075-8ccf6fb5b0a14a3cb7ad57028bd0de1d'),\n",
       " Match(model_a='deepseek-r1', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='e7bde45393f542d1bad34ecb8e7e8d4a-1a9977a448854c558e9058f769c701e2'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemma-3-4b', score=<MatchScore.Draw: 1>, id='3d5730dbeec5441887d812bde0eb4bd2-19b504c400ef48abb6f9305ba213310f'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='259b851959404ef29e41ee9a4a2aa7e2-3848f1e84efd45ca8388ebcbda9d77df'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='0ef8c2036f6a4c699c2576cd4d1659e0-7d14d50f802e4d4087522982300db743'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='2a9e129fda6c415587566f9fd955ac65-3f60a9ae38ff4a3197d3b64acc373dba'),\n",
       " Match(model_a='o3-mini', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='90777e8b06564345adcec47dc4320b22-6f2744f1201b477580a19606d213c96e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='command-a', score=<MatchScore.B: 0>, id='3402d3ada7e54e5d86b1bdb45ca5a252-e88e84331b894c4bb3af75d4c93f486d'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='da10458bbf2d4e2983a144368551c6af-3d4b2828ed0e4c458366e7771a98e4ea'),\n",
       " Match(model_a='mistral-large-2411', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='2b1637a1f9a44a198dac4a64b87553b0-e94a767b963242edb85e5ef89efa9937'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='4bdf3fd1cd8a4887956d337f9e4ae859-8bf64f4984e542e89d0bd12b5e51881e'),\n",
       " Match(model_a='gemma-3-4b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='9f7d7fcbacb1455a942e5b364c8e2a13-eb3e6e5b77ed4dee960e776aa7bf07a1'),\n",
       " Match(model_a='llama-3.1-8b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='a22e93426db5468ca2b9e89c9ca1f92b-c52491e6956d4ca6b0be876e5d11f337'),\n",
       " Match(model_a='llama-3.3-70b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='55f7ac5841504249820a104f39be5c49-d14387b37e894f479c31019fd3c18770'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='db19ed5a11b94940a7905d7d0dad132b-8727687485c24293ae56b3536519e318'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='a769dc00678549308cb969e46dd84a04-c93f731c97b44b16b0a6304d91f00721'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='4c53bebd2ce449e8a2f0b6f74210d455-d8669b7ce2a14fe181969c4bcf342d7f'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='95eab76ca3a94a3e8db547c81d4928ab-a784daf86d24492bb575f8b930c4fe29'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='3395a41b6ac545e08e14ece93ec7539f-0e95504275bf498e9e44811e1276cfb9'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='2f9f1939c5384c89a61aa92a604522ec-d8a8a377d7c74050a62f2d2733276a83'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='80baef8ae8f34e60ad5c55aee8c02d4e-8fe2ba2f21014b11bd7222616cc5f97c'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='a7fb5734292d418e8e5034498742aa0d-48553c612b4a4390b22ece29ffb8ec96'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='0e6080763ff040af8407270a5c569f1f-afcbef23a54e4168afaf68efcf4e74c8'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='cae1acc5e31f452a85bf24773a7a42f7-b2799173d1b94d1ba564f9dea148fcfe'),\n",
       " Match(model_a='llama-3.3-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='5118b669ab2d410db52e78fbb30124d0-e5c07caacc95421e97411228aaabfe96'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='7377329361204483b04b54359e597019-2e6771e481db4b89af541cf338dee4ec'),\n",
       " Match(model_a='llama-3.1-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='c040cf15de064818a034d0ee60bd63bc-75fa3bed55bb4e6d94bc09a66b724097'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='d4abd887c88b48eb93c89831af550dff-2fc23bb6eeaa4d62a3bdaa35464fa696'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='80b020e502b24e7fb353716610ec1a98-e2a556794c2d417881f06ade15977265'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='008e22a08c9e403a9ec6cfae0b8f2afa-f9408159f81d4faeae98b905adadce24'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='1da3b5fa5d13421fa13d990cb0888bb5-73e1cb2d6a26410a9f5a748444c6eecf'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='38281b8494a647b381d6aae9cf8b551b-a16b0553d6894d29a27fdae304e2b63e'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='3a4d73bd15a84cd285ebd479add58f2d-94024b6a50f541439d02675f6b86742f'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='123b9852b08e45fbb879139a98ada42e-caa08205b27a46b3bd8846b33132b49f'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='93e3ef1e26e747b198ee6a09c6fbf8c5-616fef21f6c740f0bd0c6ee67b3859a0'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='c91317cc978942c5a03548664fb0319f-c51b3ba890504af2935ab34b30f117b6'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='lfm-40b', score=<MatchScore.A: 2>, id='7515e10baab34477b17b498d8b094374-9fa09ccbc89a4a5fa7a819c1e8042b40'),\n",
       " Match(model_a='llama-3.3-70b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='7d79500b43ce458b8307147e0dbc9680-866511892cb449568bc97f946615b945'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='bba7f3af627743f6a3d3e7cb0c9d4391-663adf9317034681a42c54d75e971fdf'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='28fd22a95e9840c79e12ee4f3ab2134e-ba46aa1a0f614318bba7f3098128e9e7'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='2b250f030ce949c39dd76ab264066f7b-77f2bfc8d8db411cb8cba460143021f1'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='fd2d51673d0e47cca78ac3279d822d65-edcfbb5048f64ed6924baac089f6683f'),\n",
       " Match(model_a='gemma-3-4b', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='9359d5cae6474c12a740f95e7995de31-379c21d3122148b6a97bff9685e11d7d'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='0a13bf1014154869b31e9f2e004b3a95-2aa8bd19f7e54d3f9ce0b6b5c0594a8b'),\n",
       " Match(model_a='phi-4', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='762d67e54aa1406aa029beac08fe93b9-31030ceb4eb04dfe98f3a8b2b90a5ff5'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='87e64b2008d34ab4b6cdd7fe746c4710-46a30eeeee8f41148b948c6204d61810'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-4-scout', score=<MatchScore.A: 2>, id='84cbfa3ad7f342188f19844b0a64dba5-6f2d9e8a58574b4688c251baa3cb4c20'),\n",
       " Match(model_a='llama-3.1-70b', model_b='command-a', score=<MatchScore.Draw: 1>, id='7ca2e6adce49447eafcf6d3168439180-089589814bce4a1b80c5baacff97b1e8'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='0ea142e0526b4f9fae2d68aaae86e49c-2700e62c913f4b5381a32431bca64ef2'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='command-a', score=<MatchScore.B: 0>, id='540e14d1730a43a78e094f292a25b469-ea1af2bbaa914b98961b7f4e849f5348'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='phi-4', score=<MatchScore.B: 0>, id='264c1486eb224e70bf1b4472c3a1a59d-d5763008986446598f766a161909812e'),\n",
       " Match(model_a='llama-3.1-8b', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.B: 0>, id='406c565c5a98457a9f355698c4a3e2df-ccf42cd87e0b48b6987e08a526f66fab'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='39ad4263500c47bb85a715391ae7643c-de99730f77fe4e43bcdf6a99e7ddad53'),\n",
       " Match(model_a='command-a', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='7d5043327bbf4ea08df2d6f20955897d-c2ad42862a4441fcbacb4a6a60e6c3a1'),\n",
       " Match(model_a='gemma-3-4b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='b7b9cf77679a4c94ad30d687c304ec77-19c0ff2b362345f39e8ed91f25022208'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='cc1fdb6d440c450c92cf7ad8ef5ad9f9-9b9e770f3f1841a49b3a6c56d7861ef9'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='phi-4', score=<MatchScore.Draw: 1>, id='c8739fd146b54d68948301d6f7c49f04-347a2abc9982423f9c43a3dcf9b6cfcb'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='aya-expanse-8b', score=<MatchScore.A: 2>, id='37dab3d210dd440cbe65f1bb800f9c38-e6c3914ba8e340878e08ffdc7788a8cd'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='87e5d28e4d544e4083cb821fd6153a7b-001867210319495795dafd8628d8bf1a'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='afcd0d358bff4b75b071eaea7a526ff7-ef16d650d7c04035a1b50f27129696f8'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='b46e57521f574e4c9b6045e0d88115f9-78be4278daa848ccbe05099f757be956'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='63d1edf1826a4559baeaedebcb58c757-37b6ff886af646f1bfb83b9f49d967d8'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='0d1c055750f34548ab31d48ede1a1ae4-07ae838aa611451284e9c0e41534505c'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='fefbf1a3690940f4ad08e8ca513e7e61-9d2323c7ca974c46ad3e5d060cec5e69'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='f554a34b87774cae933936c91f5f508b-510e0f66722d464395914b6cd442c3d2'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='307a03f1a57e4f1ea7fdea5b472c23c3-c37601f446f445e097d86060ff3616fc'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='49b4e59535374d6f94268628a9c526f8-52276e68e9ac424997669e64a7d7e41c'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='lfm-40b', score=<MatchScore.B: 0>, id='4eb019eee0ff48e09a53ae120bb59f41-22f9dfafd4564154b23a1c78bcba0baf'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='0e3de5137b7b42c2aa4d587f47ec4b33-38db53ad9cfd44de9ee904e4be52b105'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='c8b6812fdd354481b2cf9db595ac3573-9cf8cc45285b4595b5c17c5f322c2446'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='93eba60d09d6462d87ff94661d3760c3-5dc6b3486f8c47f09da637bf6c502950'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='8fd08fd7b17e417c9827471a34f03ea6-fd66dd1f64a047a5b2fc184f4c881f54'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='e317b95570d544aa85653472c8932872-70fb4aa204e8409da5f31f6b1a450c95'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='aa6b1510729f446d9f5bde4515fe0fbb-a81f460d344d480380fa591faa0d6ced'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='6df91383e4cb4523a35c25fb2429a237-0095d2d82cae4aeca35125a6a3184880'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='5199497e5b7d466a9fc2b74e358011ef-a8ff42b20b81452e98d49e051e12ee14'),\n",
       " Match(model_a='deepseek-r1', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.Draw: 1>, id='1f148bc914694af7bc930a1d0b6a26fe-41eb09acf4684a0a908094207c5a5fa4'),\n",
       " Match(model_a='gemma-3-4b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='87400d916e504835a34e35b796712a31-0d4e9c081f7a4d0bba71c1ada44fe88e'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemma-3-12b', score=<MatchScore.A: 2>, id='49b82e9d33da4fe684c19b0b97bab11a-21d9a4f2ad1b4fe2a4fb6269152395e7'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='42b1cf63c6694de3bd2dd003cb090709-41ddf17617354291ad7ec91c57ed8f1b'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='0375b3c6ee2e44298883d79e895678c8-fa3f072372cf4701a33b90dbfb62d278'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='538bd35ad84f4c10a019f99fdc068c26-1e5e6f09da8c4befb1488aa3fe556499'),\n",
       " Match(model_a='qwen2-7b-instruct', model_b='Yi-1.5-9B-Chat', score=<MatchScore.A: 2>, id='e0d7730f42cf484fb781911bf1ece984-cf74841525754d68bf4ccae62b60ee3c'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='4607d103e5094159955b161a88eba4b2-85b3761751ea42a6aa799ccf80b496cf'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-saba', score=<MatchScore.B: 0>, id='7f4272a43b384ff9b0e85669f6ca55b4-ec2c899eb1544ccc827e8207226355c1'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='phi-4', score=<MatchScore.A: 2>, id='a7ec6f5bca714922ad1f3adcd5b7bcd3-3f587440722b416e95ebe22e50f523bd'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='fc5e4cc531af47ad95a1b0fa0de1d139-04fb25ddb65b4c7cbbe1a1d87c7d30cd'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='65bf75d5c15941438c787f23e22c17cd-91426c3a8ed644418c84a8c29211edaf'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='f78c693d74f64c06892ec553b217bd1e-201c47895be546bda99b0a05774591e7'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='2332d7c73f0348eb9e94e2111f1cb627-8c53b48ee09e400385d11f9bd45e07e2'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='46837ba617464de18e8f7e424cf652a8-8a8303d27df343e78d863e7d0860704c'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='f496967c9e7c4bb69bdb2c677de46076-a548f75aa17f47c1936e0b89380b3d08'),\n",
       " Match(model_a='gemma-3-12b', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='1560decd5b2f452aa4e917651f1111f6-0de9726875514345ae0f246f23e6d628'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='9c5fcc37f332452ebf52ab24925c86d1-7f254ec5047847e6a98cfd9ea6c2a33e'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='51843bcff0814bf2a96e2d2a0bd1a271-9ff462e28ca048baa2ad7fe4949615ec'),\n",
       " Match(model_a='mistral-large-2411', model_b='phi-4', score=<MatchScore.B: 0>, id='0fc8ddd15a4d4f36a2f655291b13445f-5f9c2c2fb0f0427dbbf1aaf978c90d78'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='13ed9222b2964e50b9915d371ebeb7f0-917031ab71f54c83bfe7f12fc7ab6c38'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='4b4a1e64708f4b93bd1f150c61aab175-594c7c5fb9714c3889914570ca51a12f'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='58ed28e498f9493aaed94f2a116dde9d-28c91ec814d7444ebff50a5b9d7b86e3'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='34963986f30e433da077d284aff88e02-75645d8709924f1988376a8c0f6edcce'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='3e3d2c3e455442faa4663fec3f8364e0-cd4c6821e6dc477bb96f9f50a0a7d491'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='38ac2041d7074a938a013cd56f71bde9-fe0c15b64ee6454d8ca30157cd2c28c8'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='4edd422585ae42ad9788f62a70f3a07b-15c4521ac69d43f5a5d8c9f5817a6c7f'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='af5cee3a85f34b5e83861d4e9174d064-a178db0a77f4470d9b9fdd77e6970700'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='8657fb33a5dd44a9afd2baf7e3aaa749-b719b747815b447a86e38b7e1cab0a67'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='4f95a4a7aa634a4a9282f1c7bed41224-7f5903a7f2dd40d7af22d88e79dc50e4'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='3a8fb442bf0745128aba023e73cd7429-e14e8864d0eb48a68474e8a09197936b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='a6e4a2091c814f92b1b3326e3f9af6c9-516f2f90ad004f29808f8ab15d151945'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='5a619b57a3a442f18458bc1eeff04311-91223477160a4cadb95166c33af97ca6'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='46d6bcc34a1946908febac42c0c7bfb7-c6bcf0f7975844ffb59a06d5cbc6608d'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='9c3b3227aa3d416aa223c446b622c926-36db201672934c049bfaa3106ad34cdb'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='9d3732d3ad41414f82a2609e3f38e55b-8e3e1388a85f4d588708f5001fd2c494'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='fec71d2bfc964fd9a2bb427008a595b6-75b90986dba5473daba09bed0f3e0baa'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='lfm-40b', score=<MatchScore.B: 0>, id='2c6df8ec09bd4f548fd085cd745764c8-7173e1145dde44f585d5e49168afd054'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='6ebda312681d4334a919622efc9c995a-75ca9caf7ab9472ca6c50c6f1d0bfebb'),\n",
       " Match(model_a='gemma-3-12b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='7e292d2a00e84961834bb12a6ddcc273-084030acfa75492d96d451714443fae6'),\n",
       " Match(model_a='qwq-32b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='7be3e1f64c9f41779f54a2b02f7e637f-204297ca9170401f9d0054d2d32b44a9'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='qwq-32b', score=<MatchScore.A: 2>, id='b2947c944ac948c0887ed24c5ac7a546-bdc5c2f53f1b4a7e9da2d4994ed97505'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='f2e17622e9c64ed1b34b2e6eb8717d94-16d98ed4cc2a4862b821345bcdc5bb26'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='d5f975f3537a4e68abe05c033d4776fc-e0c740ef476645eaa32cea929eb1eec1'),\n",
       " Match(model_a='phi-4', model_b='command-a', score=<MatchScore.A: 2>, id='f658d8e3cb30419aaa1c7248d885a882-55593510b0524aee98a11587346d444a'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='llama-4-scout', score=<MatchScore.A: 2>, id='7e4cc0deee8e4017bd68d060e899b032-9ecc81827fba4b32be9f85c0899df191'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='8347a916176b40b4b46744ee99fb2b6d-a0a61528c3bb44829e82bdd332a1b14c'),\n",
       " Match(model_a='phi-4', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.B: 0>, id='69cf7237769645f9bf3f8fc60a96e43d-a22bc8e46e08412288980d14b7667990'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='06fed55fe9ec4b0ca44f6e32d5e6070a-b9ae9ad20e8347729c87e761a28b27e3'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='80046c8e96ed445daf44214a044fe704-badfdff05fad440c82c8eeb888dbc0f9'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='b4f6283b9d894f2485a327ded30ead9d-0edf33be40054d8e920188ff3300d1c9'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='o3-mini', score=<MatchScore.B: 0>, id='f7008ebd9b10430f8a1e39b609a16dbc-c7859bb2001f4caa86ec807deaa87c63'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-7-sonnet', score=<MatchScore.A: 2>, id='8f38c79c78404cba8f68113a754423bf-10dd2d5f9dc640e0b46dce03fa83de56'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='fd63d826ee93430caf7d56e3c884e0f9-4eceafa503944259adc6b41d5c6c8c61'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='e1c4419f77fb4c58bb66770e861d2d16-113e77eb0ff64cd7a3c00e89788758ed'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='4a5dc741829f4cbea8dd57eb98e4c9d2-2f0a464f049b4f809e7d84459032ebb0'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='2a9813589ae748fe97290378118f4ede-dbe5465b68c64057a0c884aaad0bf3ad'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='b9be9abd43f34e4ea5c7fac9c5e23e6d-9f5ec6d234e7434a947508d979089f16'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='9522e8a143604b879ff26fe2432ddcce-7f04047c5e274dd5b388482ddbc808bf'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='b022f696318d413f82cfb29fcd80cf79-ad132bd73cdb420f95dd01411dbe7bd4'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='25a8d05ff32444c9a307ed7432c82a99-ab1c9cc455204fb88aae1faebb72fff8'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='238ef06c4c6144669f055b440fd13aaf-f2dfff05933f4f4a90f7487135cbb8e7'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='3a64bf32a55f45139153f45c76fafc26-b603066eab144e8ca127409dce85338a'),\n",
       " Match(model_a='llama-3.3-70b', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='e67487187f234fefa06175cdfd5a1f9c-a19e982a8d404c6d8103733f6c9a60d6'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='677cd7fb3ea44ed59112b0a31c34f56c-a0c22ac512d845ccbbe6fa26c36f2f3f'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='45be75fb17bb4b668822501bd15e7545-6aeac953229d447ea422c700af5ba6e9'),\n",
       " Match(model_a='llama-3.1-405b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='0c41c63064184eda888d65278a477c71-f686ace3fa154e768ad37e293dcf7061'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='deepseek-v3-0324', score=<MatchScore.Draw: 1>, id='365fdaecbccf4fa194211eeaa1eca54f-d0e3180e068845f9afaf0c858d66214c'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='deepseek-v3-0324', score=<MatchScore.A: 2>, id='719d8559747449f7b5e3ad27f54a6479-95464c05e4bd447aad81ff24c8e5615f'),\n",
       " Match(model_a='llama-3.3-70b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='376cdc61b10d4f4a86ec31e45f35fcde-b7495395d5934d8a8e7aa866e79add18'),\n",
       " Match(model_a='phi-4', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='948e80e2c5b4497b9f514619fe5cbe52-0b3471944aca430dbefd530ea8129955'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='76367e210be74dc99c48c9ec813acbd2-fa8d5224263b423ab744e33534013bdb'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='ff60e30fae3b45128025ff69412419ab-f6f6d7eeaa1c4b2084913cb25ff6c155'),\n",
       " Match(model_a='aya-expanse-8b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='5a65b616eb2240739bf8cd645c1b3294-af721559235846c28a98a4b92d3f11d5'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='phi-4', score=<MatchScore.B: 0>, id='d15782b03602464882237b1cf298cd4e-260a56ec3a3b4e3c8a90c02492c26150'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='d50c2761f88245ec988aabaeeb385c66-9824585c74544c3ea987e0a7b457f872'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='6acca403f6ae42d1895226e38e3ba7b2-459abf37f4d74fc9848ce60d27a02d72'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='408ec8b98aab4c4b9ed038aeca674d3c-e638c1e4d6204b14ab90628ea100995e'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='cffae1786f1a4ae6b05e5ba9cb8812fe-e67357655b0c42b9b9d8275892a226c7'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='phi-4', score=<MatchScore.A: 2>, id='04c79b439e6f4b6e9af233600b19dc52-1dbcd1b1e7e34fe497c3632192a2c7a7'),\n",
       " Match(model_a='grok-3-mini-beta', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='e422e781820b4aedb395cc6dfa8da6cd-785d5a0b9c0d4473aeae88e793973eaa'),\n",
       " Match(model_a='aya-expanse-8b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='514cc500d8f4474caaca5752ecb48472-b01733931f9843dabe167f1ea0735482'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='jamba-1.5-large', score=<MatchScore.A: 2>, id='911210e85f834c18960ff629fdb587d0-61ed27c812d7473ea3987fc0fd726220'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='dc4c59bdb1174f758eb7c32375d1cf98-8b5f02be1a7a4ac3a077769c886f9975'),\n",
       " Match(model_a='llama-3.1-70b', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='663952c2e2094414947839adad906a6e-259da1f011a444258af3177ff471de80'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='49b90c37f270476ca56d347082426fe1-600200e1d2c74f7594ef5fd8a53c1ea7'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='phi-4', score=<MatchScore.B: 0>, id='0810206511ca4076a9ea4d3909a0a730-26d1c359f51a4fb8807b17d8a6f79871'),\n",
       " Match(model_a='gemma-3-12b', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='579eaa213ec14808910f6bf5e8be9d1a-a17e559ec33348d8ba4d61efd16b95e5'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='6d81ec980b6e4d7ba41e316d39025b13-c0be1808d71148d4864796bcbbe9e830'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='a9f5a7953cc54ccaac671c907f939e43-4edd71edbe554356bbb4b643ceae2f4d'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='ceacaa34bf1d476993b9f9d95eac3d66-661cf8506d884bcd8a17938b82089eb1'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='grok-3-mini-beta', score=<MatchScore.B: 0>, id='69634390917e4ecc90bef766dc908a75-3301becd5c0f4ad08b3c2efe9bf502b5'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='fa409fe88ad34f1ba7cef73301811039-312446e30ce445a6b0f37d754de9dea2'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='8338b9a0f9824d07bd08cc574a661fff-0291fab0a05c4f2cad78d2d85bfca4f2'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='lfm-40b', score=<MatchScore.A: 2>, id='bd7ec5b7c06548ce9dcbeb6fc2a9a7d2-54fa97bcbd204f248c8615dd971a2ac7'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='00f6eea49bd54aa6a3cc2a32e80cac0f-462def2628c14866b8e0b32688aeeec8'),\n",
       " Match(model_a='mistral-saba', model_b='llama-4-scout', score=<MatchScore.A: 2>, id='b0d42f4cf40049948f92e9eb3de5f6e3-c49e031811c5473fa08a8dd0e20485d7'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='6c7f753b08bd40efb2150b3a6152959e-c44743a38fa04f5eb078a338e471dba3'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='c20d945142ff47aca199c6c12d507f71-59557efad4544a00a82c17d9abd1a856'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='qwq-32b', score=<MatchScore.A: 2>, id='d5ce06daf0364d548a7e59e19928da1b-b6312faaebea4d94a384d9d84777e882'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='e6875d41dc2646779fb9c938bf5608e8-c9252baee9d042f78cd3cbc3c3540fcb'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='79e6e684b53441b4b11e6f265e939810-9ce4bdffe4a44669930dab31cf9b64f9'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='d0e9c73bb71e46fba7d8509a7972dc68-08248e2897bd40459d9f83fa769e0358'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='e3d1915de0a44d76bcd70e3d59c5582c-3a702fe024594654b5da65fb4ef2341b'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='ada541381d31414c8b4c2f712f64cf31-d9f1412f304648328e4f3c510e3549af'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='81e92b4129bd4e4599280edf75369b3f-a4dcab7e60024ea6b1385188243f293b'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='0e8bef9b9fad410ebb4012780ed928a9-451f82a311a54b52b2ddcaaac10c354a'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='9a97e0fb5d274600b88eac22569bf311-c5b68b9da9514602bb7d401b41fb16c7'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='a6c0d39485154bc1869ecd400617dcd4-4bd78ae4f39b4f21aea0ccf240c5dda0'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='130e8b6eeb924919b1a0247fb41b282a-27509ee99d5941be962a949c0274b022'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='2c0e1ee0a8b544869dcdf1ac941f46b3-1c5bf5b561b3450d9958445ef725e10d'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='7a0d6f4dedec416a87bb644f09352464-14337ce2d94546fd903cfb1138354738'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='df8711332adf4e1b99b0d3b21fe92685-322abd730cef4b4eb0c6240cafd66be3'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='fb9e96a7258f4f8bb112415f3879c4ee-8cb7c3a6bac6488bb0753f7fb8ce6211'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='d221963925504eb6864ed7b42ded2bc2-66611f27557548f2af618b673b565059'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='ce89b445325e4c74b9f2562e24de071f-5390292f8c3e4340b406c139e20b277b'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='0202accb49164302972d0b17870a1aa2-2a22b9770d344b35980f8172752e1ece'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='bf1b680ffb834e06b442b28f1bcf3ca7-425c0f83c65644759b6c5e5c56d383e0'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='e7db3d65ff1f47a5821ae7ed0ab013da-6fa13cd652424f5d835c6abcacf61c2f'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='45b65eadf3ad4c9a825699ac7d3ff152-d86336e55559429b86c236745b6657cd'),\n",
       " Match(model_a='gemma-3-12b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='0b06d45feb9645d6b33c3f591e626bdf-216d9a3335254b859fca984a860147a6'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='qwq-32b', score=<MatchScore.B: 0>, id='a1b9eeaaa4ea46bcbfdc12d22861c8ac-8308c620e2e54ff0ba82b042580781f2'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='4dc7ceb5460046658c90ca12ec0b3237-7e828e4378d044bd8110d1ba00d1f29e'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='942ef2178c874dfc9a7aea8f17f8a3aa-ad1cfc6099f24aaf86feb85a48a6d03d'),\n",
       " Match(model_a='gemma-3-27b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='0763f7c946d244e78c23083add97ea61-90ab8939b55b4871abf04ec9307ab73a'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='35c5af25aa714de3b807adeb50933d5d-5b7c78878c0945949bb5ab246869ca5a'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='57bde0c53b854c57af9df6f33b1f5f9b-33dab9cef92845329041a0eeb9146cee'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='87ed7006e4e145019530b958c9dff1bb-5f0143b2d0dd4ddd9b29cb2d322969b6'),\n",
       " Match(model_a='llama-3.1-405b', model_b='phi-4', score=<MatchScore.A: 2>, id='f54f428b53e046789624729efea422c3-b78f31a0a4a84577911fff76aba75dad'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='e086eefb7b4746f58d6e3f1d30388662-cea5cd1ec32e40f2b34436b26e25f60a'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='5b58b693aa3048dba40f3181cbccbc47-67735c6efaad4213bb201ff9594751b4'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='56e9ea325c3a457989ecaf4a995e2729-70c65558dd7f42eebe6b660f80b8ac71'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='8505749f1d73426484ca005ecfd360c0-465a7778bf4740ae8c3cac00a95dff8c'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='11aa1a8d733d4ee8af33c6c22deff4f9-db2b96d030a040718e15d97f9f7f9fa9'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='2a9b0978bd2143698cb4fa8c67c51917-ff301ec696734b2bb8d276850fa7e63c'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-saba', score=<MatchScore.A: 2>, id='209ff95ef791473fa08fe16b49fa0d72-a5d46ee938d04bd7923b562b930e5bb1'),\n",
       " Match(model_a='llama-3.1-405b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='f802f2f0e6f74ad08f5365dbfaf02198-c8f3699803f145a7bb97cea9553d01eb'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='68880661637642a4bb00333dfb189e9d-8ca2b8f7a5ea4b698fe1f3a6100462ba'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='3a90e35cb52f436ab081860f631af1ce-279a9000ffc44d9a9fb150079835fee4'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='771b35f5606948cebe2b6be148b74f51-0c790876f9ad409fb1582273429a1c92'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='df86c5b78dff4cf9bba7e83e211273ec-ebbfb6e89e2e41fbbce7feb948de5d91'),\n",
       " Match(model_a='command-a', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='80f455addd29447ca9f6fa9e61e9c0e5-aed9b82329ac4850a04f33e759ef4807'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='a9499f7cc48442c1a0c9855afbe710fb-46e2340a327a49e09c9091a35a73a166'),\n",
       " Match(model_a='mistral-saba', model_b='gpt-4.1-nano', score=<MatchScore.B: 0>, id='e539fc9c087d4ce8bf0f7cb5ba3aaa3f-5215c7aa1ea34f8988e96595d0c741a1'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='o3-mini', score=<MatchScore.B: 0>, id='7ca29c8e77ae4ec3ba87010003c1a1d4-9026bd1220084f70b5d0e331b1242786'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='3810d666fc26438298cfb6bfd9082abc-b55bb98617a34a0ebcc4e2778176588e'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='8ff2d13b664d41e3b1a5728b83c860a8-0ef67f70f0a2435d8bbe9bf74c7e2b0c'),\n",
       " Match(model_a='qwen2.5-32b-instruct', model_b='lfm-40b', score=<MatchScore.A: 2>, id='5c08669bb10743d8884b34d9fe714130-db56b06b1b9e40ec8dd2b3d97b941b44'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='c05a5d580d81416a81766784908ed3c5-7950d20181fa478aad4bd613097d1099'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='41205cae2aa642dab70ba817d052a717-1d4b8d7cb1f948189a0e4f6a6398c4df'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='7fe1df52ecbb4e12a9ba36c3af6659c1-1712790f0a164a45aca90e5f19883d47'),\n",
       " Match(model_a='llama-4-scout', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='c5a1b0270dbc4b85864d0464f7b39911-919c4833eecf4d2c898353f45a1092bd'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='5e710d0fca974a668dcf8288b65fb24a-7908d41e1ed343e2af6daeb7e43b099a'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='8da163262fa1490ca3936319fa931fcc-ae2cbfb356b940e4b2f1b6decdbd412b'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='claude-3-7-sonnet', score=<MatchScore.A: 2>, id='57c22a1194564b92b3adfe7620b21e16-4c6210a1231846af992f7fe5499355fb'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='632800f876414abdaf864725c044d85f-196cf51a834a46b79bb4077cc3c32228'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='0b11aea0a3684d6b8e753f4e56e23984-bd2a9d6a380b40c3872e0b27043d3bc5'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='9e7e5ca3de304be18bd095bf22013ce6-c0334a4a0df44c6aabbf0c0769628a06'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='0c94863be45d4056900b3d4638535f78-9e3a97b9d3cd4fd7a8e6b991d2f36259'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='phi-4', score=<MatchScore.A: 2>, id='d6969d51d2fe4101af23912991a3a9db-ec1cf226e4e2426ca48d775abec24cc8'),\n",
       " Match(model_a='qwq-32b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='3f3c49eaa44b48609c568f9b2790f82a-d332ca2459b547d2b2565ae94abc53b6'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='77195e88f72d4964b8c8096261544071-15191fc82cc24a99913efd52e27e22ce'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwq-32b', score=<MatchScore.A: 2>, id='d98c67f3f38b47f6bb234340cebcc0d3-05f03d0aa7b14304a56b71e3c2c9b17b'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='652d338a889d41db8105643d1a33d386-e8fa14d9c0c543318262395475b8ab5c'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='f06bc00016774873bba27edb15c27a13-50ddb062955441e497d6f546c21c1505'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='e770a81646a9415682e3fc524f3f57b5-945cc0dc8a7f4d50b2f0b6553e02c93d'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='4e741be239354968b3535b8aac607d16-6fe9d28f3ea645e6a46661efe77503b2'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='b265c775429547598756d68928eb3a09-30405851145b442daed2037635a18bcf'),\n",
       " Match(model_a='llama-3.1-8b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='cb51e3729cd64ba3812b74e45e9bb37c-d3759b3e65b24b77b569fca639438701'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='09b4dc4bfd5b437ba641bcb748b85803-7c39fbf74abc418bbd1aa89b39af269e'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='47d92f5bd55641ddbf99294c5f6be2e3-43fe1fab1b5e443096a1e0b7ba8c6de1'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='ca9beb0f973a484d8c415f5f04592d1f-ae15636d345d48beb2b3c4fa94625142'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='315b67e65bbd4a5a88af3b32b5fb5bf8-3a0066b6b45d4be2b00aaefb457cbac4'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='7757e1ec85de46f484ae62234e276fb6-e7014b9386994440818c0f5529d6cf03'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='21b8fed856624eb9b366f537873eade7-76c7836f4c7140aea5920d43a7cb923c'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemma-3-4b', score=<MatchScore.Draw: 1>, id='ae8dd1eb28104c9c9cd47471dfcab3b3-18f4d9666b1341fd8d5e1f6bc1f666cb'),\n",
       " Match(model_a='mistral-saba', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='0745c00039a44089ad0f56ecfd3cbffd-995f674bf5e14ad493d1f608052f8dbf'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='c24a578cf18a4c47869116e29167d0bc-e00c9a62949a4415a0e275cfd7d3abfe'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='937079976cc8417bb101c4b247d0505a-64149f9952584e2487a6b5b8dc736cc5'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='83aca03da89a4c80be0fda07fab4711c-2da95ee9c8db407ebf4789b0fe35b9d7'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='d4fa72bc2e23470fb287c2968ad975b4-c64906b0a1b440d792b77382751a1d38'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='lfm-40b', score=<MatchScore.B: 0>, id='4102796cee9b43d1a22edc9b6cae53cb-74762799415b4e34913c880f1a96f218'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='7d298947e2c24defa30d31b4122e78bb-246c3466d26449ec957dc18377eceec1'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='4fc8d79cc4f64c66940ee97e3b3e1b62-15d9002fb97b4f6c92b59e688f9989aa'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='58a7acc07aac4892a606ebab1939bf70-701d2d654f9a4111a292f54b87fa122c'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='cf5778445700483f9044f4b75e4ce012-2825de30a6554950b01d23ef2573f5a0'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='e9da202201ef466297594a879fb4c59d-b03c54d8688842c5bd576bfa14cf2ca8'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-4-scout', score=<MatchScore.Draw: 1>, id='78d3837e5fb94cd5a379629139c0b92c-501d783de20348ba97ca9f47fc6a5c99'),\n",
       " Match(model_a='mistral-saba', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='a6faa2be719b43dd9032751b9594f205-93c7510322ea4d8fbde5b470a8caf4f3'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='a01b2bada3ee4bf4b073d8c1148f8f05-eadd3ab5ce174153ad686bb4bdf897db'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='phi-4', score=<MatchScore.B: 0>, id='030d5d1c7cde45cea6d442edd04ac748-90ae49f3ef7c4a708358ad8488a25466'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='e8e1d8b033d845b79f581f8681ecb30e-02d13d9a9caa4f0f946b60412ef8326f'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='phi-4', score=<MatchScore.Draw: 1>, id='e57cc308bbfb4bc08e536b3022adb5e6-9a0d58d8b64c4b08a6a70400aee49593'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='3a3d2025b0ba41a896a3d68b252d5849-91c77afcf9154faa9f7ec558d8a7e2b1'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='05ed566cbbae4acf9304781059afca00-84203189c0444b93a26133bf114e30a7'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='896b65609d1d477a862d1791ba892b49-790a5eefa3db434e993adbd05fcd2ebe'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='60adbab6f06f4f979c464fea12ddc9c3-ea971090a64546e49ff870310fe9a770'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='1572d3b6a1d74c3da832d93c993a26eb-56758ab7727a4c778f39c041b05d912d'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='d8b33f2613c84b73ae84aabc8094f887-675c20ef9f244679b6aa6bcdbc90daae'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='ab4c4f32236c4d829b39fbd2b06b52be-8fce42c259244d159cc2e1a0bbe685c2'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='c667aeaaddf84e9ebc332eea7d566816-ad49803c1bbb45ce961c0b34262c5d6c'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='8fdc73d265cf4749a050776ac541e826-1565a3f6733945318e28f7a984078529'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='7578848d9bd04fa4bbeb8560a7bbe83b-e48cb7fec49c4e96ac77956e9ea5f29c'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='c6807eeb43ed476aa9a3a5297a6d1b60-dcaa2260aaa84d72b2918bf283f01426'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='320c1cd79cd6416985b3fbe152fe39d4-50399c2cabdb4fc9a512f00801c2c145'),\n",
       " Match(model_a='command-a', model_b='gemma-3-12b', score=<MatchScore.A: 2>, id='45c4d095ffe347ff82ec9293d2b4141a-fd167ed3c8e24850a21f9c6a3feb1efc'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='c74468f752bd428ab2220742ead598e0-c1f6a42d35ab46159957db0c81d37b57'),\n",
       " Match(model_a='phi-4', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='937bfa50889549ac9d76506b1b209535-38b651896b5d499e95b39d54f711b69f'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='fb72de8964594a908e0693d54824d7f6-c8165165667a4da7a33b0fb5c67bbc80'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='df7839c7712346fba7a1d6d7cc97d3fe-01c9592264024e20b03f9caf7f350f59'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='dcab1ed65e2d4f948e7217c725420dcc-337fad4c45984e19b23eafa2819b9513'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='e3d6692b5e3740528a97e8a8ba37ad2c-bab5ca992d7f475489bb00abd2d9f16e'),\n",
       " Match(model_a='lfm-40b', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='64fce54308c542cab76c66874a2929b8-73cea7da92654cc9860a5742c3ee9cdb'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='95d2e3e5a8fc4f5bacb5277545ab4620-5acc13a405184594af9645d1353f8837'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='8816ee30995c41ce8b022d6b7a4f395b-2bf276b43ddf48968e129ca582da2911'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='34d7b2d1dcd7407e99faf19403c7aa16-d1d06cb061f7422086157814ac1c2cdc'),\n",
       " Match(model_a='o4-mini', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='6b3df6bfdcb64b9ea7551f6d377aeadd-24121d2a28ee465f8006ef7574213e16'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='command-a', score=<MatchScore.B: 0>, id='b31a36ce16fb40bcad4d3c58da77b6ec-af1a9cc972d64a4393c65d3646a3bdc3'),\n",
       " Match(model_a='phi-4', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='120d11194a83488b9903eac0b9a2ba30-f5531347978c4e90b243e2d426196927'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='9ae579ed176d40f799b10b06c615ba6d-b692c89ae753430ba6e33566f13de6a8'),\n",
       " Match(model_a='deepseek-r1', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='2458bc8d18834cefa00b462441b5d037-d5b9e9f73dbc40e7bd030f3f0fac3f54'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='5ce99ed6ec3949cd90222d3b58449384-239fa5daf31c4076ab6f49198425ca75'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='5b99aaab3e4d4905a08bc8bcb760a156-86dbc3a2d5514b55bfe312ad75423f9d'),\n",
       " Match(model_a='qwq-32b', model_b='o3-mini', score=<MatchScore.A: 2>, id='209e8a3b8813454b951336fe67c30a5c-dd35ed4bb34d4ea78454b9d9cae38178'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='ee5e91259f25436b8dacc949501dd6b5-31125a6fdaf141b38e82da6eb952bb10'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='b6d85f17d745410db2a632e817795763-4ebbf073c613414bbf6be0daa8e4b39b'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='4b00720b2587454bb9f97e0e8b5f5078-3c9ba95c47964f82b8fccb95fedcfd80'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='1106de54723240d7ac34f0c3b7f1661e-09155e48d06d44219cdb14362b70b41c'),\n",
       " Match(model_a='llama-3.3-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='0d11a9e40d91450b823cfa744405dff7-53ca54762b01455a8768fad34a28092c'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='0fce5ede5a54466d9422a45bdae240e8-ab723a9c8f424b3fa2d0809eea7c4588'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='335c7bdf795540b8a8c7ceaf4d901b48-ae20225bff1c4934afab5b51bcd75431'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='6d37275f448742579b347583815ef497-af3fe357612a4214b37de79ac7ca298b'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='a71eb2a12a444ca9a17d7a118aeb8fc0-8dd9bcbff19b4aa7b7b5a629e9d7a86a'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-4', score=<MatchScore.B: 0>, id='e02ffd9ce6034b78964e70d93249a150-065e2be2931247b786aa06fcab727dee'),\n",
       " Match(model_a='llama-4-scout', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='b6e5c81e768f41bcaa46bc8a2ae59c1e-7df9992c91b344e39bbdfaaaab539dab'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='c98eace7557b49ffa3f0aa1e2af725a7-15c3868e478548588cf29e6097fee2d7'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='e68944df884448ed8dc0702fd7b58511-1c327234596045cab6f4333e2b15f4ad'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='358b0f85fda743c8a2f1dd538e615d9f-b2208053fa244dc5a8bc19b635b7393b'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='6df0a599f5dc464a9f50c2cac588c74b-b0812bd669c44f0d83e42a4555f6573b'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='05059034939f4e3da09cfc52117ac0dc-652f2aaa3d93402f815844290c1aec75'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='76451b15370f4ec3a17bfdb47bcb6e3a-903c190624cf4725acec5517e6c75fd8'),\n",
       " Match(model_a='phi-4', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='e04676f969c249f5b2c916f756cc4cfa-5ce5b7578df5423fbea8cfc6634a94a1'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='477fbcefecee462f85be4a6282da8d16-5b0b21003aeb4797a2a987bfc27ecbda'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='c719a5e8140841a2b56965dcfaef19aa-514f3dbf6472431d95e2ed8c1234e405'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='6f1ebb5006f242919631432703ed45fe-f6d4fba2d2554f1097e041ca5bcb762a'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='phi-4', score=<MatchScore.Draw: 1>, id='aa444791bbf74c97a30bf400f8837d3b-01038656a948423a9d64c4e7597cf0a3'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='06aae8a708a74adcacd1c2b03ee312cc-ca6036edd8c140b989a026d190da51d3'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='2a067c615b914b4b88ecba82c7a1b0ac-66a7af53949b43f885bbe20035cf5ae4'),\n",
       " Match(model_a='llama-3.1-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='00c74a842c54474181d5d785da17fe95-45ea4e85196c4d718e33d20317c20552'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='0d9c41b2947740309b0904e4c38f1cf3-15438cfc6cb3426d9b4f93cb91fda02c'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-4-scout', score=<MatchScore.Draw: 1>, id='9ad5f239a79740fca22662b1c07b6d5a-cdb26ed674cc4e32968bc1c4df1eecc2'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='1cf55c9ff8754c57941bce841b23c29d-a9bc25f620ce4bceb1bfb515a4e2ac1b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='9f4438cf22874343b1462dd5f351a330-ad432e21a6704814adaded6f40f49532'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='8ca1cdc6564a41429c959d0e99bcf18e-8e26751c524a452db4b9a302f2547d3b'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='phi-4', score=<MatchScore.A: 2>, id='2b5d621abad248fb9ec5a2c7218c3d6e-e16195aa6c74430d9c4af7db1e7e2c3a'),\n",
       " Match(model_a='llama-3.3-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='02a39e827a254897af3bc65a6c4a887a-ff3fa258a63b48b3ae96961a582a73fb'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='a597157956ee43ffa1175f39f9b9751f-9bd276ebce6f40fe9100ba8c5a7f32c5'),\n",
       " Match(model_a='llama-3.3-70b', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='abe2772c09cb4c598f64c938a7f385ba-f8d6bd1665974595b9998855e609d8ed'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='03bf6718095a41838ec444ffa0022f0c-78e1183ee65b41ba98d9ab32308d7997'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='27777c37a0c04b8daf86794bbf262f5a-8b72921c73f4415fb77533009c2f55a5'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='62f6bb75e2cb4ee794a4656b4a90e94e-43d3437dcc2e413fa533f6884643451e'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='3359a4ccf67e4ce582a79f426959cb37-cba6e610f6e945dd92537df49226a202'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-4', score=<MatchScore.B: 0>, id='4926e3e91eb44f35923de0d12923c185-e3b1527a71fc4c06abfeb8c3e64d0e34'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='901cfd87bc574c30897638165cc35414-ed240c5945224363822c407e7d0ab200'),\n",
       " Match(model_a='llama-3.1-405b', model_b='o4-mini', score=<MatchScore.Draw: 1>, id='97cea971a9fc45329dcb7a93c6b7ae8e-8b825e0b9fe44c3eb39da3043037dcc9'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='phi-4', score=<MatchScore.A: 2>, id='cd2be1027f6f444aa2150da180f6fd14-036ca2e666df4c559feff3a53246c331'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='ca9b93894bd3445eb8501810c983f458-ea4bfefc1b7e4b22bc49c475ac399fe7'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='9dbaca4887ae466f8df5447d2bd9717a-df7741257cea43889638e03fda6e4709'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='qwq-32b', score=<MatchScore.A: 2>, id='8c69eb3c1e6f411ba7d0b110ccafd627-8d29f73536ec4ef7a92365b1ee6d57f5'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='d0a7739091564a678c04d47c9f0df8a9-6b66a81425dd48bc84d050e82327fd04'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='14b8871839334997bf9000515ef20b8a-9b4e3e3011c84f82bfba71ff22b16e34'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='lfm-40b', score=<MatchScore.A: 2>, id='bcf25e6e61874d09be3055aa7496ca83-b71423fba0d14ad09130a9d2e683abd4'),\n",
       " Match(model_a='mistral-saba', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='43e9099bc4d44d439d90443e0cae68df-d81f8d10767f4c9da58083f29904268e'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='646d06a8670240f6af041a659a1e1398-88cc18b15ccb47d8921b012cfc8c060e'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='143347ef1a7443cf9656676ef954e2cf-995664b6b04e4b41a99cabb0107eb2f0'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='ffcb37b7175f41ebad6ceacc44e3c4b6-8d25983255be4294afd5cbe7dfc4cf90'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='257f455bb1634d81b192c7f2eb1a9777-7abb4370e27048208424aa8f016241d2'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='phi-4', score=<MatchScore.B: 0>, id='1df8eecd0615469780818c1f08cc6e2c-90cab3c6807c4bdb91dd8307af755482'),\n",
       " Match(model_a='mistral-large-2411', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='a7c8b8f7bfe248eaa4fc3f4a35dd6cad-14a56847f8d64a7782521f30c8b088b4'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='bffb838a20f14607b8d3f4a4410faaff-9b263e23d187409ebde0831fdf6bac57'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='fd3138d0e78c4501baecec973e65858f-2fa4976ac4a740a2adc2466689c6f3bd'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='2e181f0a4a5246769102a8ce6a99693c-a5a410f246724ad09160321975e1188d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='0c7e7de1ba5947408c2648b79c7763d0-22f9ddb854864d1992db4aa95ec4ed1b'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='ec358debc3a54fa0ac5dc6dbe613aca9-5cd6c71146d2420eb0fb401215e39605'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='1400e96f890b46e3a043b0397d246fb3-9ef37260a48d4851bcc54879594aad56'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='6489356283d74d259eecb4e8840d6f38-89ed7dd968564dcb94cf5bc19d913355'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='362b0403390f4a58afd8049a93cdf60c-396825d03f8d4a15803b295b3412a954'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='f8c8a1a08a5b4a82914e2a9dd3bc4185-0ac45e1e7b42405b8e6e097dd947728b'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='0ca2983b41004710b0b1cab251226096-fa754562e6c8453cbc77792ff5f9fe92'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='4036376b614b4c46a0d64894ceda2bb9-117c582b6a7d4cf8b13ac5f4d6180c18'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='62ef596336a24941bbc2a25c030914a0-200e403409854079aa3d65099b9f419a'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='c56b1257d8ff44d798bacf1a5ba941a4-765af4a6a8b644419206a6ecd12b0dfe'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='e5b4fd1ed527433198ec0936c0154330-5f349821f3ed440f9420304807d3da05'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='a2af72467ff64f409bad296b4c3c5cd6-d079b6ec0cf949f3b602a074d982d42b'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='d3ff8f1b548d46209d6da3186c38e019-bb323ca40d894e1285d34c30f7a1fde4'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='87cba0731a41469d8aab97a26a8d5dda-0d62f70751b04960b5b0d9d2c04a3060'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemma-2-27b-it-q8', score=<MatchScore.A: 2>, id='a3e2166492d3477ab83c339b295b8fce-a8ed7a8b2d874080bb7ccd5a7547207f'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='e4b3b9c3c71246148c56761aa9a5eff7-5906a23f3a9f445fb81fd114cb695bdd'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='03de8663b2154f66bea0145807dfb730-fe262d6cc670488a95cb51159153577a'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='168aea0b5bff475794b04d195b027dad-c69e6a38cc0d41c3a106043d59e6fb94'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='73cb75c7fa554194934ec5a595dd1ddd-ba83a1c44ea5476d9c567595768c2f3b'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='0b17027d6a6e472e806b9b86cd190c7f-d132eacbd08e4750af8b7b92355771aa'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='ecaf587ac2b24ebb867dd8cf845c919e-6e72708f6aac405f93f0c36c39f16914'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='e9de2d3af2a847a7b1accb46f2ef2647-d6139fc6f33b409cab575617d234f87e'),\n",
       " Match(model_a='o3-mini', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='b2c62bf762a84820ad9c7cf81044493e-f6ca86eb4c3a42588cfd5cef8bb7eca7'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='c146e18812a140c4b700ccd37c358ae1-249f816e8169476588c219fef91c8e53'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='e39bf14079a840e594ac24e010cdfa4e-8e2fcc46903741418eb2e4626c3fa832'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='b29c3dc492a5482a8d67203bfa188e2a-24474c8202ef4aa2b6f91644cead5d3b'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='58133a093ee843739a3f6f9fbad4daa4-2fe29008fae943c3be5ea63bee2905ea'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='e393c210ac894dbf867ca9c5c547b49d-2ff89e6d22c146aaa2c85ced97a7ad97'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='cbc7cbc0b296445ea7ad30cc33856833-2759ac6d716e49e0a71193fc29c5df84'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='8f8343cd40a648b180acc4020aac4837-5a77fd192bca461a883303b1ab2a1f9a'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='3e1f144219fa4f47bc93fe03ebdc56df-9bf579b525e04751adb446444b6b7cf6'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='3fede358d591415187fd47a7402ee33d-770ed50d4604477dae8809e9e4da8c2d'),\n",
       " Match(model_a='phi-4', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='133a36418fda48b9800a663684fcfc01-0be0bd3cdaf14393bdaa8775edc9c60b'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='3e99beb5d92e4e5fb97f141a43ed21e5-c57eb0e8f2e142fc85b5f50ca249ee73'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='cef1100a004441d69434663583551a78-8b06b33bb72242edb93ca72c8aaa8445'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='phi-4', score=<MatchScore.B: 0>, id='b6a2c54d9b9c480e860f47ce4b5ce219-5e876fa655864d318e9be9d7690b4206'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='61ad26a72dc7462d8e6449710c6927b2-eb6058b162c14a20b53a951cbf2c206b'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='9f185945f3794d18af87d44b332b4363-990e398896d14f0bad980b6ca44c60eb'),\n",
       " Match(model_a='llama-3.1-8b', model_b='o3-mini', score=<MatchScore.A: 2>, id='459cf9a4d02f47548f9718f57145ade3-b0a545315ef0404d9708f03467acd32e'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='cd8f74c80cc44d6f8c110fb966d09f8b-274feb0457564819ab77a61abc61a10a'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='e78f383ed2c74a19bced4ba52fb350d5-770ee68813804e9b8afce62ebbd4ce49'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='phi-4', score=<MatchScore.Draw: 1>, id='66f4611fea604a51bea2380f4fa338ed-270e890d86f842d1b8fed51627cceaab'),\n",
       " Match(model_a='llama-3.1-405b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='2fc45fd81ba54223a488aabe57ffb89c-ef14863f8957488f96239e22723c119c'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='d604a850881a4deeb74a838affbbb7ca-9ae2d50026b340b885fcc6f7293a2667'),\n",
       " Match(model_a='gemma-3-4b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='4f7a6bc7ac72422092a4243971268d91-5f49fb4a5d834bd99cd57602d19d9b84'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='f1f7a0596fcb4173ad39327f7fc86904-3abd2022a5214264a397d7cc9334ce1f'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='d0ad807093f2440990340dd6e59d5ac9-4a77090f32f74fc9904c48f92cb80af1'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.Draw: 1>, id='53857388b2b741429996aea2a9a7425f-4f7a82deb5b9445dadd3ec9489596241'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='e4b9a92704764395ae581a7c8195c238-a07936ad413944fcb9b8292418d9d7c1'),\n",
       " Match(model_a='lfm-40b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='9ffdcb597cf24f8ab489b2cd40a00353-b8d6b5d11700419a989d1caf899c04c2'),\n",
       " Match(model_a='lfm-40b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='54b2c6758ea44ad7b79b2a07ce1e7759-83b5ebe4ab974af1863139c73ce2268a'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='ba96bc1e62294c4ba9e93f3d1b7cc7f8-cbab2b7d544e42628d30aef4c63e7a19'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='e93d7ebc99dd4fecaf7644e7879ea30c-29bfca5586794dd0a3a8e188d51e23bf'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='fa9aad71975c4393a22d156fe4a4d78d-ec2a8e647fc14ae2a29c9e4d1392608a'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='1ccc6d5c74634e56b9f9b2390972b017-4c4694051648494a976a298318cbf6f1'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='420b3b33e1e34f0da09668b6bd187acd-ae52e64793454c078705a6291bd396e6'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='c9bfe707083843b285de80eee0020295-d372089280304a5c9cd2783d7a2bbecb'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='0a388746aa5846908a1125419ca93ddd-f9190be097824736bf8d7e2f1ed05ef4'),\n",
       " Match(model_a='deepseek-r1', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='b15e2f149a7a40058fe77767ec0816d4-2ea5b29c65bd4c83ad5ae7c93b8e38d9'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='19ae2b296269487c9b9e9fb5bfcbf8b8-f8d8df181a354b7e982e86cba00f6bf6'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='b1fd912f745c42429f888e2d56f5ea6e-b74a559f0de3442c8db106592eea5374'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-saba', score=<MatchScore.Draw: 1>, id='bd969fe1827b4d1ea9daafd303bd374e-d634d629d3eb4ab588d0f278757d5bc3'),\n",
       " Match(model_a='phi-4', model_b='lfm-40b', score=<MatchScore.A: 2>, id='ac216ba89def4224a16d1a0b052eac81-6d3868e60d8247baad986231c9b43d2a'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gpt-4.1-nano', score=<MatchScore.Draw: 1>, id='d04cbea4f4d94bc7a1670eb2500e1557-53990b840a074960a4a3cb3a54d60487'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='2c27e9fa3bcb4eaba0d63dcfa682c3ed-ca2ee916b570405793e8529aa412844e'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='0efc163ad7b64aeea0cb4034ca417b3f-0150c72dbe6d4b0086d9ea5985a02a7f'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='0ae2145ac7894bbf8184c0bfb93a199d-438d83ba01d54075956453b6aa341d9a'),\n",
       " Match(model_a='gemma-3-27b', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='44589a0a42294820a673ad0527c86b47-08b063a107d94d29bbaaf524635f9cd3'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='321e997cc5924c819ffcaa25de2c0b61-30752b499de74f3d9f143091abbec438'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='86333ce554fc400b8799bee14d9a23d7-fe305184c681455eba2bd0720e8aac25'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='53c1295a14f94b78b7299ebd715f99a3-818630b15c5b4db2b193deeeb12dbaa3'),\n",
       " Match(model_a='gemma-3-4b', model_b='gpt-4.1-nano', score=<MatchScore.Draw: 1>, id='0530feb939ab49b6a507315bfe1a3934-fab5d6d1e7f34a8988663e8ed89df6ca'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='b5e9cf0e9f564693a7de7a6e974fe01c-795669d1249d4ed4a3ebc20369b301a5'),\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.match_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1574044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 76861 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  5.75it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bcac115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>rank</th><th>rank_p2.5</th><th>rank_p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>845.146613</td><td>760.249232</td><td>975.55544</td><td>49</td><td>33</td><td>52</td><td>47531.0</td><td>0.182743</td><td>65</td><td>0.002811</td><td>0.000004</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>949.893052</td><td>929.220376</td><td>1098.460576</td><td>40</td><td>12</td><td>42</td><td>1.05781e6</td><td>3.98568</td><td>1302</td><td>0.003061</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>946.578753</td><td>886.412487</td><td>994.77975</td><td>42</td><td>25</td><td>45</td><td>2.747666e6</td><td>20.763975</td><td>3598</td><td>0.005771</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>764.524717</td><td>656.778782</td><td>788.82102</td><td>52</td><td>50</td><td>52</td><td>131187.0</td><td>0.602249</td><td>309</td><td>0.001949</td><td>0.000005</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>828.435309</td><td>774.724597</td><td>913.562886</td><td>50</td><td>45</td><td>51</td><td>533384.0</td><td>1.934863</td><td>1796</td><td>0.001077</td><td>0.000004</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>766.099411</td><td>697.026032</td><td>869.498738</td><td>51</td><td>46</td><td>52</td><td>43550.0</td><td>0.153078</td><td>80</td><td>0.001913</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>994.208979</td><td>929.319663</td><td>1104.187624</td><td>27</td><td>7</td><td>42</td><td>75812.0</td><td>0.531085</td><td>142</td><td>0.00374</td><td>0.000007</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>940.704691</td><td>889.574137</td><td>1036.704745</td><td>43</td><td>15</td><td>48</td><td>1.186919e6</td><td>4.305576</td><td>1420</td><td>0.003032</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>955.701214</td><td>905.549779</td><td>1024.057833</td><td>38</td><td>22</td><td>45</td><td>4.0819e6</td><td>29.128193</td><td>4954</td><td>0.00588</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>995.498403</td><td>929.293137</td><td>1046.728188</td><td>25</td><td>19</td><td>41</td><td>1.757717e6</td><td>12.542963</td><td>1479</td><td>0.008481</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 12)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ Yi-1.5-9B- ┆ 845.14661 ┆ 760.24923 ┆ 975.55544 ┆ … ┆ 0.182743  ┆ 65      ┆ 0.002811  ┆ 0.000004  │\n",
       "│ Chat       ┆ 3         ┆ 2         ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ aya-expans ┆ 949.89305 ┆ 929.22037 ┆ 1098.4605 ┆ … ┆ 3.98568   ┆ 1302    ┆ 0.003061  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 2         ┆ 6         ┆ 76        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 946.57875 ┆ 886.41248 ┆ 994.77975 ┆ … ┆ 20.763975 ┆ 3598    ┆ 0.005771  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆ 3         ┆ 7         ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 764.52471 ┆ 656.77878 ┆ 788.82102 ┆ … ┆ 0.602249  ┆ 309     ┆ 0.001949  ┆ 0.000005  │\n",
       "│ e-14b-inst ┆ 7         ┆ 2         ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ ruct-dpo-v ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 828.43530 ┆ 774.72459 ┆ 913.56288 ┆ … ┆ 1.934863  ┆ 1796    ┆ 0.001077  ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆ 9         ┆ 7         ┆ 6         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ qwen2-7b-i ┆ 766.09941 ┆ 697.02603 ┆ 869.49873 ┆ … ┆ 0.153078  ┆ 80      ┆ 0.001913  ┆ 0.000004  │\n",
       "│ nstruct    ┆ 1         ┆ 2         ┆ 8         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-32 ┆ 994.20897 ┆ 929.31966 ┆ 1104.1876 ┆ … ┆ 0.531085  ┆ 142     ┆ 0.00374   ┆ 0.000007  │\n",
       "│ b-instruct ┆ 9         ┆ 3         ┆ 24        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 940.70469 ┆ 889.57413 ┆ 1036.7047 ┆ … ┆ 4.305576  ┆ 1420    ┆ 0.003032  ┆ 0.000004  │\n",
       "│ -instruct  ┆ 1         ┆ 7         ┆ 45        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 955.70121 ┆ 905.54977 ┆ 1024.0578 ┆ … ┆ 29.128193 ┆ 4954    ┆ 0.00588   ┆ 0.000007  │\n",
       "│ der-32b-in ┆ 4         ┆ 9         ┆ 33        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 995.49840 ┆ 929.29313 ┆ 1046.7281 ┆ … ┆ 12.542963 ┆ 1479    ┆ 0.008481  ┆ 0.000007  │\n",
       "│            ┆ 3         ┆ 7         ┆ 88        ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dac27",
   "metadata": {},
   "source": [
    "### Une autre méthode de calcul \n",
    "\n",
    "Ici on utilise uniquement les données de votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e971e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/5a02c58f54f2db3fc51f076d24a840f04efa01fa (last modified on Tue Sep 30 13:43:20 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n",
      "Computing bootstrap scores from a sample of 21244 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 23.68it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\",\n",
    "    include_votes=False,\n",
    "    include_reactions=True,\n",
    "    bootstrap_samples=5,\n",
    "    mean_how=\"token\",\n",
    "    export_path=None,  # Path(\"output\"),\n",
    "    token=None,\n",
    ")\n",
    "scores_votes = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c91a29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>rank</th><th>rank_p2.5</th><th>rank_p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;aya-expanse-8b&quot;</td><td>1013.928862</td><td>966.131345</td><td>1054.106374</td><td>22</td><td>15</td><td>30</td><td>327851.0</td><td>1.235297</td><td>467</td><td>0.002645</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>939.33355</td><td>858.531048</td><td>948.581674</td><td>38</td><td>34</td><td>44</td><td>741453.0</td><td>5.603123</td><td>1079</td><td>0.005193</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>816.25162</td><td>731.751982</td><td>862.603705</td><td>48</td><td>44</td><td>48</td><td>167003.0</td><td>0.605807</td><td>556</td><td>0.00109</td><td>0.000004</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>968.551005</td><td>898.219131</td><td>1103.761051</td><td>34</td><td>5</td><td>42</td><td>992729.0</td><td>133.262452</td><td>1834</td><td>0.072662</td><td>0.000134</td></tr><tr><td>&quot;claude-3-7-sonnet&quot;</td><td>1035.29893</td><td>1024.064541</td><td>1182.885878</td><td>17</td><td>4</td><td>22</td><td>287583.0</td><td>38.604711</td><td>296</td><td>0.130421</td><td>0.000134</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>890.902386</td><td>843.279529</td><td>966.550322</td><td>45</td><td>30</td><td>46</td><td>343212.0</td><td>1.052349</td><td>430</td><td>0.002447</td><td>0.000003</td></tr><tr><td>&quot;phi-4&quot;</td><td>982.490627</td><td>971.978936</td><td>994.715125</td><td>28</td><td>25</td><td>31</td><td>1.149348e6</td><td>5.298356</td><td>1498</td><td>0.003537</td><td>0.000005</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>917.003338</td><td>876.90425</td><td>935.594578</td><td>40</td><td>37</td><td>43</td><td>313742.0</td><td>1.138106</td><td>392</td><td>0.002903</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>900.678166</td><td>818.17964</td><td>949.086506</td><td>43</td><td>33</td><td>48</td><td>1.168947e6</td><td>8.341536</td><td>1490</td><td>0.005598</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>1019.73713</td><td>891.157413</td><td>1033.741498</td><td>20</td><td>18</td><td>43</td><td>353398.0</td><td>2.521827</td><td>298</td><td>0.008463</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 12)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ aya-expans ┆ 1013.9288 ┆ 966.13134 ┆ 1054.1063 ┆ … ┆ 1.235297  ┆ 467     ┆ 0.002645  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 62        ┆ 5         ┆ 74        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 939.33355 ┆ 858.53104 ┆ 948.58167 ┆ … ┆ 5.603123  ┆ 1079    ┆ 0.005193  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆           ┆ 8         ┆ 4         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 816.25162 ┆ 731.75198 ┆ 862.60370 ┆ … ┆ 0.605807  ┆ 556     ┆ 0.00109   ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆           ┆ 2         ┆ 5         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ claude-3-5 ┆ 968.55100 ┆ 898.21913 ┆ 1103.7610 ┆ … ┆ 133.26245 ┆ 1834    ┆ 0.072662  ┆ 0.000134  │\n",
       "│ -sonnet-v2 ┆ 5         ┆ 1         ┆ 51        ┆   ┆ 2         ┆         ┆           ┆           │\n",
       "│ claude-3-7 ┆ 1035.2989 ┆ 1024.0645 ┆ 1182.8858 ┆ … ┆ 38.604711 ┆ 296     ┆ 0.130421  ┆ 0.000134  │\n",
       "│ -sonnet    ┆ 3         ┆ 41        ┆ 78        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ phi-3.5-mi ┆ 890.90238 ┆ 843.27952 ┆ 966.55032 ┆ … ┆ 1.052349  ┆ 430     ┆ 0.002447  ┆ 0.000003  │\n",
       "│ ni-instruc ┆ 6         ┆ 9         ┆ 2         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ t          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ phi-4      ┆ 982.49062 ┆ 971.97893 ┆ 994.71512 ┆ … ┆ 5.298356  ┆ 1498    ┆ 0.003537  ┆ 0.000005  │\n",
       "│            ┆ 7         ┆ 6         ┆ 5         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 917.00333 ┆ 876.90425 ┆ 935.59457 ┆ … ┆ 1.138106  ┆ 392     ┆ 0.002903  ┆ 0.000004  │\n",
       "│ -instruct  ┆ 8         ┆           ┆ 8         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 900.67816 ┆ 818.17964 ┆ 949.08650 ┆ … ┆ 8.341536  ┆ 1490    ┆ 0.005598  ┆ 0.000007  │\n",
       "│ der-32b-in ┆ 6         ┆           ┆ 6         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 1019.7371 ┆ 891.15741 ┆ 1033.7414 ┆ … ┆ 2.521827  ┆ 298     ┆ 0.008463  ┆ 0.000007  │\n",
       "│            ┆ 3         ┆ 3         ┆ 98        ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914dc5de",
   "metadata": {},
   "source": [
    "## Pipeline avec un ranker alternatif\n",
    "\n",
    "Utilisation du Ranker `MaximumLikelihood`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33484b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/3a81e160fed75a8dccf44e59cb8a74c13b981a86 (last modified on Tue Sep 30 13:43:04 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/5a02c58f54f2db3fc51f076d24a840f04efa01fa (last modified on Tue Sep 30 13:43:20 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"ml\",\n",
    "    include_votes=True,\n",
    "    include_reactions=True,\n",
    "    mean_how=\"token\",\n",
    "    bootstrap_samples=5,\n",
    "    export_path=Path(\"output\"),\n",
    "    token=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d46e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 76861 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_ml = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76592e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/3a81e160fed75a8dccf44e59cb8a74c13b981a86 (last modified on Tue Sep 30 13:43:04 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Computing bootstrap scores from a sample of 55617 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  7.70it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"ml\", include_votes=True, include_reactions=False, mean_how=\"token\", bootstrap_samples=5, token=None\n",
    ")\n",
    "\n",
    "scores_ml_votes = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66711d3",
   "metadata": {},
   "source": [
    "## Comparaison des différentes méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "159fa36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>score_elo</th><th>score_elo_votes</th><th>score_ml</th><th>score_ml_votes</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>845.146613</td><td>null</td><td>798.219892</td><td>791.19946</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>949.893052</td><td>1013.928862</td><td>1004.669255</td><td>1000.708868</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>946.578753</td><td>939.33355</td><td>961.894915</td><td>954.533255</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>764.524717</td><td>null</td><td>775.2214</td><td>816.819757</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>828.435309</td><td>816.25162</td><td>846.43855</td><td>848.629728</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>766.099411</td><td>null</td><td>771.610673</td><td>755.61618</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>994.208979</td><td>null</td><td>1022.797335</td><td>1005.472615</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>940.704691</td><td>917.003338</td><td>958.722484</td><td>976.35348</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>955.701214</td><td>900.678166</td><td>955.465134</td><td>960.824767</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>995.498403</td><td>1019.73713</td><td>977.80733</td><td>972.894117</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 5)\n",
       "┌─────────────────────────────────┬────────────┬─────────────────┬─────────────┬────────────────┐\n",
       "│ model_name                      ┆ score_elo  ┆ score_elo_votes ┆ score_ml    ┆ score_ml_votes │\n",
       "│ ---                             ┆ ---        ┆ ---             ┆ ---         ┆ ---            │\n",
       "│ str                             ┆ f64        ┆ f64             ┆ f64         ┆ f64            │\n",
       "╞═════════════════════════════════╪════════════╪═════════════════╪═════════════╪════════════════╡\n",
       "│ Yi-1.5-9B-Chat                  ┆ 845.146613 ┆ null            ┆ 798.219892  ┆ 791.19946      │\n",
       "│ aya-expanse-8b                  ┆ 949.893052 ┆ 1013.928862     ┆ 1004.669255 ┆ 1000.708868    │\n",
       "│ c4ai-command-r-08-2024          ┆ 946.578753 ┆ 939.33355       ┆ 961.894915  ┆ 954.533255     │\n",
       "│ chocolatine-14b-instruct-dpo-v… ┆ 764.524717 ┆ null            ┆ 775.2214    ┆ 816.819757     │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 828.435309 ┆ 816.25162       ┆ 846.43855   ┆ 848.629728     │\n",
       "│ …                               ┆ …          ┆ …               ┆ …           ┆ …              │\n",
       "│ qwen2-7b-instruct               ┆ 766.099411 ┆ null            ┆ 771.610673  ┆ 755.61618      │\n",
       "│ qwen2.5-32b-instruct            ┆ 994.208979 ┆ null            ┆ 1022.797335 ┆ 1005.472615    │\n",
       "│ qwen2.5-7b-instruct             ┆ 940.704691 ┆ 917.003338      ┆ 958.722484  ┆ 976.35348      │\n",
       "│ qwen2.5-coder-32b-instruct      ┆ 955.701214 ┆ 900.678166      ┆ 955.465134  ┆ 960.824767     │\n",
       "│ qwq-32b                         ┆ 995.498403 ┆ 1019.73713      ┆ 977.80733   ┆ 972.894117     │\n",
       "└─────────────────────────────────┴────────────┴─────────────────┴─────────────┴────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "pl.concat(\n",
    "    [\n",
    "        scores.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo\"}),\n",
    "        scores_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo_votes\"}),\n",
    "        scores_ml.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml\"}),\n",
    "        scores_ml_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml_votes\"}),\n",
    "    ],\n",
    "    how=\"align\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953a2437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-412eff19e9dd4bccb27e504a1e56b8be.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-412eff19e9dd4bccb27e504a1e56b8be.vega-embed details,\n",
       "  #altair-viz-412eff19e9dd4bccb27e504a1e56b8be.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-412eff19e9dd4bccb27e504a1e56b8be\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-412eff19e9dd4bccb27e504a1e56b8be\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-412eff19e9dd4bccb27e504a1e56b8be\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bbc14d9978c5eee0f9c039b9fbcf80fa\"}, \"mark\": {\"type\": \"circle\", \"size\": 80}, \"encoding\": {\"color\": {\"field\": \"score_type\", \"title\": \"Score Type\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"model_name\", \"type\": \"nominal\"}, {\"field\": \"score\", \"type\": \"quantitative\"}, {\"field\": \"score_type\", \"type\": \"nominal\"}], \"x\": {\"field\": \"model_name\", \"sort\": [\"gemma-3-12b\", \"gemini-2.0-flash-001\", \"gemma-3-27b\", \"gemini-2.0-flash-exp\", \"deepseek-v3-chat\", \"llama-3.1-nemotron-70b-instruct\", \"claude-3-7-sonnet\", \"grok-3-mini-beta\", \"command-a\", \"gemini-1.5-pro-001\", \"gemma-3-4b\", \"gemini-1.5-pro-002\", \"deepseek-v3-0324\", \"mistral-large-2411\", \"deepseek-r1\", \"gpt-4.1-mini\", \"mistral-small-3.1-24b\", \"llama-4-scout\", \"llama-3.1-70b\", \"gpt-4.1-nano\", \"mistral-saba\", \"o4-mini\", \"phi-4\", \"o3-mini\", \"qwq-32b\", \"llama-3.1-405b\", \"qwen2.5-32b-instruct\", \"gpt-4o-2024-08-06\", \"deepseek-r1-distill-llama-70b\", \"gpt-4o-mini-2024-07-18\", \"claude-3-5-sonnet-v2\", \"gemma-2-27b-it-q8\", \"jamba-1.5-large\", \"ministral-8b-instruct-2410\", \"mistral-small-24b-instruct-2501\", \"hermes-3-llama-3.1-405b\", \"gemma-2-9b-it\", \"qwen2.5-coder-32b-instruct\", \"llama-3.3-70b\", \"aya-expanse-8b\", \"llama-3.1-8b\", \"c4ai-command-r-08-2024\", \"qwen2.5-7b-instruct\", \"phi-3.5-mini-instruct\", \"mistral-nemo-2407\", \"mixtral-8x7b-instruct-v0.1\", \"lfm-40b\", \"mixtral-8x22b-instruct-v0.1\", \"Yi-1.5-9B-Chat\", \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"qwen2-7b-instruct\", \"chocolatine-14b-instruct-dpo-v1.2-q4\"], \"title\": \"model_name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"score\", \"scale\": {\"domain\": [500, 1300]}, \"title\": \"Score\", \"type\": \"quantitative\"}}, \"height\": 400, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-bbc14d9978c5eee0f9c039b9fbcf80fa\": [{\"model_name\": \"gemma-3-12b\", \"score_type\": \"Elo score (all data)\", \"score\": 1183.1870496044778}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"Elo score (all data)\", \"score\": 1134.095721445028}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"Elo score (all data)\", \"score\": 1122.7847561933788}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"Elo score (all data)\", \"score\": 1116.0034286163132}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"Elo score (all data)\", \"score\": 1111.972922346194}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 1101.1240052728047}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"Elo score (all data)\", \"score\": 1100.3419494743105}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"Elo score (all data)\", \"score\": 1096.971850554676}, {\"model_name\": \"command-a\", \"score_type\": \"Elo score (all data)\", \"score\": 1094.7682597148437}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"Elo score (all data)\", \"score\": 1082.2426448467852}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"Elo score (all data)\", \"score\": 1081.605076757518}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"Elo score (all data)\", \"score\": 1078.6393666396878}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"Elo score (all data)\", \"score\": 1077.0402639070583}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"Elo score (all data)\", \"score\": 1061.0713041948968}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"Elo score (all data)\", \"score\": 1052.1378427024683}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 1048.3400087703153}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"Elo score (all data)\", \"score\": 1041.340599723624}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"Elo score (all data)\", \"score\": 1035.745808141317}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 1025.2008649406037}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"Elo score (all data)\", \"score\": 1025.0551350509993}, {\"model_name\": \"mistral-saba\", \"score_type\": \"Elo score (all data)\", \"score\": 1018.6173621259563}, {\"model_name\": \"o4-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 1012.7143400996592}, {\"model_name\": \"phi-4\", \"score_type\": \"Elo score (all data)\", \"score\": 1010.1546889309428}, {\"model_name\": \"o3-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 1003.5535493836504}, {\"model_name\": \"qwq-32b\", \"score_type\": \"Elo score (all data)\", \"score\": 995.4984029102458}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"Elo score (all data)\", \"score\": 994.9192495565068}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 994.2089789245138}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"Elo score (all data)\", \"score\": 993.4416604847273}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 991.0308935829268}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"Elo score (all data)\", \"score\": 990.6573321631773}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"Elo score (all data)\", \"score\": 987.5643691351778}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"Elo score (all data)\", \"score\": 987.5300827266286}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"Elo score (all data)\", \"score\": 983.8446204358052}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"Elo score (all data)\", \"score\": 966.3046402739027}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"Elo score (all data)\", \"score\": 964.5065860338867}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"Elo score (all data)\", \"score\": 963.9237418530644}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"Elo score (all data)\", \"score\": 960.6941386388893}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 955.7012142412894}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 950.3834953093192}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"Elo score (all data)\", \"score\": 949.8930521113663}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"Elo score (all data)\", \"score\": 947.4835499711107}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"Elo score (all data)\", \"score\": 946.5787532645028}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 940.7046907512761}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 925.1530094353341}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"Elo score (all data)\", \"score\": 903.3147553584382}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"Elo score (all data)\", \"score\": 900.1492431637046}, {\"model_name\": \"lfm-40b\", \"score_type\": \"Elo score (all data)\", \"score\": 898.5498148226787}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"Elo score (all data)\", \"score\": 877.318824221448}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"Elo score (all data)\", \"score\": 845.1466128189454}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"Elo score (all data)\", \"score\": 828.4353092755479}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 766.0994108597581}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"Elo score (all data)\", \"score\": 764.52471735483}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1082.7217461389284}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"Elo score (votes data)\", \"score\": 1149.2634109310486}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1132.5455016890453}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"Elo score (votes data)\", \"score\": 1207.1494474246067}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"Elo score (votes data)\", \"score\": 1170.23905949279}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 1109.4393645849907}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"Elo score (votes data)\", \"score\": 1035.2989295220843}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"Elo score (votes data)\", \"score\": 1074.32789139534}, {\"model_name\": \"command-a\", \"score_type\": \"Elo score (votes data)\", \"score\": 1058.772878631679}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"Elo score (votes data)\", \"score\": 1064.6134811544873}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1083.62573289195}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"Elo score (votes data)\", \"score\": 1019.609418059402}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"Elo score (votes data)\", \"score\": 1114.2705820313445}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"Elo score (votes data)\", \"score\": 1023.7649538817552}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"Elo score (votes data)\", \"score\": 1063.0517828124655}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1049.417777969246}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1069.9777896957664}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"Elo score (votes data)\", \"score\": 1038.3622102093602}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 989.8734379803286}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"Elo score (votes data)\", \"score\": 999.961235828462}, {\"model_name\": \"mistral-saba\", \"score_type\": \"Elo score (votes data)\", \"score\": 980.3834126209379}, {\"model_name\": \"o4-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1045.1769409926978}, {\"model_name\": \"phi-4\", \"score_type\": \"Elo score (votes data)\", \"score\": 982.490626795873}, {\"model_name\": \"o3-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1002.5524116513949}, {\"model_name\": \"qwq-32b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1019.7371298505299}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"Elo score (votes data)\", \"score\": 971.3684899438222}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"Elo score (votes data)\", \"score\": 970.203844570425}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1005.092346338622}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"Elo score (votes data)\", \"score\": 1033.9334817430663}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"Elo score (votes data)\", \"score\": 968.5510046117193}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"Elo score (votes data)\", \"score\": 943.3700327592918}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"Elo score (votes data)\", \"score\": 980.8414879378865}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"Elo score (votes data)\", \"score\": 965.6180186722854}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"Elo score (votes data)\", \"score\": 990.4222177081954}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"Elo score (votes data)\", \"score\": 909.9608606533386}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"Elo score (votes data)\", \"score\": 913.7567827264087}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 900.6781662483136}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 980.662917626947}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1013.9288615336642}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"Elo score (votes data)\", \"score\": 957.6948299450353}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"Elo score (votes data)\", \"score\": 939.333550079346}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 917.0033382872284}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 890.9023855502563}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"Elo score (votes data)\", \"score\": 843.1328963590915}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"Elo score (votes data)\", \"score\": 923.5885918653624}, {\"model_name\": \"lfm-40b\", \"score_type\": \"Elo score (votes data)\", \"score\": 898.3502729934366}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"Elo score (votes data)\", \"score\": 834.616118684226}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"Elo score (votes data)\", \"score\": 816.2516201112647}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"BT score (all data)\", \"score\": 1105.179727571333}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"BT score (all data)\", \"score\": 1129.1287930142996}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"BT score (all data)\", \"score\": 1123.4813794301108}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"BT score (all data)\", \"score\": 1142.3107907316776}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"BT score (all data)\", \"score\": 1110.7143010014147}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 1079.5462667355764}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"BT score (all data)\", \"score\": 1088.1281259660964}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"BT score (all data)\", \"score\": 1081.7796167139713}, {\"model_name\": \"command-a\", \"score_type\": \"BT score (all data)\", \"score\": 1110.9423679383317}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"BT score (all data)\", \"score\": 1088.924402429826}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"BT score (all data)\", \"score\": 1078.9936307219991}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"BT score (all data)\", \"score\": 1052.5903223996909}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"BT score (all data)\", \"score\": 1093.8142270198007}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"BT score (all data)\", \"score\": 1049.4948817132781}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"BT score (all data)\", \"score\": 1040.7759881179668}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1067.7766545398492}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"BT score (all data)\", \"score\": 1029.1370611947118}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"BT score (all data)\", \"score\": 1043.0272178444925}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"BT score (all data)\", \"score\": 1006.0928632828244}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"BT score (all data)\", \"score\": 999.2905614563027}, {\"model_name\": \"mistral-saba\", \"score_type\": \"BT score (all data)\", \"score\": 1021.3400358159672}, {\"model_name\": \"o4-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1010.0338301403015}, {\"model_name\": \"phi-4\", \"score_type\": \"BT score (all data)\", \"score\": 999.8658530362507}, {\"model_name\": \"o3-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1006.9342695790299}, {\"model_name\": \"qwq-32b\", \"score_type\": \"BT score (all data)\", \"score\": 977.8073300307235}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"BT score (all data)\", \"score\": 1013.1486796584128}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 1022.7973349597387}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"BT score (all data)\", \"score\": 995.0029636656258}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"BT score (all data)\", \"score\": 974.3857881004824}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"BT score (all data)\", \"score\": 1013.3018750604152}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"BT score (all data)\", \"score\": 998.8158819276546}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"BT score (all data)\", \"score\": 1033.2335402677836}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"BT score (all data)\", \"score\": 1002.9713871363997}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"BT score (all data)\", \"score\": 989.4656365751987}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"BT score (all data)\", \"score\": 1014.2187868920398}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"BT score (all data)\", \"score\": 964.6759250475911}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"BT score (all data)\", \"score\": 983.6093600577655}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 955.4651340602306}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"BT score (all data)\", \"score\": 1013.0221776976362}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"BT score (all data)\", \"score\": 1004.6692545544872}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"BT score (all data)\", \"score\": 939.4146880929346}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"BT score (all data)\", \"score\": 961.8949149989148}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 958.7224838400415}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 893.8161463533579}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"BT score (all data)\", \"score\": 882.1480312352089}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"BT score (all data)\", \"score\": 921.064492572327}, {\"model_name\": \"lfm-40b\", \"score_type\": \"BT score (all data)\", \"score\": 918.9585188515473}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"BT score (all data)\", \"score\": 873.2032988662598}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"BT score (all data)\", \"score\": 798.219891598359}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"BT score (all data)\", \"score\": 846.4385502475119}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 771.6106727469339}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"BT score (all data)\", \"score\": 775.221400044109}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"BT score (votes data)\", \"score\": 1102.9828201362334}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"BT score (votes data)\", \"score\": 1123.4232397394533}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"BT score (votes data)\", \"score\": 1112.3434299340904}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"BT score (votes data)\", \"score\": 1129.5970636530346}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"BT score (votes data)\", \"score\": 1103.3522481001978}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 1074.5125368686017}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"BT score (votes data)\", \"score\": 1082.5609574483642}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"BT score (votes data)\", \"score\": 1054.415543130385}, {\"model_name\": \"command-a\", \"score_type\": \"BT score (votes data)\", \"score\": 1099.9926507369694}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"BT score (votes data)\", \"score\": 1097.9914042776027}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"BT score (votes data)\", \"score\": 1078.3519161493618}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"BT score (votes data)\", \"score\": 1045.9797221518388}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"BT score (votes data)\", \"score\": 1083.9264775311572}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"BT score (votes data)\", \"score\": 1048.3130800127124}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"BT score (votes data)\", \"score\": 1027.3771777668912}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1062.4293929957742}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"BT score (votes data)\", \"score\": 1036.0825962482613}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"BT score (votes data)\", \"score\": 1032.6830515670285}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 1010.1805033128643}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"BT score (votes data)\", \"score\": 997.952532452616}, {\"model_name\": \"mistral-saba\", \"score_type\": \"BT score (votes data)\", \"score\": 1015.8855265947839}, {\"model_name\": \"o4-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1017.1476578196229}, {\"model_name\": \"phi-4\", \"score_type\": \"BT score (votes data)\", \"score\": 997.8890473294925}, {\"model_name\": \"o3-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1015.0827592478614}, {\"model_name\": \"qwq-32b\", \"score_type\": \"BT score (votes data)\", \"score\": 972.8941166509914}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"BT score (votes data)\", \"score\": 1014.4695073425239}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 1005.4726147903866}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"BT score (votes data)\", \"score\": 985.329325448822}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 980.477102160661}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"BT score (votes data)\", \"score\": 1014.576184860176}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"BT score (votes data)\", \"score\": 996.9173678736327}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"BT score (votes data)\", \"score\": 1047.095708098277}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"BT score (votes data)\", \"score\": 997.3870615790298}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"BT score (votes data)\", \"score\": 995.067395407757}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"BT score (votes data)\", \"score\": 1019.6127254321775}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"BT score (votes data)\", \"score\": 971.8952254768674}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"BT score (votes data)\", \"score\": 986.031800718471}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 960.8247674929568}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 1009.0366876753569}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"BT score (votes data)\", \"score\": 1000.7088676968223}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"BT score (votes data)\", \"score\": 932.5312934343577}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"BT score (votes data)\", \"score\": 954.5332551552957}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 976.3534797719961}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 895.5435216855549}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"BT score (votes data)\", \"score\": 885.9241412186412}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"BT score (votes data)\", \"score\": 922.4280115253187}, {\"model_name\": \"lfm-40b\", \"score_type\": \"BT score (votes data)\", \"score\": 914.5348123170941}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"BT score (votes data)\", \"score\": 872.890557978098}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"BT score (votes data)\", \"score\": 791.1994602240418}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"BT score (votes data)\", \"score\": 848.6297281035158}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 755.6161795477166}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"BT score (votes data)\", \"score\": 816.8197566246365}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import altair as alt\n",
    "\n",
    "df_pl = pl.concat(\n",
    "    [\n",
    "        scores.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo\"}),\n",
    "        scores_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo_votes\"}),\n",
    "        scores_ml.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml\"}),\n",
    "        scores_ml_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml_votes\"}),\n",
    "    ],\n",
    "    how=\"align\",\n",
    ").sort(\"score_elo\", descending=True)\n",
    "\n",
    "df = df_pl.to_pandas()\n",
    "df_long = df.melt(\n",
    "    id_vars=[\"model_name\"],\n",
    "    value_vars=[\"score_elo\", \"score_elo_votes\", \"score_ml\", \"score_ml_votes\"],\n",
    "    var_name=\"score_type\",\n",
    "    value_name=\"score\",\n",
    ")\n",
    "legend_labels = {\n",
    "    \"score_elo\": \"Elo score (all data)\",\n",
    "    \"score_elo_votes\": \"Elo score (votes data)\",\n",
    "    \"score_ml\": \"BT score (all data)\",\n",
    "    \"score_ml_votes\": \"BT score (votes data)\",\n",
    "}\n",
    "df_long[\"score_type\"] = df_long[\"score_type\"].map(legend_labels)\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(df_long)\n",
    "    .mark_circle(size=80)\n",
    "    .encode(\n",
    "        x=alt.X(\"model_name:N\", sort=df[\"model_name\"].tolist(), title=\"model_name\"),\n",
    "        y=alt.Y(\"score:Q\", title=\"Score\", scale=alt.Scale(domain=[500, 1300])),\n",
    "        color=alt.Color(\"score_type:N\", title=\"Score Type\"),\n",
    "        tooltip=[\"model_name\", \"score\", \"score_type\"],\n",
    "    )\n",
    "    .properties(width=600, height=400)\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd13bf",
   "metadata": {},
   "source": [
    "## Scores par catégorie\n",
    "\n",
    "Les méthodes `run_category` et `run_all_categories` permettent de calculer des scores pour une catégorie spécifiée ou pour toutes les catégories (avec un nombre de matchs total supérieur à un seuil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f335bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/3a81e160fed75a8dccf44e59cb8a74c13b981a86 (last modified on Tue Sep 30 13:43:04 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/5a02c58f54f2db3fc51f076d24a840f04efa01fa (last modified on Tue Sep 30 13:43:20 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\", include_votes=True, include_reactions=True, mean_how=\"token\", bootstrap_samples=5, token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccbcb453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 23033 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 21.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>rank</th><th>rank_p2.5</th><th>rank_p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>810.886296</td><td>756.0441</td><td>927.047296</td><td>51</td><td>40</td><td>51</td><td>47531.0</td><td>0.182743</td><td>65</td><td>0.002811</td><td>0.000004</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>1021.787998</td><td>988.34202</td><td>1092.162238</td><td>22</td><td>8</td><td>29</td><td>1.05781e6</td><td>3.98568</td><td>1302</td><td>0.003061</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>922.217773</td><td>841.049174</td><td>1000.393202</td><td>44</td><td>27</td><td>48</td><td>2.747666e6</td><td>20.763975</td><td>3598</td><td>0.005771</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>757.67941</td><td>681.091785</td><td>794.294127</td><td>52</td><td>51</td><td>52</td><td>131187.0</td><td>0.602249</td><td>309</td><td>0.001949</td><td>0.000005</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>812.33883</td><td>754.694448</td><td>945.684688</td><td>50</td><td>40</td><td>52</td><td>533384.0</td><td>1.934863</td><td>1796</td><td>0.001077</td><td>0.000004</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>816.746842</td><td>744.453329</td><td>859.413755</td><td>49</td><td>49</td><td>50</td><td>43550.0</td><td>0.153078</td><td>80</td><td>0.001913</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>1023.736507</td><td>994.053471</td><td>1108.587949</td><td>20</td><td>11</td><td>31</td><td>75812.0</td><td>0.531085</td><td>142</td><td>0.00374</td><td>0.000007</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>967.446611</td><td>901.204991</td><td>1046.532278</td><td>36</td><td>19</td><td>44</td><td>1.186919e6</td><td>4.305576</td><td>1420</td><td>0.003032</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>974.70686</td><td>958.574983</td><td>1000.942753</td><td>34</td><td>28</td><td>37</td><td>4.0819e6</td><td>29.128193</td><td>4954</td><td>0.00588</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>965.806299</td><td>883.352598</td><td>1007.774712</td><td>37</td><td>23</td><td>45</td><td>1.757717e6</td><td>12.542963</td><td>1479</td><td>0.008481</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 12)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ Yi-1.5-9B- ┆ 810.88629 ┆ 756.0441  ┆ 927.04729 ┆ … ┆ 0.182743  ┆ 65      ┆ 0.002811  ┆ 0.000004  │\n",
       "│ Chat       ┆ 6         ┆           ┆ 6         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ aya-expans ┆ 1021.7879 ┆ 988.34202 ┆ 1092.1622 ┆ … ┆ 3.98568   ┆ 1302    ┆ 0.003061  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 98        ┆           ┆ 38        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 922.21777 ┆ 841.04917 ┆ 1000.3932 ┆ … ┆ 20.763975 ┆ 3598    ┆ 0.005771  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆ 3         ┆ 4         ┆ 02        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 757.67941 ┆ 681.09178 ┆ 794.29412 ┆ … ┆ 0.602249  ┆ 309     ┆ 0.001949  ┆ 0.000005  │\n",
       "│ e-14b-inst ┆           ┆ 5         ┆ 7         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ ruct-dpo-v ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 812.33883 ┆ 754.69444 ┆ 945.68468 ┆ … ┆ 1.934863  ┆ 1796    ┆ 0.001077  ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆           ┆ 8         ┆ 8         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ qwen2-7b-i ┆ 816.74684 ┆ 744.45332 ┆ 859.41375 ┆ … ┆ 0.153078  ┆ 80      ┆ 0.001913  ┆ 0.000004  │\n",
       "│ nstruct    ┆ 2         ┆ 9         ┆ 5         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-32 ┆ 1023.7365 ┆ 994.05347 ┆ 1108.5879 ┆ … ┆ 0.531085  ┆ 142     ┆ 0.00374   ┆ 0.000007  │\n",
       "│ b-instruct ┆ 07        ┆ 1         ┆ 49        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 967.44661 ┆ 901.20499 ┆ 1046.5322 ┆ … ┆ 4.305576  ┆ 1420    ┆ 0.003032  ┆ 0.000004  │\n",
       "│ -instruct  ┆ 1         ┆ 1         ┆ 78        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 974.70686 ┆ 958.57498 ┆ 1000.9427 ┆ … ┆ 29.128193 ┆ 4954    ┆ 0.00588   ┆ 0.000007  │\n",
       "│ der-32b-in ┆           ┆ 3         ┆ 53        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 965.80629 ┆ 883.35259 ┆ 1007.7747 ┆ … ┆ 12.542963 ┆ 1479    ┆ 0.008481  ┆ 0.000007  │\n",
       "│            ┆ 9         ┆ 8         ┆ 12        ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.run_category(\"Education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efc06527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 23033 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 22.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 8046 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 69.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 12297 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 41.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 10069 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 11206 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 48.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5281 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 107.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5714 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 99.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 31303 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 15.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 17013 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 13220 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 41.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Other which has less than 1000 matches.\n",
      "Computing bootstrap scores from a sample of 7920 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 70.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5642 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 102.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5913 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 84.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Shopping & Commodity which has less than 1000 matches.\n",
      "Skipping Daily Life & Home & Lifestyle which has less than 1000 matches.\n",
      "Skipping Religion & Spirituality which has less than 1000 matches.\n",
      "Skipping Sports which has less than 1000 matches.\n",
      "Skipping History which has less than 1000 matches.\n",
      "Skipping Real Estate which has less than 1000 matches.\n",
      "Skipping Philosophy which has less than 1000 matches.\n",
      "Skipping International which has less than 1000 matches.\n",
      "Skipping Psychology which has less than 1000 matches.\n",
      "Skipping Security which has less than 1000 matches.\n",
      "Skipping Philosophy & Spirituality which has less than 1000 matches.\n",
      "Skipping Fashion which has less than 1000 matches.\n",
      "Skipping Music which has less than 1000 matches.\n",
      "Skipping Marketing which has less than 1000 matches.\n",
      "Skipping Ethics & Debate which has less than 1000 matches.\n",
      "Skipping Philosophy & logic which has less than 1000 matches.\n",
      "Skipping Philosophy & Ethics which has less than 1000 matches.\n",
      "Skipping Industry which has less than 1000 matches.\n",
      "Skipping Robotics which has less than 1000 matches.\n",
      "Skipping Travel which has less than 1000 matches.\n",
      "Skipping Technology which has less than 1000 matches.\n",
      "Skipping Travel & Hobby which has less than 1000 matches.\n",
      "Skipping Philosophy and Ethics which has less than 1000 matches.\n",
      "Skipping Theology which has less than 1000 matches.\n",
      "Skipping Anthropology which has less than 1000 matches.\n",
      "Skipping Philosophy & Religion which has less than 1000 matches.\n",
      "Skipping Urban Planning which has less than 1000 matches.\n",
      "Skipping Agriculture which has less than 1000 matches.\n",
      "Skipping Linguistics which has less than 1000 matches.\n",
      "Skipping Philosophy & Metaphysics which has less than 1000 matches.\n",
      "Skipping Psychology & Mental Health which has less than 1000 matches.\n",
      "Skipping Sociology which has less than 1000 matches.\n",
      "Skipping Architecture and construction which has less than 1000 matches.\n",
      "Skipping Industry and artisanat which has less than 1000 matches.\n",
      "Skipping Biotechnology which has less than 1000 matches.\n",
      "Skipping Marketing & Sales which has less than 1000 matches.\n",
      "Skipping Mathematics which has less than 1000 matches.\n",
      "Skipping Engineering which has less than 1000 matches.\n",
      "Skipping Ethics which has less than 1000 matches.\n"
     ]
    }
   ],
   "source": [
    "results = pipeline.run_all_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3972e690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Education': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemini-2.0-flash-exp   ┆ 1198.777772 ┆ 1061.365262 ┆ 1277.037143 ┆ 1    ┆ 1         ┆ 16         │\n",
       " │ deepseek-v3-chat       ┆ 1158.249867 ┆ 1137.461276 ┆ 1190.193932 ┆ 2    ┆ 2         ┆ 4          │\n",
       " │ deepseek-v3-0324       ┆ 1142.399506 ┆ 1099.362764 ┆ 1152.515567 ┆ 3    ┆ 4         ┆ 8          │\n",
       " │ gemma-3-27b            ┆ 1130.114202 ┆ 1038.312915 ┆ 1186.550402 ┆ 4    ┆ 3         ┆ 19         │\n",
       " │ gemini-1.5-pro-001     ┆ 1112.283105 ┆ 1043.289601 ┆ 1152.517116 ┆ 5    ┆ 1         ┆ 16         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ mixtral-8x22b-instruct ┆ 849.104217  ┆ 768.111364  ┆ 886.283398  ┆ 48   ┆ 47        ┆ 50         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ Yi-1.5-9B-Chat         ┆ 847.061237  ┆ 811.689674  ┆ 865.817851  ┆ 49   ┆ 46        ┆ 51         │\n",
       " │ chocolatine-2-14b-inst ┆ 825.714266  ┆ 785.80767   ┆ 879.451853  ┆ 50   ┆ 46        ┆ 52         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ qwen2-7b-instruct      ┆ 794.097817  ┆ 734.635602  ┆ 819.578525  ┆ 51   ┆ 50        ┆ 52         │\n",
       " │ chocolatine-14b-instru ┆ 764.82766   ┆ 721.85181   ┆ 849.551001  ┆ 52   ┆ 48        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Arts': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ deepseek-v3-chat       ┆ 1148.154778 ┆ 1081.154106 ┆ 1180.544092 ┆ 1    ┆ 2         ┆ 10         │\n",
       " │ gemini-2.0-flash-001   ┆ 1145.007919 ┆ 1095.604205 ┆ 1207.214314 ┆ 2    ┆ 1         ┆ 11         │\n",
       " │ gemma-3-27b            ┆ 1140.025333 ┆ 1036.425139 ┆ 1209.641599 ┆ 3    ┆ 1         ┆ 23         │\n",
       " │ gemini-2.0-flash-exp   ┆ 1131.265962 ┆ 1098.029107 ┆ 1183.644691 ┆ 4    ┆ 1         ┆ 9          │\n",
       " │ claude-3-7-sonnet      ┆ 1127.460102 ┆ 1084.708395 ┆ 1160.193853 ┆ 5    ┆ 3         ┆ 11         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ qwen2-7b-instruct      ┆ 861.894439  ┆ 826.900251  ┆ 912.281747  ┆ 48   ┆ 42        ┆ 48         │\n",
       " │ qwen2.5-7b-instruct    ┆ 857.175377  ┆ 820.803844  ┆ 929.931551  ┆ 49   ┆ 41        ┆ 49         │\n",
       " │ chocolatine-14b-instru ┆ 812.223284  ┆ 724.90637   ┆ 888.974981  ┆ 50   ┆ 47        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-2-14b-inst ┆ 792.897735  ┆ 755.411191  ┆ 854.268348  ┆ 51   ┆ 50        ┆ 52         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ Yi-1.5-9B-Chat         ┆ 790.657477  ┆ 763.229728  ┆ 845.18319   ┆ 52   ┆ 49        ┆ 52         │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Entertainment & Travel & Hobby': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemini-2.0-flash-001   ┆ 1173.571551 ┆ 1021.075712 ┆ 1264.846905 ┆ 1    ┆ 1         ┆ 18         │\n",
       " │ command-a              ┆ 1156.590598 ┆ 1045.752434 ┆ 1186.790014 ┆ 2    ┆ 2         ┆ 20         │\n",
       " │ gemini-2.0-flash-exp   ┆ 1124.002551 ┆ 1009.729174 ┆ 1244.845038 ┆ 3    ┆ 2         ┆ 23         │\n",
       " │ jamba-1.5-large        ┆ 1115.449905 ┆ 998.554184  ┆ 1211.76436  ┆ 4    ┆ 1         ┆ 28         │\n",
       " │ deepseek-v3-chat       ┆ 1113.109128 ┆ 1064.455562 ┆ 1203.323711 ┆ 5    ┆ 1         ┆ 14         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ mistral-nemo-2407      ┆ 889.049434  ┆ 750.439864  ┆ 954.34446   ┆ 48   ┆ 38        ┆ 52         │\n",
       " │ qwen2-7b-instruct      ┆ 873.136075  ┆ 831.755231  ┆ 887.165327  ┆ 49   ┆ 47        ┆ 51         │\n",
       " │ chocolatine-14b-instru ┆ 842.90773   ┆ 760.570632  ┆ 899.216819  ┆ 50   ┆ 46        ┆ 51         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-2-14b-inst ┆ 831.692491  ┆ 795.186261  ┆ 895.171045  ┆ 51   ┆ 45        ┆ 52         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ Yi-1.5-9B-Chat         ┆ 809.10443   ┆ 763.714921  ┆ 852.835667  ┆ 52   ┆ 49        ┆ 52         │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Culture & Cultural geography': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ claude-3-7-sonnet      ┆ 1139.40317  ┆ 1042.329999 ┆ 1183.87232  ┆ 1    ┆ 1         ┆ 19         │\n",
       " │ gemma-3-27b            ┆ 1124.613413 ┆ 1086.741716 ┆ 1178.450065 ┆ 2    ┆ 2         ┆ 8          │\n",
       " │ gemini-2.0-flash-exp   ┆ 1109.299114 ┆ 1082.50001  ┆ 1193.498453 ┆ 3    ┆ 1         ┆ 11         │\n",
       " │ gemini-2.0-flash-001   ┆ 1100.324091 ┆ 1046.104694 ┆ 1161.482965 ┆ 4    ┆ 3         ┆ 17         │\n",
       " │ gemini-1.5-pro-001     ┆ 1096.284892 ┆ 1001.849884 ┆ 1124.59438  ┆ 5    ┆ 3         ┆ 28         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ mixtral-8x7b-instruct- ┆ 900.448893  ┆ 875.974768  ┆ 1010.959256 ┆ 48   ┆ 27        ┆ 48         │\n",
       " │ v0.1                   ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ qwen2.5-coder-32b-inst ┆ 892.376403  ┆ 868.29252   ┆ 947.083748  ┆ 49   ┆ 40        ┆ 49         │\n",
       " │ ruct                   ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ qwen2-7b-instruct      ┆ 872.69777   ┆ 801.093554  ┆ 944.353063  ┆ 50   ┆ 39        ┆ 52         │\n",
       " │ chocolatine-2-14b-inst ┆ 851.793439  ┆ 801.025452  ┆ 921.600429  ┆ 51   ┆ 48        ┆ 51         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-14b-instru ┆ 768.72292   ┆ 670.132978  ┆ 829.876982  ┆ 52   ┆ 51        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Politics & Government': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemini-2.0-flash-exp   ┆ 1195.479818 ┆ 1112.17436  ┆ 1253.287622 ┆ 1    ┆ 1         ┆ 5          │\n",
       " │ gemma-3-27b            ┆ 1189.933771 ┆ 1105.589758 ┆ 1238.495534 ┆ 2    ┆ 1         ┆ 6          │\n",
       " │ gemma-3-12b            ┆ 1130.595399 ┆ 1074.511588 ┆ 1158.767534 ┆ 3    ┆ 2         ┆ 13         │\n",
       " │ deepseek-v3-chat       ┆ 1100.669102 ┆ 1023.484959 ┆ 1182.962514 ┆ 4    ┆ 1         ┆ 23         │\n",
       " │ gemma-3-4b             ┆ 1091.758488 ┆ 990.704792  ┆ 1112.7194   ┆ 5    ┆ 5         ┆ 30         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ mixtral-8x7b-instruct- ┆ 900.031289  ┆ 836.217771  ┆ 1045.139581 ┆ 48   ┆ 16        ┆ 49         │\n",
       " │ v0.1                   ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mixtral-8x22b-instruct ┆ 870.007805  ┆ 793.589134  ┆ 1008.838434 ┆ 49   ┆ 25        ┆ 51         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mistral-nemo-2407      ┆ 861.26703   ┆ 850.986066  ┆ 955.69329   ┆ 50   ┆ 37        ┆ 49         │\n",
       " │ chocolatine-2-14b-inst ┆ 851.163854  ┆ 704.705721  ┆ 967.068017  ┆ 51   ┆ 35        ┆ 51         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-14b-instru ┆ 689.58948   ┆ 630.932196  ┆ 754.371682  ┆ 52   ┆ 52        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Food & Drink & Cooking': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemini-2.0-flash-exp   ┆ 1194.21009  ┆ 1135.055952 ┆ 1244.4604   ┆ 1    ┆ 1         ┆ 5          │\n",
       " │ gemini-2.0-flash-001   ┆ 1171.202632 ┆ 1126.691009 ┆ 1268.582967 ┆ 2    ┆ 1         ┆ 6          │\n",
       " │ deepseek-v3-chat       ┆ 1145.152817 ┆ 1049.659776 ┆ 1177.328119 ┆ 3    ┆ 2         ┆ 15         │\n",
       " │ gemma-3-27b            ┆ 1142.891995 ┆ 1081.926396 ┆ 1174.044117 ┆ 4    ┆ 3         ┆ 14         │\n",
       " │ gemini-1.5-pro-001     ┆ 1134.819521 ┆ 1108.773032 ┆ 1196.536136 ┆ 5    ┆ 2         ┆ 7          │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ mixtral-8x22b-instruct ┆ 878.154985  ┆ 813.85854   ┆ 961.47443   ┆ 48   ┆ 35        ┆ 49         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mixtral-8x7b-instruct- ┆ 876.034483  ┆ 825.349248  ┆ 960.962807  ┆ 49   ┆ 35        ┆ 51         │\n",
       " │ v0.1                   ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mistral-nemo-2407      ┆ 850.283619  ┆ 759.429784  ┆ 889.794199  ┆ 50   ┆ 46        ┆ 52         │\n",
       " │ chocolatine-14b-instru ┆ 787.846777  ┆ 755.275916  ┆ 915.7713    ┆ 51   ┆ 47        ┆ 51         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-2-14b-inst ┆ 776.137125  ┆ 696.470301  ┆ 804.440716  ┆ 52   ┆ 50        ┆ 52         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Law & Justice': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemini-2.0-flash-exp   ┆ 1217.897281 ┆ 1038.619833 ┆ 1283.658336 ┆ 1    ┆ 1         ┆ 20         │\n",
       " │ gemma-3-27b            ┆ 1164.905429 ┆ 1098.442147 ┆ 1212.773172 ┆ 2    ┆ 1         ┆ 9          │\n",
       " │ deepseek-v3-chat       ┆ 1163.972041 ┆ 1140.213834 ┆ 1213.886031 ┆ 3    ┆ 1         ┆ 3          │\n",
       " │ gemma-3-12b            ┆ 1120.573472 ┆ 1011.208099 ┆ 1185.099346 ┆ 4    ┆ 4         ┆ 22         │\n",
       " │ gemini-2.0-flash-001   ┆ 1102.928269 ┆ 1045.948859 ┆ 1172.267416 ┆ 5    ┆ 2         ┆ 16         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ phi-3.5-mini-instruct  ┆ 873.306039  ┆ 807.563565  ┆ 918.765875  ┆ 48   ┆ 44        ┆ 52         │\n",
       " │ mistral-nemo-2407      ┆ 835.168321  ┆ 731.314148  ┆ 865.735962  ┆ 49   ┆ 47        ┆ 52         │\n",
       " │ mixtral-8x22b-instruct ┆ 830.218579  ┆ 814.45466   ┆ 851.346241  ┆ 50   ┆ 48        ┆ 51         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-14b-instru ┆ 822.808923  ┆ 784.576974  ┆ 838.165744  ┆ 51   ┆ 49        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-2-14b-inst ┆ 812.987705  ┆ 793.297759  ┆ 902.088123  ┆ 52   ┆ 45        ┆ 51         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Natural Science & Formal Science & Technology': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemini-2.0-flash-001   ┆ 1159.563926 ┆ 1101.779869 ┆ 1234.222226 ┆ 1    ┆ 1         ┆ 9          │\n",
       " │ gemma-3-27b            ┆ 1152.621621 ┆ 1073.432466 ┆ 1173.237172 ┆ 2    ┆ 2         ┆ 18         │\n",
       " │ gemma-3-12b            ┆ 1149.573513 ┆ 1108.222307 ┆ 1196.876455 ┆ 3    ┆ 1         ┆ 8          │\n",
       " │ claude-3-7-sonnet      ┆ 1138.615228 ┆ 1048.909379 ┆ 1171.108738 ┆ 4    ┆ 3         ┆ 19         │\n",
       " │ deepseek-v3-chat       ┆ 1129.161836 ┆ 1068.618981 ┆ 1161.234837 ┆ 5    ┆ 3         ┆ 13         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ mixtral-8x7b-instruct- ┆ 845.374237  ┆ 833.403399  ┆ 942.165447  ┆ 48   ┆ 38        ┆ 47         │\n",
       " │ v0.1                   ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mixtral-8x22b-instruct ┆ 837.878769  ┆ 768.900817  ┆ 946.781669  ┆ 49   ┆ 41        ┆ 50         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ Yi-1.5-9B-Chat         ┆ 829.909932  ┆ 725.346398  ┆ 849.84374   ┆ 50   ┆ 48        ┆ 52         │\n",
       " │ chocolatine-2-14b-inst ┆ 809.361517  ┆ 771.120039  ┆ 834.03739   ┆ 51   ┆ 49        ┆ 52         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-14b-instru ┆ 773.538473  ┆ 762.720637  ┆ 896.848937  ┆ 52   ┆ 44        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Business & Economics & Finance': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ command-a              ┆ 1180.754193 ┆ 1099.039009 ┆ 1234.197288 ┆ 1    ┆ 1         ┆ 8          │\n",
       " │ gemini-2.0-flash-exp   ┆ 1177.710456 ┆ 1108.908937 ┆ 1208.029134 ┆ 2    ┆ 1         ┆ 6          │\n",
       " │ gemma-3-27b            ┆ 1150.36404  ┆ 1102.860384 ┆ 1237.865111 ┆ 3    ┆ 1         ┆ 7          │\n",
       " │ gemini-1.5-pro-001     ┆ 1129.289104 ┆ 972.308344  ┆ 1180.625781 ┆ 4    ┆ 1         ┆ 30         │\n",
       " │ deepseek-v3-0324       ┆ 1117.250413 ┆ 1081.966001 ┆ 1132.37347  ┆ 5    ┆ 4         ┆ 11         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ hermes-3-llama-3.1-405 ┆ 862.301857  ┆ 842.164344  ┆ 952.563698  ┆ 48   ┆ 35        ┆ 48         │\n",
       " │ b                      ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ chocolatine-2-14b-inst ┆ 847.772645  ┆ 796.582076  ┆ 949.670834  ┆ 49   ┆ 34        ┆ 51         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mixtral-8x22b-instruct ┆ 828.377028  ┆ 790.489056  ┆ 882.972193  ┆ 50   ┆ 45        ┆ 52         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mistral-nemo-2407      ┆ 827.041629  ┆ 725.1884    ┆ 933.148916  ┆ 51   ┆ 40        ┆ 52         │\n",
       " │ chocolatine-14b-instru ┆ 812.844682  ┆ 713.668873  ┆ 886.980645  ┆ 52   ┆ 47        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Society & Social Issues & Human Rights': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemini-2.0-flash-exp   ┆ 1200.954312 ┆ 1027.939982 ┆ 1230.911481 ┆ 1    ┆ 1         ┆ 20         │\n",
       " │ gemma-3-12b            ┆ 1149.1457   ┆ 1105.555139 ┆ 1201.627485 ┆ 2    ┆ 2         ┆ 8          │\n",
       " │ gemini-1.5-pro-001     ┆ 1141.463944 ┆ 999.567825  ┆ 1257.35155  ┆ 3    ┆ 1         ┆ 26         │\n",
       " │ gemma-3-4b             ┆ 1123.010538 ┆ 1065.563031 ┆ 1203.347275 ┆ 4    ┆ 3         ┆ 15         │\n",
       " │ gemini-2.0-flash-001   ┆ 1119.303758 ┆ 1034.25386  ┆ 1227.029493 ┆ 5    ┆ 1         ┆ 22         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ mistral-nemo-2407      ┆ 878.744718  ┆ 829.964714  ┆ 1021.765895 ┆ 48   ┆ 25        ┆ 50         │\n",
       " │ lfm-40b                ┆ 875.859597  ┆ 834.921778  ┆ 1054.305439 ┆ 49   ┆ 16        ┆ 49         │\n",
       " │ chocolatine-2-14b-inst ┆ 802.985221  ┆ 774.551801  ┆ 854.489277  ┆ 50   ┆ 48        ┆ 51         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ qwen2-7b-instruct      ┆ 758.609519  ┆ 750.120435  ┆ 847.992335  ┆ 51   ┆ 48        ┆ 52         │\n",
       " │ chocolatine-14b-instru ┆ 683.438937  ┆ 616.735613  ┆ 754.993855  ┆ 52   ┆ 51        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Personal Development & Human Resources & Career': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ llama-3.1-nemotron-70b ┆ 1146.172295 ┆ 1069.642999 ┆ 1201.942709 ┆ 1    ┆ 1         ┆ 16         │\n",
       " │ -instruc…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ gemini-2.0-flash-exp   ┆ 1138.80608  ┆ 1099.070614 ┆ 1182.989091 ┆ 2    ┆ 1         ┆ 7          │\n",
       " │ deepseek-v3-0324       ┆ 1132.838364 ┆ 1116.494451 ┆ 1164.851168 ┆ 3    ┆ 2         ┆ 5          │\n",
       " │ gemini-1.5-pro-001     ┆ 1114.310815 ┆ 1077.154988 ┆ 1168.242824 ┆ 4    ┆ 2         ┆ 10         │\n",
       " │ command-a              ┆ 1113.330095 ┆ 1088.683851 ┆ 1183.602711 ┆ 5    ┆ 1         ┆ 12         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ chocolatine-14b-instru ┆ 882.409683  ┆ 771.858587  ┆ 897.822893  ┆ 48   ┆ 42        ┆ 52         │\n",
       " │ ct-dpo-v…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ phi-3.5-mini-instruct  ┆ 875.354768  ┆ 839.150316  ┆ 952.368306  ┆ 49   ┆ 38        ┆ 51         │\n",
       " │ mixtral-8x22b-instruct ┆ 846.753736  ┆ 783.022605  ┆ 908.194347  ┆ 50   ┆ 44        ┆ 52         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mistral-nemo-2407      ┆ 839.735136  ┆ 794.459681  ┆ 945.842472  ┆ 51   ┆ 37        ┆ 51         │\n",
       " │ chocolatine-2-14b-inst ┆ 822.268013  ┆ 758.037156  ┆ 900.763624  ┆ 52   ┆ 45        ┆ 52         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Environment': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemini-2.0-flash-exp   ┆ 1174.47935  ┆ 1062.157663 ┆ 1215.007204 ┆ 1    ┆ 1         ┆ 15         │\n",
       " │ gemma-2-27b-it-q8      ┆ 1156.524019 ┆ 1078.05378  ┆ 1193.8264   ┆ 2    ┆ 1         ┆ 12         │\n",
       " │ deepseek-v3-chat       ┆ 1143.53137  ┆ 1045.585301 ┆ 1193.968266 ┆ 3    ┆ 2         ┆ 16         │\n",
       " │ gemma-3-4b             ┆ 1134.785615 ┆ 1081.564247 ┆ 1165.262261 ┆ 4    ┆ 1         ┆ 11         │\n",
       " │ gemini-1.5-pro-001     ┆ 1134.645432 ┆ 1030.55527  ┆ 1192.25802  ┆ 5    ┆ 1         ┆ 19         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ claude-3-5-sonnet-v2   ┆ 905.113974  ┆ 897.15027   ┆ 956.953724  ┆ 48   ┆ 36        ┆ 45         │\n",
       " │ mistral-nemo-2407      ┆ 882.417906  ┆ 774.031112  ┆ 940.624354  ┆ 49   ┆ 40        ┆ 52         │\n",
       " │ phi-3.5-mini-instruct  ┆ 879.35285   ┆ 783.726103  ┆ 920.282138  ┆ 50   ┆ 45        ┆ 51         │\n",
       " │ chocolatine-2-14b-inst ┆ 832.401439  ┆ 780.195319  ┆ 886.100528  ┆ 51   ┆ 45        ┆ 51         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mixtral-8x22b-instruct ┆ 818.45975   ┆ 754.019645  ┆ 846.281339  ┆ 52   ┆ 48        ┆ 52         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘,\n",
       " 'Health & Wellness & Medicine': shape: (52, 7)\n",
       " ┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       " │ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       " │ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       " │ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       " ╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       " │ gemma-3-12b            ┆ 1171.632628 ┆ 1134.884717 ┆ 1208.526305 ┆ 1    ┆ 1         ┆ 6          │\n",
       " │ gemini-2.0-flash-001   ┆ 1159.544685 ┆ 1090.631848 ┆ 1181.052096 ┆ 2    ┆ 2         ┆ 13         │\n",
       " │ deepseek-v3-0324       ┆ 1156.744844 ┆ 1117.253566 ┆ 1197.864809 ┆ 3    ┆ 1         ┆ 9          │\n",
       " │ gemini-2.0-flash-exp   ┆ 1138.358896 ┆ 1060.568794 ┆ 1154.178991 ┆ 4    ┆ 3         ┆ 14         │\n",
       " │ gemma-3-27b            ┆ 1127.74585  ┆ 969.929693  ┆ 1164.662166 ┆ 5    ┆ 3         ┆ 37         │\n",
       " │ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       " │ qwen2.5-7b-instruct    ┆ 892.983135  ┆ 860.032593  ┆ 1048.407279 ┆ 48   ┆ 14        ┆ 47         │\n",
       " │ mixtral-8x22b-instruct ┆ 872.067194  ┆ 815.465974  ┆ 894.261331  ┆ 49   ┆ 44        ┆ 50         │\n",
       " │ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mixtral-8x7b-instruct- ┆ 841.987174  ┆ 793.184279  ┆ 864.672199  ┆ 50   ┆ 48        ┆ 51         │\n",
       " │ v0.1                   ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " │ mistral-nemo-2407      ┆ 841.201555  ┆ 788.622381  ┆ 867.095298  ┆ 51   ┆ 47        ┆ 52         │\n",
       " │ chocolatine-2-14b-inst ┆ 765.448603  ┆ 707.803784  ┆ 851.564854  ┆ 52   ┆ 49        ┆ 52         │\n",
       " │ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       " └────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04843dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
