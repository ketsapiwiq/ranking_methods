{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass()\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_TOKEN\"] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "comparia = datasets.load_dataset(\n",
    "    \"ministere-culture/comparia-reactions\",\n",
    "    cache_dir=\"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia: pl.DataFrame = comparia.to_polars()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia_model_a = (\n",
    "    comparia.group_by([\"model_a_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_a_name\")\n",
    "    .drop(\"model_a_name\")\n",
    ")\n",
    "comparia_model_b = (\n",
    "    comparia.group_by([\"model_b_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_b_name\")\n",
    "    .drop(\"model_b_name\")\n",
    ")\n",
    "number_by_model = (\n",
    "    pl.concat([comparia_model_a, comparia_model_b]).group_by(\"model_name\").sum().sort(\"len\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>3894</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>3857</td></tr><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>3816</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>3514</td></tr><tr><td>&quot;llama-3.1-405b&quot;</td><td>3409</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;gemma-3-12b&quot;</td><td>408</td></tr><tr><td>&quot;mistral-small-3.1-24b&quot;</td><td>383</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>381</td></tr><tr><td>&quot;gemma-2-27b-it-q8&quot;</td><td>296</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>237</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 2)\n",
       "┌────────────────────────┬──────┐\n",
       "│ model_name             ┆ len  │\n",
       "│ ---                    ┆ ---  │\n",
       "│ str                    ┆ u32  │\n",
       "╞════════════════════════╪══════╡\n",
       "│ gpt-4o-2024-08-06      ┆ 3894 │\n",
       "│ deepseek-v3-chat       ┆ 3857 │\n",
       "│ gpt-4o-mini-2024-07-18 ┆ 3816 │\n",
       "│ claude-3-5-sonnet-v2   ┆ 3514 │\n",
       "│ llama-3.1-405b         ┆ 3409 │\n",
       "│ …                      ┆ …    │\n",
       "│ gemma-3-12b            ┆ 408  │\n",
       "│ mistral-small-3.1-24b  ┆ 383  │\n",
       "│ gemma-3-4b             ┆ 381  │\n",
       "│ gemma-2-27b-it-q8      ┆ 296  │\n",
       "│ jamba-1.5-large        ┆ 237  │\n",
       "└────────────────────────┴──────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(comparia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;mistral-small-24b-instruct-250…</td><td>&quot;mistral-large-2411&quot;</td><td>&quot;71e04e857dfc45319c259493c3bd33…</td><td>0</td><td>1</td></tr><tr><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;gemini-2.0-flash-exp&quot;</td><td>&quot;abf3a7f173a94365ac2a86766d5f8a…</td><td>-4</td><td>5</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>&quot;command-a&quot;</td><td>&quot;4bd0e7f4cb2440d6ab17dc5a15e1ee…</td><td>-2</td><td>1</td></tr><tr><td>&quot;mistral-large-2411&quot;</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;a39fc656efe44dc09304f599453c43…</td><td>-1</td><td>3</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;gemma-2-9b-it&quot;</td><td>&quot;8f9f1ccfddd24e5a8fb51982970909…</td><td>0</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌───────────────────────────┬──────────────────────┬───────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name              ┆ model_b_name         ┆ conversation_pair_id      ┆ score_a ┆ score_b │\n",
       "│ ---                       ┆ ---                  ┆ ---                       ┆ ---     ┆ ---     │\n",
       "│ str                       ┆ str                  ┆ str                       ┆ i64     ┆ i64     │\n",
       "╞═══════════════════════════╪══════════════════════╪═══════════════════════════╪═════════╪═════════╡\n",
       "│ mistral-small-24b-instruc ┆ mistral-large-2411   ┆ 71e04e857dfc45319c259493c ┆ 0       ┆ 1       │\n",
       "│ t-250…                    ┆                      ┆ 3bd33…                    ┆         ┆         │\n",
       "│ gemini-1.5-pro-002        ┆ gemini-2.0-flash-exp ┆ abf3a7f173a94365ac2a86766 ┆ -4      ┆ 5       │\n",
       "│                           ┆                      ┆ d5f8a…                    ┆         ┆         │\n",
       "│ chocolatine-2-14b-instruc ┆ command-a            ┆ 4bd0e7f4cb2440d6ab17dc5a1 ┆ -2      ┆ 1       │\n",
       "│ t-v2.…                    ┆                      ┆ 5e1ee…                    ┆         ┆         │\n",
       "│ mistral-large-2411        ┆ claude-3-5-sonnet-v2 ┆ a39fc656efe44dc09304f5994 ┆ -1      ┆ 3       │\n",
       "│                           ┆                      ┆ 53c43…                    ┆         ┆         │\n",
       "│ llama-3.1-8b              ┆ gemma-2-9b-it        ┆ 8f9f1ccfddd24e5a8fb519829 ┆ 0       ┆ 2       │\n",
       "│                           ┆                      ┆ 70909…                    ┆         ┆         │\n",
       "└───────────────────────────┴──────────────────────┴───────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>275</td><td>202</td><td>73.454545</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1511</td><td>1065</td><td>70.483124</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>434</td><td>301</td><td>69.354839</td></tr><tr><td>&quot;command-a&quot;</td><td>208</td><td>141</td><td>67.788462</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1440</td><td>430</td><td>29.861111</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ gemma-3-27b                     ┆ 275  ┆ 202  ┆ 73.454545 │\n",
       "│ deepseek-v3-chat                ┆ 1511 ┆ 1065 ┆ 70.483124 │\n",
       "│ gemini-2.0-flash-001            ┆ 434  ┆ 301  ┆ 69.354839 │\n",
       "│ command-a                       ┆ 208  ┆ 141  ┆ 67.788462 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1440 ┆ 430  ┆ 29.861111 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma-3-27b : 1156.0486512649727\n",
      "gemini-2.0-flash-exp : 1150.1602912876206\n",
      "deepseek-v3-chat : 1125.1919281182347\n",
      "gemini-2.0-flash-001 : 1123.6845140222883\n",
      "command-a : 1102.9467503281348\n",
      "llama-3.1-nemotron-70b-instruct : 1079.7847337684125\n",
      "gemma-3-12b : 1074.291038064285\n",
      "gemini-1.5-pro-002 : 1069.8553168291314\n",
      "deepseek-r1 : 1064.8458669324705\n",
      "gemma-3-4b : 1058.0982386645562\n",
      "gemini-1.5-pro-001 : 1053.8535513382164\n",
      "mistral-small-3.1-24b : 1042.0602365840293\n",
      "mistral-large-2411 : 1038.6511694741837\n",
      "claude-3-5-sonnet-v2 : 1019.0033262775237\n",
      "llama-3.1-405b : 1018.5229289903359\n",
      "gpt-4o-mini-2024-07-18 : 1017.7388198070615\n",
      "o3-mini : 1007.7727452827941\n",
      "gpt-4o-2024-08-06 : 1005.4396846845273\n",
      "jamba-1.5-large : 996.6073494344724\n",
      "llama-3.3-70b : 996.5877927226035\n",
      "mistral-small-24b-instruct-2501 : 994.1136438084618\n",
      "phi-4 : 993.7654264555771\n",
      "deepseek-r1-distill-llama-70b : 985.0189314843499\n",
      "gemma-2-27b-it-q8 : 983.2483960577565\n",
      "llama-3.1-70b : 982.5898172578559\n",
      "gemma-2-9b-it : 978.6402321674244\n",
      "aya-expanse-8b : 977.2288867092425\n",
      "ministral-8b-instruct-2410 : 967.6289257829593\n",
      "qwq-32b : 954.2838628579716\n",
      "hermes-3-llama-3.1-405b : 949.8350903223559\n",
      "c4ai-command-r-08-2024 : 943.6313673353529\n",
      "llama-3.1-8b : 939.4824860733424\n",
      "qwen2.5-coder-32b-instruct : 927.1642561403615\n",
      "qwen2.5-7b-instruct : 926.5765290628983\n",
      "lfm-40b : 908.747536569203\n",
      "mixtral-8x7b-instruct-v0.1 : 902.397232329896\n",
      "phi-3.5-mini-instruct : 898.9109591887328\n",
      "mixtral-8x22b-instruct-v0.1 : 875.9316909180659\n",
      "mistral-nemo-2407 : 868.3666471740298\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 841.2931484283056\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1154.1670879122732,\n",
       " 'command-a': 1139.5466574147688,\n",
       " 'gemma-3-12b': 1137.031875816478,\n",
       " 'gemma-3-4b': 1136.335483342115,\n",
       " 'gemini-2.0-flash-001': 1130.7334208177335,\n",
       " 'gemma-3-27b': 1126.4946403630825,\n",
       " 'gemini-1.5-pro-002': 1090.0302601576593,\n",
       " 'deepseek-v3-chat': 1089.2898228891256,\n",
       " 'mistral-small-3.1-24b': 1059.5915419240193,\n",
       " 'deepseek-r1': 1042.6066504794112,\n",
       " 'gemini-1.5-pro-001': 1028.501278401883,\n",
       " 'llama-3.1-70b': 1027.0419065432473,\n",
       " 'gpt-4o-mini-2024-07-18': 1023.1861996143211,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1021.3307252216715,\n",
       " 'jamba-1.5-large': 1018.4061061470616,\n",
       " 'claude-3-5-sonnet-v2': 1013.9789381278949,\n",
       " 'llama-3.3-70b': 1007.373247030111,\n",
       " 'gpt-4o-2024-08-06': 1002.870761825725,\n",
       " 'qwq-32b': 1001.2230929385424,\n",
       " 'o3-mini': 1000.6309714099089,\n",
       " 'llama-3.1-405b': 996.4394335019336,\n",
       " 'c4ai-command-r-08-2024': 991.9649408078149,\n",
       " 'ministral-8b-instruct-2410': 987.3279426089935,\n",
       " 'qwen2.5-7b-instruct': 987.2479906429548,\n",
       " 'gemma-2-9b-it': 980.1352577056639,\n",
       " 'mistral-small-24b-instruct-2501': 977.4701336619767,\n",
       " 'hermes-3-llama-3.1-405b': 975.2947286855316,\n",
       " 'gemma-2-27b-it-q8': 974.475131564415,\n",
       " 'mistral-large-2411': 970.6491662043915,\n",
       " 'phi-4': 948.8105543872806,\n",
       " 'aya-expanse-8b': 947.2067776408927,\n",
       " 'deepseek-r1-distill-llama-70b': 942.3234085159346,\n",
       " 'qwen2.5-coder-32b-instruct': 937.0946059689256,\n",
       " 'llama-3.1-8b': 920.4920458419441,\n",
       " 'mixtral-8x7b-instruct-v0.1': 916.7905239548195,\n",
       " 'lfm-40b': 891.293238505473,\n",
       " 'phi-3.5-mini-instruct': 867.7185194659074,\n",
       " 'mistral-nemo-2407': 855.4081036769587,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 849.2806132651515,\n",
       " 'mixtral-8x22b-instruct-v0.1': 832.2062150159945}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(42)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1221.793689083819,\n",
       " 'gemma-3-12b': 1148.1826597289905,\n",
       " 'gemma-3-27b': 1135.8888035423233,\n",
       " 'command-a': 1121.4580982995947,\n",
       " 'deepseek-v3-chat': 1121.3171590302288,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1098.386096698119,\n",
       " 'deepseek-r1': 1070.7324007588047,\n",
       " 'gemma-3-4b': 1063.279752807947,\n",
       " 'mistral-large-2411': 1047.9870626308698,\n",
       " 'mistral-small-3.1-24b': 1044.0944007008816,\n",
       " 'claude-3-5-sonnet-v2': 1042.7785359594016,\n",
       " 'gemini-1.5-pro-002': 1036.2798065845957,\n",
       " 'mistral-small-24b-instruct-2501': 1034.236011889542,\n",
       " 'gemini-2.0-flash-001': 1031.1886306339286,\n",
       " 'gemini-1.5-pro-001': 1030.7096709576833,\n",
       " 'o3-mini': 1018.6811133063709,\n",
       " 'deepseek-r1-distill-llama-70b': 1017.0813047650392,\n",
       " 'llama-3.3-70b': 1009.6888478013763,\n",
       " 'gemma-2-9b-it': 1008.8204756820937,\n",
       " 'llama-3.1-405b': 1007.491138858506,\n",
       " 'llama-3.1-70b': 1006.1804391859696,\n",
       " 'llama-3.1-8b': 994.1151087595802,\n",
       " 'gpt-4o-mini-2024-07-18': 992.8972656379399,\n",
       " 'ministral-8b-instruct-2410': 986.7619787932464,\n",
       " 'gemma-2-27b-it-q8': 977.3459236914399,\n",
       " 'jamba-1.5-large': 976.0049200591296,\n",
       " 'hermes-3-llama-3.1-405b': 958.841808257551,\n",
       " 'lfm-40b': 947.5071233952165,\n",
       " 'qwen2.5-coder-32b-instruct': 939.8860378964608,\n",
       " 'gpt-4o-2024-08-06': 939.8010230219076,\n",
       " 'phi-4': 936.7520739374767,\n",
       " 'qwq-32b': 931.2811005486413,\n",
       " 'qwen2.5-7b-instruct': 930.0276212635213,\n",
       " 'c4ai-command-r-08-2024': 930.005386832432,\n",
       " 'mixtral-8x7b-instruct-v0.1': 924.9717642318282,\n",
       " 'aya-expanse-8b': 923.4318038423714,\n",
       " 'mistral-nemo-2407': 898.1144917043025,\n",
       " 'phi-3.5-mini-instruct': 871.2420519638225,\n",
       " 'mixtral-8x22b-instruct-v0.1': 854.6601697526925,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 770.096247504344}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(1337)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': np.float64(1071.5911431488407),\n",
       " 'gemma-3-27b': np.float64(1070.6149512161712),\n",
       " 'deepseek-v3-chat': np.float64(1058.7552040623111),\n",
       " 'gemini-2.0-flash-001': np.float64(1058.5208268808342),\n",
       " 'command-a': np.float64(1050.5695593880446),\n",
       " 'llama-3.1-nemotron-70b-instruct': np.float64(1038.0127107423277),\n",
       " 'gemma-3-12b': np.float64(1034.5409904078952),\n",
       " 'deepseek-r1': np.float64(1031.587219159033),\n",
       " 'gemma-3-4b': np.float64(1030.116072155743),\n",
       " 'gemini-1.5-pro-002': np.float64(1028.6351487602242),\n",
       " 'gemini-1.5-pro-001': np.float64(1025.3303833271143),\n",
       " 'mistral-small-3.1-24b': np.float64(1019.7461220960782),\n",
       " 'mistral-large-2411': np.float64(1018.3135817966249),\n",
       " 'llama-3.1-405b': np.float64(1009.1366953721039),\n",
       " 'claude-3-5-sonnet-v2': np.float64(1006.6935189502154),\n",
       " 'gpt-4o-mini-2024-07-18': np.float64(1005.1632698064823),\n",
       " 'o3-mini': np.float64(1004.5772402173053),\n",
       " 'gpt-4o-2024-08-06': np.float64(1002.5159238018146),\n",
       " 'llama-3.3-70b': np.float64(1000.532393964355),\n",
       " 'jamba-1.5-large': np.float64(999.2765808294832),\n",
       " 'mistral-small-24b-instruct-2501': np.float64(998.2313291217116),\n",
       " 'phi-4': np.float64(995.93442251403),\n",
       " 'gemma-2-27b-it-q8': np.float64(994.919325880369),\n",
       " 'deepseek-r1-distill-llama-70b': np.float64(992.0372030341064),\n",
       " 'llama-3.1-70b': np.float64(991.4876165691761),\n",
       " 'gemma-2-9b-it': np.float64(990.1126465726843),\n",
       " 'ministral-8b-instruct-2410': np.float64(987.0897413320048),\n",
       " 'aya-expanse-8b': np.float64(986.9600716967157),\n",
       " 'qwq-32b': np.float64(980.9493976214153),\n",
       " 'hermes-3-llama-3.1-405b': np.float64(976.2327599926916),\n",
       " 'c4ai-command-r-08-2024': np.float64(973.2419407001789),\n",
       " 'llama-3.1-8b': np.float64(971.2998070021388),\n",
       " 'qwen2.5-coder-32b-instruct': np.float64(969.3315289631774),\n",
       " 'qwen2.5-7b-instruct': np.float64(964.7674195261942),\n",
       " 'lfm-40b': np.float64(955.9367836691523),\n",
       " 'phi-3.5-mini-instruct': np.float64(953.6297878497624),\n",
       " 'mixtral-8x7b-instruct-v0.1': np.float64(950.9005188655495),\n",
       " 'mixtral-8x22b-instruct-v0.1': np.float64(939.3698833826462),\n",
       " 'mistral-nemo-2407': np.float64(937.3972390749847),\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': np.float64(925.9410405483087)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.maximum_likelihood import MaximumLikelihoodRanker\n",
    "\n",
    "ranker = MaximumLikelihoodRanker()\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aya-expanse-8b',\n",
       " 'c4ai-command-r-08-2024',\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8',\n",
       " 'claude-3-5-sonnet-v2',\n",
       " 'command-a',\n",
       " 'deepseek-r1',\n",
       " 'deepseek-r1-distill-llama-70b',\n",
       " 'deepseek-v3-chat',\n",
       " 'gemini-1.5-pro-001',\n",
       " 'gemini-1.5-pro-002',\n",
       " 'gemini-2.0-flash-001',\n",
       " 'gemini-2.0-flash-exp',\n",
       " 'gemma-2-27b-it-q8',\n",
       " 'gemma-2-9b-it',\n",
       " 'gemma-3-12b',\n",
       " 'gemma-3-27b',\n",
       " 'gemma-3-4b',\n",
       " 'gpt-4o-2024-08-06',\n",
       " 'gpt-4o-mini-2024-07-18',\n",
       " 'hermes-3-llama-3.1-405b',\n",
       " 'jamba-1.5-large',\n",
       " 'lfm-40b',\n",
       " 'llama-3.1-405b',\n",
       " 'llama-3.1-70b',\n",
       " 'llama-3.1-8b',\n",
       " 'llama-3.1-nemotron-70b-instruct',\n",
       " 'llama-3.3-70b',\n",
       " 'ministral-8b-instruct-2410',\n",
       " 'mistral-large-2411',\n",
       " 'mistral-nemo-2407',\n",
       " 'mistral-small-24b-instruct-2501',\n",
       " 'mistral-small-3.1-24b',\n",
       " 'mixtral-8x22b-instruct-v0.1',\n",
       " 'mixtral-8x7b-instruct-v0.1',\n",
       " 'o3-mini',\n",
       " 'phi-3.5-mini-instruct',\n",
       " 'phi-4',\n",
       " 'qwen2.5-7b-instruct',\n",
       " 'qwen2.5-coder-32b-instruct',\n",
       " 'qwq-32b'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:03<00:00, 29.76it/s]\n"
     ]
    }
   ],
   "source": [
    "ranker = ELORanker(K=40)\n",
    "\n",
    "ranker.add_players(model_names)  # type: ignore\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemma-3-27b&quot;</td><td>1154.441609</td><td>1080.287601</td><td>1228.198377</td></tr><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1166.362917</td><td>1088.292898</td><td>1228.393702</td></tr><tr><td>&quot;llama-3.1-nemotron-70b-instruc…</td><td>1082.746041</td><td>1016.218255</td><td>1163.795486</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1127.974128</td><td>1045.808538</td><td>1217.288659</td></tr><tr><td>&quot;command-a&quot;</td><td>1107.549563</td><td>1038.563985</td><td>1198.142902</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>955.571501</td><td>888.08977</td><td>1017.773079</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>867.894862</td><td>792.95239</td><td>938.15538</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>908.471049</td><td>836.608766</td><td>983.980811</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>894.57041</td><td>823.186301</td><td>962.992924</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>836.654321</td><td>761.282863</td><td>907.286006</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model                           ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemma-3-27b                     ┆ 1154.441609 ┆ 1080.287601 ┆ 1228.198377 │\n",
       "│ gemini-2.0-flash-exp            ┆ 1166.362917 ┆ 1088.292898 ┆ 1228.393702 │\n",
       "│ llama-3.1-nemotron-70b-instruc… ┆ 1082.746041 ┆ 1016.218255 ┆ 1163.795486 │\n",
       "│ gemini-2.0-flash-001            ┆ 1127.974128 ┆ 1045.808538 ┆ 1217.288659 │\n",
       "│ command-a                       ┆ 1107.549563 ┆ 1038.563985 ┆ 1198.142902 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ qwq-32b                         ┆ 955.571501  ┆ 888.08977   ┆ 1017.773079 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 867.894862  ┆ 792.95239   ┆ 938.15538   │\n",
       "│ lfm-40b                         ┆ 908.471049  ┆ 836.608766  ┆ 983.980811  │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 894.57041   ┆ 823.186301  ┆ 962.992924  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 836.654321  ┆ 761.282863  ┆ 907.286006  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [01:48<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "ranker = MaximumLikelihoodRanker()\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemma-3-27b&quot;</td><td>1071.228735</td><td>1054.095027</td><td>1085.856631</td></tr><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1070.70261</td><td>1062.689237</td><td>1078.417569</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1059.31096</td><td>1052.828469</td><td>1065.3792</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1059.401273</td><td>1047.658237</td><td>1071.575883</td></tr><tr><td>&quot;llama-3.1-nemotron-70b-instruc…</td><td>1037.970977</td><td>1029.47792</td><td>1048.945975</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>952.145416</td><td>940.388631</td><td>962.030301</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>954.177657</td><td>936.796446</td><td>966.384446</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>937.481536</td><td>930.563496</td><td>942.746621</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>939.723636</td><td>930.659723</td><td>945.291229</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>925.780614</td><td>912.997114</td><td>940.971991</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model                           ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemma-3-27b                     ┆ 1071.228735 ┆ 1054.095027 ┆ 1085.856631 │\n",
       "│ gemini-2.0-flash-exp            ┆ 1070.70261  ┆ 1062.689237 ┆ 1078.417569 │\n",
       "│ deepseek-v3-chat                ┆ 1059.31096  ┆ 1052.828469 ┆ 1065.3792   │\n",
       "│ gemini-2.0-flash-001            ┆ 1059.401273 ┆ 1047.658237 ┆ 1071.575883 │\n",
       "│ llama-3.1-nemotron-70b-instruc… ┆ 1037.970977 ┆ 1029.47792  ┆ 1048.945975 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 952.145416  ┆ 940.388631  ┆ 962.030301  │\n",
       "│ phi-3.5-mini-instruct           ┆ 954.177657  ┆ 936.796446  ┆ 966.384446  │\n",
       "│ mistral-nemo-2407               ┆ 937.481536  ┆ 930.563496  ┆ 942.746621  │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 939.723636  ┆ 930.659723  ┆ 945.291229  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 925.780614  ┆ 912.997114  ┆ 940.971991  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank-comparia-SXEyBiqD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
