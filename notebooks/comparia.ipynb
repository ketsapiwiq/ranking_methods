{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass()\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_TOKEN\"] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "comparia = datasets.load_dataset(\n",
    "    \"ministere-culture/comparia-reactions\",\n",
    "    cache_dir=\"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia: pl.DataFrame = comparia.to_polars()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia_model_a = (\n",
    "    comparia.group_by([\"model_a_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_a_name\")\n",
    "    .drop(\"model_a_name\")\n",
    ")\n",
    "comparia_model_b = (\n",
    "    comparia.group_by([\"model_b_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_b_name\")\n",
    "    .drop(\"model_b_name\")\n",
    ")\n",
    "number_by_model = (\n",
    "    pl.concat([comparia_model_a, comparia_model_b]).group_by(\"model_name\").sum().sort(\"len\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>3894</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>3857</td></tr><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>3816</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>3514</td></tr><tr><td>&quot;llama-3.1-405b&quot;</td><td>3409</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;gemma-3-12b&quot;</td><td>408</td></tr><tr><td>&quot;mistral-small-3.1-24b&quot;</td><td>383</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>381</td></tr><tr><td>&quot;gemma-2-27b-it-q8&quot;</td><td>296</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>237</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 2)\n",
       "┌────────────────────────┬──────┐\n",
       "│ model_name             ┆ len  │\n",
       "│ ---                    ┆ ---  │\n",
       "│ str                    ┆ u32  │\n",
       "╞════════════════════════╪══════╡\n",
       "│ gpt-4o-2024-08-06      ┆ 3894 │\n",
       "│ deepseek-v3-chat       ┆ 3857 │\n",
       "│ gpt-4o-mini-2024-07-18 ┆ 3816 │\n",
       "│ claude-3-5-sonnet-v2   ┆ 3514 │\n",
       "│ llama-3.1-405b         ┆ 3409 │\n",
       "│ …                      ┆ …    │\n",
       "│ gemma-3-12b            ┆ 408  │\n",
       "│ mistral-small-3.1-24b  ┆ 383  │\n",
       "│ gemma-3-4b             ┆ 381  │\n",
       "│ gemma-2-27b-it-q8      ┆ 296  │\n",
       "│ jamba-1.5-large        ┆ 237  │\n",
       "└────────────────────────┴──────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(comparia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;llama-3.1-405b&quot;</td><td>&quot;ministral-8b-instruct-2410&quot;</td><td>&quot;720b5c23ef07404896536f1945780a…</td><td>2</td><td>0</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>&quot;mistral-large-2411&quot;</td><td>&quot;3a8b72f6f778430ca466d0f056613a…</td><td>0</td><td>1</td></tr><tr><td>&quot;gemma-2-9b-it&quot;</td><td>&quot;mistral-nemo-2407&quot;</td><td>&quot;0731014c941449768290a706b4260b…</td><td>1</td><td>-1</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;45122dc4707a415e937f8195011fda…</td><td>0</td><td>4</td></tr><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;e38d646e2da7432abbe6964d0ed14e…</td><td>5</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────────┬─────────────────────────┬─────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name             ┆ model_b_name            ┆ conversation_pair_id    ┆ score_a ┆ score_b │\n",
       "│ ---                      ┆ ---                     ┆ ---                     ┆ ---     ┆ ---     │\n",
       "│ str                      ┆ str                     ┆ str                     ┆ i64     ┆ i64     │\n",
       "╞══════════════════════════╪═════════════════════════╪═════════════════════════╪═════════╪═════════╡\n",
       "│ llama-3.1-405b           ┆ ministral-8b-instruct-2 ┆ 720b5c23ef07404896536f1 ┆ 2       ┆ 0       │\n",
       "│                          ┆ 410                     ┆ 945780a…                ┆         ┆         │\n",
       "│ mixtral-8x22b-instruct-v ┆ mistral-large-2411      ┆ 3a8b72f6f778430ca466d0f ┆ 0       ┆ 1       │\n",
       "│ 0.1                      ┆                         ┆ 056613a…                ┆         ┆         │\n",
       "│ gemma-2-9b-it            ┆ mistral-nemo-2407       ┆ 0731014c941449768290a70 ┆ 1       ┆ -1      │\n",
       "│                          ┆                         ┆ 6b4260b…                ┆         ┆         │\n",
       "│ mixtral-8x22b-instruct-v ┆ gpt-4o-mini-2024-07-18  ┆ 45122dc4707a415e937f819 ┆ 0       ┆ 4       │\n",
       "│ 0.1                      ┆                         ┆ 5011fda…                ┆         ┆         │\n",
       "│ gpt-4o-mini-2024-07-18   ┆ deepseek-v3-chat        ┆ e38d646e2da7432abbe6964 ┆ 5       ┆ 1       │\n",
       "│                          ┆                         ┆ d0ed14e…                ┆         ┆         │\n",
       "└──────────────────────────┴─────────────────────────┴─────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>275</td><td>202</td><td>73.454545</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1511</td><td>1065</td><td>70.483124</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>434</td><td>301</td><td>69.354839</td></tr><tr><td>&quot;command-a&quot;</td><td>208</td><td>141</td><td>67.788462</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1440</td><td>430</td><td>29.861111</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ gemma-3-27b                     ┆ 275  ┆ 202  ┆ 73.454545 │\n",
       "│ deepseek-v3-chat                ┆ 1511 ┆ 1065 ┆ 70.483124 │\n",
       "│ gemini-2.0-flash-001            ┆ 434  ┆ 301  ┆ 69.354839 │\n",
       "│ command-a                       ┆ 208  ┆ 141  ┆ 67.788462 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1440 ┆ 430  ┆ 29.861111 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1156.1004278778405\n",
      "gemma-3-27b : 1150.1716949861686\n",
      "deepseek-v3-chat : 1125.495745778569\n",
      "gemini-2.0-flash-001 : 1124.8876503681481\n",
      "command-a : 1112.562974819661\n",
      "llama-3.1-nemotron-70b-instruct : 1083.075774833557\n",
      "gemma-3-12b : 1071.4604002616913\n",
      "deepseek-r1 : 1065.478023218923\n",
      "gemini-1.5-pro-002 : 1063.6057012365407\n",
      "gemma-3-4b : 1059.9305784011249\n",
      "gemini-1.5-pro-001 : 1056.5126722499294\n",
      "mistral-small-3.1-24b : 1047.2671006303808\n",
      "mistral-large-2411 : 1036.457386333585\n",
      "claude-3-5-sonnet-v2 : 1024.2494895151578\n",
      "llama-3.1-405b : 1017.5007553771991\n",
      "o3-mini : 1014.4649910360977\n",
      "gpt-4o-mini-2024-07-18 : 1007.8929045031135\n",
      "gpt-4o-2024-08-06 : 1007.0763468989388\n",
      "llama-3.3-70b : 999.6052152769726\n",
      "jamba-1.5-large : 998.3568564325521\n",
      "mistral-small-24b-instruct-2501 : 991.8242932923025\n",
      "gemma-2-27b-it-q8 : 990.6543025310857\n",
      "phi-4 : 987.2785605924513\n",
      "deepseek-r1-distill-llama-70b : 979.4535948223928\n",
      "llama-3.1-70b : 978.6077391509342\n",
      "gemma-2-9b-it : 976.8990809209939\n",
      "aya-expanse-8b : 976.69257457501\n",
      "ministral-8b-instruct-2410 : 973.8067728598329\n",
      "qwq-32b : 963.2837001203542\n",
      "hermes-3-llama-3.1-405b : 943.8373600633506\n",
      "llama-3.1-8b : 942.1177614594686\n",
      "c4ai-command-r-08-2024 : 939.8680063867882\n",
      "qwen2.5-coder-32b-instruct : 939.0328627368222\n",
      "qwen2.5-7b-instruct : 923.9528378446582\n",
      "phi-3.5-mini-instruct : 906.7732699524457\n",
      "lfm-40b : 900.0934981283023\n",
      "mixtral-8x7b-instruct-v0.1 : 894.3513651034561\n",
      "mixtral-8x22b-instruct-v0.1 : 868.7318228612553\n",
      "mistral-nemo-2407 : 861.502496170988\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 839.0854103909583\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepseek-v3-chat': 1159.2933220629432,\n",
       " 'gemma-3-27b': 1131.4826054838509,\n",
       " 'gemini-2.0-flash-exp': 1115.5434587195246,\n",
       " 'command-a': 1112.228637384357,\n",
       " 'deepseek-r1': 1108.0014373805302,\n",
       " 'gemma-3-4b': 1106.4568188126573,\n",
       " 'gemini-1.5-pro-002': 1099.3880616353367,\n",
       " 'mistral-small-3.1-24b': 1090.3709302131715,\n",
       " 'gemini-1.5-pro-001': 1071.5089307256758,\n",
       " 'gemma-3-12b': 1064.9502700017786,\n",
       " 'aya-expanse-8b': 1061.035237293724,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1059.6540036015351,\n",
       " 'o3-mini': 1053.3097242360948,\n",
       " 'gemini-2.0-flash-001': 1036.8512236236552,\n",
       " 'claude-3-5-sonnet-v2': 1021.0011212701257,\n",
       " 'qwq-32b': 1003.6707106743951,\n",
       " 'phi-4': 1000.4463589369606,\n",
       " 'llama-3.1-70b': 998.2657938646969,\n",
       " 'mistral-large-2411': 998.0276305624897,\n",
       " 'jamba-1.5-large': 995.0334584722015,\n",
       " 'mistral-small-24b-instruct-2501': 990.2609533875658,\n",
       " 'gemma-2-9b-it': 983.9516374897088,\n",
       " 'llama-3.1-405b': 983.9372880182531,\n",
       " 'deepseek-r1-distill-llama-70b': 980.0967373139342,\n",
       " 'gemma-2-27b-it-q8': 979.2716824118214,\n",
       " 'gpt-4o-2024-08-06': 975.8591626887234,\n",
       " 'ministral-8b-instruct-2410': 975.1340380378738,\n",
       " 'llama-3.3-70b': 959.4248522576727,\n",
       " 'qwen2.5-coder-32b-instruct': 948.847045081196,\n",
       " 'gpt-4o-mini-2024-07-18': 946.9185073604507,\n",
       " 'llama-3.1-8b': 945.7746013333376,\n",
       " 'qwen2.5-7b-instruct': 937.0845459681367,\n",
       " 'c4ai-command-r-08-2024': 923.128151400648,\n",
       " 'mixtral-8x22b-instruct-v0.1': 917.1869474511699,\n",
       " 'mixtral-8x7b-instruct-v0.1': 916.8749012782317,\n",
       " 'hermes-3-llama-3.1-405b': 912.4959360992729,\n",
       " 'lfm-40b': 889.0844517756933,\n",
       " 'phi-3.5-mini-instruct': 880.9250339639979,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 861.8865708628718,\n",
       " 'mistral-nemo-2407': 805.3372208637352}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(42)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepseek-v3-chat': 1192.4519647836078,\n",
       " 'gemma-3-27b': 1172.5505507546152,\n",
       " 'gemini-2.0-flash-exp': 1149.1984235473246,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1148.5766871691976,\n",
       " 'gemini-2.0-flash-001': 1147.658799637024,\n",
       " 'gemma-3-12b': 1119.050781689956,\n",
       " 'claude-3-5-sonnet-v2': 1083.7977330173142,\n",
       " 'gemini-1.5-pro-002': 1078.9683706881383,\n",
       " 'command-a': 1077.4824644476864,\n",
       " 'gemma-3-4b': 1052.7087714093007,\n",
       " 'deepseek-r1': 1034.5443067702472,\n",
       " 'mistral-small-3.1-24b': 1033.367189127272,\n",
       " 'llama-3.3-70b': 1019.0032678674577,\n",
       " 'gpt-4o-mini-2024-07-18': 1008.0489077877519,\n",
       " 'gemma-2-27b-it-q8': 1006.5294334292803,\n",
       " 'c4ai-command-r-08-2024': 999.1302972363653,\n",
       " 'mistral-small-24b-instruct-2501': 997.0482454845783,\n",
       " 'jamba-1.5-large': 996.0236493428928,\n",
       " 'llama-3.1-405b': 990.9570812984107,\n",
       " 'gemini-1.5-pro-001': 990.4876389890597,\n",
       " 'qwq-32b': 983.8871814740564,\n",
       " 'qwen2.5-7b-instruct': 982.0868234985542,\n",
       " 'o3-mini': 978.350235620246,\n",
       " 'mistral-large-2411': 978.188433626538,\n",
       " 'aya-expanse-8b': 975.878579633954,\n",
       " 'qwen2.5-coder-32b-instruct': 970.2813713487424,\n",
       " 'ministral-8b-instruct-2410': 964.1220516327322,\n",
       " 'phi-3.5-mini-instruct': 960.0946604209119,\n",
       " 'gpt-4o-2024-08-06': 954.5904519368573,\n",
       " 'deepseek-r1-distill-llama-70b': 952.1238628933945,\n",
       " 'phi-4': 949.5104652517845,\n",
       " 'llama-3.1-70b': 941.2158141810621,\n",
       " 'lfm-40b': 940.1562855930745,\n",
       " 'hermes-3-llama-3.1-405b': 922.7966737862338,\n",
       " 'gemma-2-9b-it': 921.9165803830468,\n",
       " 'mixtral-8x7b-instruct-v0.1': 920.6813722910218,\n",
       " 'llama-3.1-8b': 908.895215814704,\n",
       " 'mixtral-8x22b-instruct-v0.1': 879.7592090433683,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 868.089193541482,\n",
       " 'mistral-nemo-2407': 749.7909735507591}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(1337)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': np.float64(1071.5911431488494),\n",
       " 'gemma-3-27b': np.float64(1070.6149512161023),\n",
       " 'deepseek-v3-chat': np.float64(1058.7552040622897),\n",
       " 'gemini-2.0-flash-001': np.float64(1058.5208268807687),\n",
       " 'command-a': np.float64(1050.569559388118),\n",
       " 'llama-3.1-nemotron-70b-instruct': np.float64(1038.0127107423189),\n",
       " 'gemma-3-12b': np.float64(1034.5409904079895),\n",
       " 'deepseek-r1': np.float64(1031.5872191591507),\n",
       " 'gemma-3-4b': np.float64(1030.1160721559013),\n",
       " 'gemini-1.5-pro-002': np.float64(1028.6351487602299),\n",
       " 'gemini-1.5-pro-001': np.float64(1025.330383327195),\n",
       " 'mistral-small-3.1-24b': np.float64(1019.7461220961129),\n",
       " 'mistral-large-2411': np.float64(1018.3135817966071),\n",
       " 'llama-3.1-405b': np.float64(1009.1366953720458),\n",
       " 'claude-3-5-sonnet-v2': np.float64(1006.6935189502087),\n",
       " 'gpt-4o-mini-2024-07-18': np.float64(1005.1632698064324),\n",
       " 'o3-mini': np.float64(1004.5772402173617),\n",
       " 'gpt-4o-2024-08-06': np.float64(1002.5159238018007),\n",
       " 'llama-3.3-70b': np.float64(1000.5323939643387),\n",
       " 'jamba-1.5-large': np.float64(999.2765808293385),\n",
       " 'mistral-small-24b-instruct-2501': np.float64(998.231329121701),\n",
       " 'phi-4': np.float64(995.9344225140206),\n",
       " 'gemma-2-27b-it-q8': np.float64(994.9193258803074),\n",
       " 'deepseek-r1-distill-llama-70b': np.float64(992.0372030340901),\n",
       " 'llama-3.1-70b': np.float64(991.4876165691795),\n",
       " 'gemma-2-9b-it': np.float64(990.112646572699),\n",
       " 'ministral-8b-instruct-2410': np.float64(987.0897413319843),\n",
       " 'aya-expanse-8b': np.float64(986.9600716966606),\n",
       " 'qwq-32b': np.float64(980.9493976214801),\n",
       " 'hermes-3-llama-3.1-405b': np.float64(976.2327599926756),\n",
       " 'c4ai-command-r-08-2024': np.float64(973.2419407001556),\n",
       " 'llama-3.1-8b': np.float64(971.299807002131),\n",
       " 'qwen2.5-coder-32b-instruct': np.float64(969.3315289631795),\n",
       " 'qwen2.5-7b-instruct': np.float64(964.7674195261297),\n",
       " 'lfm-40b': np.float64(955.9367836691282),\n",
       " 'phi-3.5-mini-instruct': np.float64(953.6297878497254),\n",
       " 'mixtral-8x7b-instruct-v0.1': np.float64(950.9005188655188),\n",
       " 'mixtral-8x22b-instruct-v0.1': np.float64(939.3698833826314),\n",
       " 'mistral-nemo-2407': np.float64(937.3972390749907),\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': np.float64(925.9410405484518)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.maximum_likelihood import MaximumLikelihoodRanker\n",
    "\n",
    "ranker = MaximumLikelihoodRanker()\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aya-expanse-8b',\n",
       " 'c4ai-command-r-08-2024',\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8',\n",
       " 'claude-3-5-sonnet-v2',\n",
       " 'command-a',\n",
       " 'deepseek-r1',\n",
       " 'deepseek-r1-distill-llama-70b',\n",
       " 'deepseek-v3-chat',\n",
       " 'gemini-1.5-pro-001',\n",
       " 'gemini-1.5-pro-002',\n",
       " 'gemini-2.0-flash-001',\n",
       " 'gemini-2.0-flash-exp',\n",
       " 'gemma-2-27b-it-q8',\n",
       " 'gemma-2-9b-it',\n",
       " 'gemma-3-12b',\n",
       " 'gemma-3-27b',\n",
       " 'gemma-3-4b',\n",
       " 'gpt-4o-2024-08-06',\n",
       " 'gpt-4o-mini-2024-07-18',\n",
       " 'hermes-3-llama-3.1-405b',\n",
       " 'jamba-1.5-large',\n",
       " 'lfm-40b',\n",
       " 'llama-3.1-405b',\n",
       " 'llama-3.1-70b',\n",
       " 'llama-3.1-8b',\n",
       " 'llama-3.1-nemotron-70b-instruct',\n",
       " 'llama-3.3-70b',\n",
       " 'ministral-8b-instruct-2410',\n",
       " 'mistral-large-2411',\n",
       " 'mistral-nemo-2407',\n",
       " 'mistral-small-24b-instruct-2501',\n",
       " 'mistral-small-3.1-24b',\n",
       " 'mixtral-8x22b-instruct-v0.1',\n",
       " 'mixtral-8x7b-instruct-v0.1',\n",
       " 'o3-mini',\n",
       " 'phi-3.5-mini-instruct',\n",
       " 'phi-4',\n",
       " 'qwen2.5-7b-instruct',\n",
       " 'qwen2.5-coder-32b-instruct',\n",
       " 'qwq-32b'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples.: 100%|██████████| 100/100 [00:03<00:00, 31.00it/s]\n"
     ]
    }
   ],
   "source": [
    "ranker = ELORanker(K=40)\n",
    "\n",
    "ranker.add_players(model_names)  # type: ignore\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1151.630602</td><td>1089.012649</td><td>1214.7701</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1156.796602</td><td>1065.642393</td><td>1231.398323</td></tr><tr><td>&quot;command-a&quot;</td><td>1108.67657</td><td>1028.633901</td><td>1193.283863</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1126.174772</td><td>1042.820364</td><td>1207.251953</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1125.913368</td><td>1043.369645</td><td>1187.758266</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>924.392659</td><td>849.701241</td><td>993.556433</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>942.755426</td><td>863.813279</td><td>1015.934088</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>869.044198</td><td>792.073653</td><td>963.989966</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>866.358855</td><td>788.742152</td><td>925.149116</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>830.420522</td><td>745.632182</td><td>930.597425</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model                           ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 1151.630602 ┆ 1089.012649 ┆ 1214.7701   │\n",
       "│ gemma-3-27b                     ┆ 1156.796602 ┆ 1065.642393 ┆ 1231.398323 │\n",
       "│ command-a                       ┆ 1108.67657  ┆ 1028.633901 ┆ 1193.283863 │\n",
       "│ deepseek-v3-chat                ┆ 1126.174772 ┆ 1042.820364 ┆ 1207.251953 │\n",
       "│ gemini-2.0-flash-001            ┆ 1125.913368 ┆ 1043.369645 ┆ 1187.758266 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ qwen2.5-7b-instruct             ┆ 924.392659  ┆ 849.701241  ┆ 993.556433  │\n",
       "│ qwen2.5-coder-32b-instruct      ┆ 942.755426  ┆ 863.813279  ┆ 1015.934088 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 869.044198  ┆ 792.073653  ┆ 963.989966  │\n",
       "│ mistral-nemo-2407               ┆ 866.358855  ┆ 788.742152  ┆ 925.149116  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 830.420522  ┆ 745.632182  ┆ 930.597425  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples.: 100%|██████████| 100/100 [01:40<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "ranker = MaximumLikelihoodRanker()\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemma-3-27b&quot;</td><td>1071.538146</td><td>1050.597322</td><td>1087.437122</td></tr><tr><td>&quot;command-a&quot;</td><td>1051.795832</td><td>1026.492324</td><td>1070.682596</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1058.029991</td><td>1047.162266</td><td>1070.90866</td></tr><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1072.226837</td><td>1064.511494</td><td>1080.581669</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1058.470982</td><td>1051.058605</td><td>1065.727889</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>954.996164</td><td>947.065501</td><td>963.425475</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>951.471693</td><td>938.301479</td><td>961.632723</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>939.928828</td><td>933.506206</td><td>946.224519</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>937.869592</td><td>931.327491</td><td>945.52133</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>925.523619</td><td>916.176364</td><td>940.23021</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model                           ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemma-3-27b                     ┆ 1071.538146 ┆ 1050.597322 ┆ 1087.437122 │\n",
       "│ command-a                       ┆ 1051.795832 ┆ 1026.492324 ┆ 1070.682596 │\n",
       "│ gemini-2.0-flash-001            ┆ 1058.029991 ┆ 1047.162266 ┆ 1070.90866  │\n",
       "│ gemini-2.0-flash-exp            ┆ 1072.226837 ┆ 1064.511494 ┆ 1080.581669 │\n",
       "│ deepseek-v3-chat                ┆ 1058.470982 ┆ 1051.058605 ┆ 1065.727889 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ lfm-40b                         ┆ 954.996164  ┆ 947.065501  ┆ 963.425475  │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 951.471693  ┆ 938.301479  ┆ 961.632723  │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 939.928828  ┆ 933.506206  ┆ 946.224519  │\n",
       "│ mistral-nemo-2407               ┆ 937.869592  ┆ 931.327491  ┆ 945.52133   │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 925.523619  ┆ 916.176364  ┆ 940.23021   │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank-comparia-SXEyBiqD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
