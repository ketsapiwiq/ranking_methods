{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass()\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_TOKEN\"] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "comparia = datasets.load_dataset(\n",
    "    \"ministere-culture/comparia-reactions\",\n",
    "    cache_dir=\"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia: pl.DataFrame = comparia.to_polars()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia_model_a = (\n",
    "    comparia.group_by([\"model_a_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_a_name\")\n",
    "    .drop(\"model_a_name\")\n",
    ")\n",
    "comparia_model_b = (\n",
    "    comparia.group_by([\"model_b_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_b_name\")\n",
    "    .drop(\"model_b_name\")\n",
    ")\n",
    "number_by_model = (\n",
    "    pl.concat([comparia_model_a, comparia_model_b]).group_by(\"model_name\").sum().sort(\"len\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>3894</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>3857</td></tr><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>3816</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>3514</td></tr><tr><td>&quot;llama-3.1-405b&quot;</td><td>3409</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;gemma-3-12b&quot;</td><td>408</td></tr><tr><td>&quot;mistral-small-3.1-24b&quot;</td><td>383</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>381</td></tr><tr><td>&quot;gemma-2-27b-it-q8&quot;</td><td>296</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>237</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 2)\n",
       "┌────────────────────────┬──────┐\n",
       "│ model_name             ┆ len  │\n",
       "│ ---                    ┆ ---  │\n",
       "│ str                    ┆ u32  │\n",
       "╞════════════════════════╪══════╡\n",
       "│ gpt-4o-2024-08-06      ┆ 3894 │\n",
       "│ deepseek-v3-chat       ┆ 3857 │\n",
       "│ gpt-4o-mini-2024-07-18 ┆ 3816 │\n",
       "│ claude-3-5-sonnet-v2   ┆ 3514 │\n",
       "│ llama-3.1-405b         ┆ 3409 │\n",
       "│ …                      ┆ …    │\n",
       "│ gemma-3-12b            ┆ 408  │\n",
       "│ mistral-small-3.1-24b  ┆ 383  │\n",
       "│ gemma-3-4b             ┆ 381  │\n",
       "│ gemma-2-27b-it-q8      ┆ 296  │\n",
       "│ jamba-1.5-large        ┆ 237  │\n",
       "└────────────────────────┴──────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(comparia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;b5864da64a9f481f9286dfa6c4d6d1…</td><td>0</td><td>-2</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;7784132de47e4ee0b4db402891f5f5…</td><td>3</td><td>3</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;f234054c39434419b2846efd06e3c5…</td><td>0</td><td>1</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;mistral-nemo-2407&quot;</td><td>&quot;ff5e42399c2d4e87961c41bd96bfff…</td><td>1</td><td>-2</td></tr><tr><td>&quot;llama-3.1-70b&quot;</td><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>&quot;2261be2af79a4445946294ae189408…</td><td>-2</td><td>-2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────────┬─────────────────────────┬─────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name             ┆ model_b_name            ┆ conversation_pair_id    ┆ score_a ┆ score_b │\n",
       "│ ---                      ┆ ---                     ┆ ---                     ┆ ---     ┆ ---     │\n",
       "│ str                      ┆ str                     ┆ str                     ┆ i64     ┆ i64     │\n",
       "╞══════════════════════════╪═════════════════════════╪═════════════════════════╪═════════╪═════════╡\n",
       "│ claude-3-5-sonnet-v2     ┆ deepseek-v3-chat        ┆ b5864da64a9f481f9286dfa ┆ 0       ┆ -2      │\n",
       "│                          ┆                         ┆ 6c4d6d1…                ┆         ┆         │\n",
       "│ llama-3.1-8b             ┆ deepseek-v3-chat        ┆ 7784132de47e4ee0b4db402 ┆ 3       ┆ 3       │\n",
       "│                          ┆                         ┆ 891f5f5…                ┆         ┆         │\n",
       "│ mixtral-8x22b-instruct-v ┆ deepseek-v3-chat        ┆ f234054c39434419b2846ef ┆ 0       ┆ 1       │\n",
       "│ 0.1                      ┆                         ┆ d06e3c5…                ┆         ┆         │\n",
       "│ claude-3-5-sonnet-v2     ┆ mistral-nemo-2407       ┆ ff5e42399c2d4e87961c41b ┆ 1       ┆ -2      │\n",
       "│                          ┆                         ┆ d96bfff…                ┆         ┆         │\n",
       "│ llama-3.1-70b            ┆ mixtral-8x22b-instruct- ┆ 2261be2af79a4445946294a ┆ -2      ┆ -2      │\n",
       "│                          ┆ v0.1                    ┆ e189408…                ┆         ┆         │\n",
       "└──────────────────────────┴─────────────────────────┴─────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>275</td><td>202</td><td>73.454545</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1511</td><td>1065</td><td>70.483124</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>434</td><td>301</td><td>69.354839</td></tr><tr><td>&quot;command-a&quot;</td><td>208</td><td>141</td><td>67.788462</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1440</td><td>430</td><td>29.861111</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ gemma-3-27b                     ┆ 275  ┆ 202  ┆ 73.454545 │\n",
       "│ deepseek-v3-chat                ┆ 1511 ┆ 1065 ┆ 70.483124 │\n",
       "│ gemini-2.0-flash-001            ┆ 434  ┆ 301  ┆ 69.354839 │\n",
       "│ command-a                       ┆ 208  ┆ 141  ┆ 67.788462 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1440 ┆ 430  ┆ 29.861111 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1157.2941479234191\n",
      "gemma-3-27b : 1151.017731303702\n",
      "gemini-2.0-flash-001 : 1128.1208818091804\n",
      "deepseek-v3-chat : 1127.2467881834598\n",
      "command-a : 1111.9863135497003\n",
      "llama-3.1-nemotron-70b-instruct : 1085.704619881789\n",
      "gemma-3-12b : 1074.0127135388204\n",
      "deepseek-r1 : 1067.0753052677067\n",
      "gemma-3-4b : 1058.942950664265\n",
      "gemini-1.5-pro-002 : 1055.109890657114\n",
      "gemini-1.5-pro-001 : 1051.7473561303123\n",
      "mistral-small-3.1-24b : 1041.177806252562\n",
      "mistral-large-2411 : 1034.2766890373898\n",
      "claude-3-5-sonnet-v2 : 1020.8692907378431\n",
      "o3-mini : 1016.0008992360407\n",
      "llama-3.1-405b : 1014.7368456157051\n",
      "gpt-4o-2024-08-06 : 1009.6175522181197\n",
      "gpt-4o-mini-2024-07-18 : 1009.0453037875014\n",
      "llama-3.3-70b : 1003.7986825017117\n",
      "jamba-1.5-large : 996.5424515898704\n",
      "mistral-small-24b-instruct-2501 : 996.0728320125398\n",
      "gemma-2-27b-it-q8 : 993.7873247351531\n",
      "phi-4 : 991.143395068032\n",
      "deepseek-r1-distill-llama-70b : 981.7745660237254\n",
      "llama-3.1-70b : 981.035165377253\n",
      "gemma-2-9b-it : 974.2934151360159\n",
      "ministral-8b-instruct-2410 : 972.8387387298151\n",
      "aya-expanse-8b : 972.0516201380477\n",
      "qwq-32b : 958.4884040335733\n",
      "hermes-3-llama-3.1-405b : 951.9996047099316\n",
      "llama-3.1-8b : 938.3413499042028\n",
      "c4ai-command-r-08-2024 : 937.9035208452859\n",
      "qwen2.5-coder-32b-instruct : 935.4985672863389\n",
      "qwen2.5-7b-instruct : 928.4740495461903\n",
      "lfm-40b : 907.7478251129792\n",
      "phi-3.5-mini-instruct : 902.4020443316053\n",
      "mixtral-8x7b-instruct-v0.1 : 894.9188278649337\n",
      "mixtral-8x22b-instruct-v0.1 : 867.8866780668768\n",
      "mistral-nemo-2407 : 863.7128238844878\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 835.3050273068001\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemma-3-27b': 1218.9697449404073,\n",
       " 'gemini-2.0-flash-exp': 1150.858189361456,\n",
       " 'deepseek-v3-chat': 1119.5783278500196,\n",
       " 'command-a': 1108.4126271866912,\n",
       " 'gemini-2.0-flash-001': 1094.5899437475196,\n",
       " 'gemma-3-4b': 1080.4268240046715,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1079.3609075985867,\n",
       " 'gemini-1.5-pro-002': 1078.108923148095,\n",
       " 'gemini-1.5-pro-001': 1075.8876201577034,\n",
       " 'gpt-4o-mini-2024-07-18': 1069.0936258148813,\n",
       " 'claude-3-5-sonnet-v2': 1065.5645975332131,\n",
       " 'gemma-3-12b': 1051.502508837704,\n",
       " 'llama-3.1-8b': 1035.6399625301644,\n",
       " 'mistral-large-2411': 1024.9240656873892,\n",
       " 'mistral-small-3.1-24b': 1022.4594850892795,\n",
       " 'qwen2.5-coder-32b-instruct': 1020.2050230041795,\n",
       " 'deepseek-r1': 1013.5370037672889,\n",
       " 'aya-expanse-8b': 1011.9924843896729,\n",
       " 'mistral-small-24b-instruct-2501': 1007.8120967265646,\n",
       " 'o3-mini': 1007.3257540112074,\n",
       " 'jamba-1.5-large': 997.1705166960566,\n",
       " 'deepseek-r1-distill-llama-70b': 990.0498018645136,\n",
       " 'phi-4': 987.0139024387507,\n",
       " 'llama-3.1-70b': 985.2419780549873,\n",
       " 'gemma-2-27b-it-q8': 981.6306690620353,\n",
       " 'llama-3.1-405b': 978.862480651645,\n",
       " 'ministral-8b-instruct-2410': 971.100106750678,\n",
       " 'llama-3.3-70b': 966.9986030862078,\n",
       " 'qwq-32b': 963.905096453094,\n",
       " 'gpt-4o-2024-08-06': 961.6354678588511,\n",
       " 'hermes-3-llama-3.1-405b': 957.4524598532014,\n",
       " 'gemma-2-9b-it': 949.757727964659,\n",
       " 'c4ai-command-r-08-2024': 947.9390599942047,\n",
       " 'phi-3.5-mini-instruct': 935.8527664679291,\n",
       " 'qwen2.5-7b-instruct': 884.949069584335,\n",
       " 'lfm-40b': 874.7320760894675,\n",
       " 'mixtral-8x7b-instruct-v0.1': 854.3565912689074,\n",
       " 'mixtral-8x22b-instruct-v0.1': 842.6034019961492,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 827.3437126928313,\n",
       " 'mistral-nemo-2407': 805.1547957847948}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(42)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1183.2249238191819,\n",
       " 'gemma-3-27b': 1170.8246373266186,\n",
       " 'command-a': 1158.7196218466388,\n",
       " 'gemini-2.0-flash-001': 1148.9368106015984,\n",
       " 'deepseek-r1': 1126.5284608238528,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1102.656687428728,\n",
       " 'gemma-3-4b': 1098.5158362420539,\n",
       " 'gemini-1.5-pro-002': 1095.7595031299986,\n",
       " 'deepseek-v3-chat': 1094.4597103322528,\n",
       " 'gemma-3-12b': 1082.8651112931598,\n",
       " 'gpt-4o-mini-2024-07-18': 1071.8016781715187,\n",
       " 'gpt-4o-2024-08-06': 1049.544044269285,\n",
       " 'mistral-small-3.1-24b': 1038.17783454564,\n",
       " 'o3-mini': 1031.1784329344102,\n",
       " 'deepseek-r1-distill-llama-70b': 1019.7467208322944,\n",
       " 'gemini-1.5-pro-001': 1013.0913784387037,\n",
       " 'llama-3.1-70b': 1006.7479287837886,\n",
       " 'mistral-small-24b-instruct-2501': 1001.7586732700793,\n",
       " 'mistral-large-2411': 998.3664288496796,\n",
       " 'jamba-1.5-large': 989.0282367273422,\n",
       " 'claude-3-5-sonnet-v2': 988.1648726866101,\n",
       " 'llama-3.1-405b': 985.6521349099373,\n",
       " 'qwen2.5-coder-32b-instruct': 982.2354056192605,\n",
       " 'qwq-32b': 972.96716042487,\n",
       " 'phi-4': 972.1451077661809,\n",
       " 'gemma-2-9b-it': 970.1578327214766,\n",
       " 'llama-3.3-70b': 967.3091479926242,\n",
       " 'ministral-8b-instruct-2410': 963.5579599518838,\n",
       " 'aya-expanse-8b': 961.9011978286376,\n",
       " 'c4ai-command-r-08-2024': 945.012407490258,\n",
       " 'gemma-2-27b-it-q8': 939.9335861746393,\n",
       " 'hermes-3-llama-3.1-405b': 938.3784379851476,\n",
       " 'qwen2.5-7b-instruct': 924.2068765369764,\n",
       " 'phi-3.5-mini-instruct': 900.7428876104738,\n",
       " 'llama-3.1-8b': 882.5627447903087,\n",
       " 'mixtral-8x22b-instruct-v0.1': 878.4978964260537,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 860.0610668387245,\n",
       " 'lfm-40b': 836.3122056661364,\n",
       " 'mixtral-8x7b-instruct-v0.1': 827.0614440316789,\n",
       " 'mistral-nemo-2407': 821.2069668813051}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(1337)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': np.float64(1154.613547646744),\n",
       " 'gemma-3-27b': np.float64(1151.996701599601),\n",
       " 'gemini-2.0-flash-001': np.float64(1124.5616750643296),\n",
       " 'deepseek-v3-chat': np.float64(1123.9831406383748),\n",
       " 'command-a': np.float64(1106.6338381476846),\n",
       " 'llama-3.1-nemotron-70b-instruct': np.float64(1079.4198358059523),\n",
       " 'gemma-3-12b': np.float64(1072.030188153528),\n",
       " 'deepseek-r1': np.float64(1065.1122962748934),\n",
       " 'gemma-3-4b': np.float64(1062.6939030753736),\n",
       " 'gemini-1.5-pro-002': np.float64(1059.1824058503007),\n",
       " 'gemini-1.5-pro-001': np.float64(1051.8732400312688),\n",
       " 'mistral-small-3.1-24b': np.float64(1040.97347256112),\n",
       " 'mistral-large-2411': np.float64(1037.7388644150883),\n",
       " 'llama-3.1-405b': np.float64(1018.244845660219),\n",
       " 'claude-3-5-sonnet-v2': np.float64(1013.7515686846236),\n",
       " 'gpt-4o-mini-2024-07-18': np.float64(1010.5428022782845),\n",
       " 'o3-mini': np.float64(1009.7305011924993),\n",
       " 'gpt-4o-2024-08-06': np.float64(1005.1432127620177),\n",
       " 'llama-3.3-70b': np.float64(1000.7964074049232),\n",
       " 'jamba-1.5-large': np.float64(998.2560355674449),\n",
       " 'mistral-small-24b-instruct-2501': np.float64(996.1518362066905),\n",
       " 'phi-4': np.float64(991.2151932676013),\n",
       " 'gemma-2-27b-it-q8': np.float64(988.3247295519006),\n",
       " 'deepseek-r1-distill-llama-70b': np.float64(983.7040120636161),\n",
       " 'llama-3.1-70b': np.float64(981.8425403160893),\n",
       " 'gemma-2-9b-it': np.float64(979.0067070319708),\n",
       " 'ministral-8b-instruct-2410': np.float64(972.8038996302553),\n",
       " 'aya-expanse-8b': np.float64(972.7549887645356),\n",
       " 'qwq-32b': np.float64(961.1362670540483),\n",
       " 'hermes-3-llama-3.1-405b': np.float64(950.5175300381126),\n",
       " 'c4ai-command-r-08-2024': np.float64(944.1189783237508),\n",
       " 'llama-3.1-8b': np.float64(940.2274777283823),\n",
       " 'qwen2.5-coder-32b-instruct': np.float64(935.9196172132108),\n",
       " 'qwen2.5-7b-instruct': np.float64(926.6478320822315),\n",
       " 'lfm-40b': np.float64(907.6695303958927),\n",
       " 'phi-3.5-mini-instruct': np.float64(903.6139303928014),\n",
       " 'mixtral-8x7b-instruct-v0.1': np.float64(897.5154896369622),\n",
       " 'mixtral-8x22b-instruct-v0.1': np.float64(871.8245270029252),\n",
       " 'mistral-nemo-2407': np.float64(867.4190257274136),\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': np.float64(840.3074047573382)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.maximum_likelihood import MaximumLikelihoodRanker\n",
    "\n",
    "ranker = MaximumLikelihoodRanker()\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank-comparia-SXEyBiqD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
