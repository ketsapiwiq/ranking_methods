{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass()\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_TOKEN\"] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "comparia = datasets.load_dataset(\n",
    "    \"ministere-culture/comparia-reactions\",\n",
    "    cache_dir=\"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia: pl.DataFrame = comparia.to_polars()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia_model_a = (\n",
    "    comparia.group_by([\"model_a_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_a_name\")\n",
    "    .drop(\"model_a_name\")\n",
    ")\n",
    "comparia_model_b = (\n",
    "    comparia.group_by([\"model_b_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_b_name\")\n",
    "    .drop(\"model_b_name\")\n",
    ")\n",
    "number_by_model = (\n",
    "    pl.concat([comparia_model_a, comparia_model_b]).group_by(\"model_name\").sum().sort(\"len\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>3894</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>3857</td></tr><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>3816</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>3514</td></tr><tr><td>&quot;llama-3.1-405b&quot;</td><td>3409</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;gemma-3-12b&quot;</td><td>408</td></tr><tr><td>&quot;mistral-small-3.1-24b&quot;</td><td>383</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>381</td></tr><tr><td>&quot;gemma-2-27b-it-q8&quot;</td><td>296</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>237</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 2)\n",
       "┌────────────────────────┬──────┐\n",
       "│ model_name             ┆ len  │\n",
       "│ ---                    ┆ ---  │\n",
       "│ str                    ┆ u32  │\n",
       "╞════════════════════════╪══════╡\n",
       "│ gpt-4o-2024-08-06      ┆ 3894 │\n",
       "│ deepseek-v3-chat       ┆ 3857 │\n",
       "│ gpt-4o-mini-2024-07-18 ┆ 3816 │\n",
       "│ claude-3-5-sonnet-v2   ┆ 3514 │\n",
       "│ llama-3.1-405b         ┆ 3409 │\n",
       "│ …                      ┆ …    │\n",
       "│ gemma-3-12b            ┆ 408  │\n",
       "│ mistral-small-3.1-24b  ┆ 383  │\n",
       "│ gemma-3-4b             ┆ 381  │\n",
       "│ gemma-2-27b-it-q8      ┆ 296  │\n",
       "│ jamba-1.5-large        ┆ 237  │\n",
       "└────────────────────────┴──────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(comparia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>&quot;llama-3.1-70b&quot;</td><td>&quot;407f67a39f0f4128b1ea0a4e130028…</td><td>0</td><td>2</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;9868b2a12eb442568206f0a32cf2cf…</td><td>3</td><td>3</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;05da273de21542138e9d8cc47c648d…</td><td>3</td><td>0</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;16a15b220d88442b89bc8adb72323e…</td><td>-1</td><td>0</td></tr><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>&quot;lfm-40b&quot;</td><td>&quot;c867c9c56c32463480eac7d1e6ede2…</td><td>0</td><td>-1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌───────────────────────┬────────────────────┬─────────────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name          ┆ model_b_name       ┆ conversation_pair_id            ┆ score_a ┆ score_b │\n",
       "│ ---                   ┆ ---                ┆ ---                             ┆ ---     ┆ ---     │\n",
       "│ str                   ┆ str                ┆ str                             ┆ i64     ┆ i64     │\n",
       "╞═══════════════════════╪════════════════════╪═════════════════════════════════╪═════════╪═════════╡\n",
       "│ phi-3.5-mini-instruct ┆ llama-3.1-70b      ┆ 407f67a39f0f4128b1ea0a4e130028… ┆ 0       ┆ 2       │\n",
       "│ llama-3.3-70b         ┆ gpt-4o-2024-08-06  ┆ 9868b2a12eb442568206f0a32cf2cf… ┆ 3       ┆ 3       │\n",
       "│ aya-expanse-8b        ┆ gemini-1.5-pro-002 ┆ 05da273de21542138e9d8cc47c648d… ┆ 3       ┆ 0       │\n",
       "│ qwen2.5-7b-instruct   ┆ gpt-4o-2024-08-06  ┆ 16a15b220d88442b89bc8adb72323e… ┆ -1      ┆ 0       │\n",
       "│ gemini-2.0-flash-exp  ┆ lfm-40b            ┆ c867c9c56c32463480eac7d1e6ede2… ┆ 0       ┆ -1      │\n",
       "└───────────────────────┴────────────────────┴─────────────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>275</td><td>202</td><td>73.454545</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1511</td><td>1065</td><td>70.483124</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>434</td><td>301</td><td>69.354839</td></tr><tr><td>&quot;command-a&quot;</td><td>208</td><td>141</td><td>67.788462</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1440</td><td>430</td><td>29.861111</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ gemma-3-27b                     ┆ 275  ┆ 202  ┆ 73.454545 │\n",
       "│ deepseek-v3-chat                ┆ 1511 ┆ 1065 ┆ 70.483124 │\n",
       "│ gemini-2.0-flash-001            ┆ 434  ┆ 301  ┆ 69.354839 │\n",
       "│ command-a                       ┆ 208  ┆ 141  ┆ 67.788462 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1440 ┆ 430  ┆ 29.861111 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.match import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_ranks(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1157.028270838856\n",
      "gemma-3-27b : 1155.3129448418474\n",
      "deepseek-v3-chat : 1127.7370483265513\n",
      "gemini-2.0-flash-001 : 1119.3969136393855\n",
      "command-a : 1110.4961845967168\n",
      "llama-3.1-nemotron-70b-instruct : 1081.6852126662395\n",
      "deepseek-r1 : 1069.1204646445353\n",
      "gemma-3-12b : 1068.2495396221402\n",
      "gemma-3-4b : 1064.6241428516964\n",
      "gemini-1.5-pro-002 : 1059.5959973931642\n",
      "gemini-1.5-pro-001 : 1056.9972654113524\n",
      "mistral-small-3.1-24b : 1046.5567065114808\n",
      "mistral-large-2411 : 1039.9056029570474\n",
      "llama-3.1-405b : 1027.1693649023744\n",
      "gpt-4o-mini-2024-07-18 : 1016.6777315210252\n",
      "o3-mini : 1012.7184184770366\n",
      "gpt-4o-2024-08-06 : 1009.289900364873\n",
      "claude-3-5-sonnet-v2 : 1008.2581872267095\n",
      "jamba-1.5-large : 999.6233574330689\n",
      "llama-3.3-70b : 998.0678896749833\n",
      "mistral-small-24b-instruct-2501 : 990.7475928390303\n",
      "phi-4 : 986.3984552127437\n",
      "gemma-2-27b-it-q8 : 984.7081894887895\n",
      "deepseek-r1-distill-llama-70b : 981.1814187776363\n",
      "llama-3.1-70b : 980.7062058969495\n",
      "gemma-2-9b-it : 976.3340476903418\n",
      "ministral-8b-instruct-2410 : 972.806587174634\n",
      "aya-expanse-8b : 970.0933319208\n",
      "qwq-32b : 965.9366725007817\n",
      "hermes-3-llama-3.1-405b : 954.3395049007045\n",
      "c4ai-command-r-08-2024 : 944.3601183028078\n",
      "llama-3.1-8b : 941.654726745966\n",
      "qwen2.5-coder-32b-instruct : 929.7974269809249\n",
      "qwen2.5-7b-instruct : 925.4558051186509\n",
      "phi-3.5-mini-instruct : 904.5450171314109\n",
      "lfm-40b : 902.1068605990259\n",
      "mixtral-8x7b-instruct-v0.1 : 892.9622771175841\n",
      "mixtral-8x22b-instruct-v0.1 : 865.2664106750964\n",
      "mistral-nemo-2407 : 863.391149561915\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 838.6970574631232\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1182.655813210524,\n",
       " 'gemma-3-27b': 1137.7936889773757,\n",
       " 'gemini-2.0-flash-001': 1132.8096894254127,\n",
       " 'command-a': 1119.0145969398302,\n",
       " 'gemini-1.5-pro-001': 1112.7388218655956,\n",
       " 'deepseek-v3-chat': 1107.2829890748374,\n",
       " 'deepseek-r1': 1086.2569897594703,\n",
       " 'mistral-small-3.1-24b': 1077.9125231734731,\n",
       " 'gemma-3-4b': 1075.5107270904402,\n",
       " 'gemma-3-12b': 1046.6431029677765,\n",
       " 'gpt-4o-2024-08-06': 1045.563105673389,\n",
       " 'aya-expanse-8b': 1039.034797080991,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1021.9468619696204,\n",
       " 'qwq-32b': 1021.3041798059635,\n",
       " 'gpt-4o-mini-2024-07-18': 1020.8563395704401,\n",
       " 'llama-3.1-405b': 1020.6523063070479,\n",
       " 'o3-mini': 1019.2265179250985,\n",
       " 'mistral-large-2411': 1016.3749877999796,\n",
       " 'claude-3-5-sonnet-v2': 1012.1734602193051,\n",
       " 'gemini-1.5-pro-002': 1007.393517141211,\n",
       " 'jamba-1.5-large': 1005.9618854374053,\n",
       " 'gemma-2-27b-it-q8': 996.4120727334465,\n",
       " 'ministral-8b-instruct-2410': 993.0275637064254,\n",
       " 'mistral-small-24b-instruct-2501': 991.9651155785541,\n",
       " 'gemma-2-9b-it': 990.8330049642636,\n",
       " 'llama-3.1-70b': 977.5846860308031,\n",
       " 'phi-4': 967.499274775978,\n",
       " 'deepseek-r1-distill-llama-70b': 959.5667272720036,\n",
       " 'llama-3.3-70b': 946.5692601184592,\n",
       " 'hermes-3-llama-3.1-405b': 932.9700625597485,\n",
       " 'lfm-40b': 926.1135736688332,\n",
       " 'qwen2.5-coder-32b-instruct': 921.3561378774474,\n",
       " 'c4ai-command-r-08-2024': 915.6265498056474,\n",
       " 'llama-3.1-8b': 907.6279335481639,\n",
       " 'phi-3.5-mini-instruct': 898.7249173161134,\n",
       " 'mixtral-8x22b-instruct-v0.1': 898.6400335956432,\n",
       " 'mistral-nemo-2407': 895.2990217411632,\n",
       " 'qwen2.5-7b-instruct': 875.0200268256514,\n",
       " 'mixtral-8x7b-instruct-v0.1': 857.264533789783,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 838.7926026766883}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(42)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_ranks(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1182.7390199203767,\n",
       " 'gemma-3-27b': 1172.766533344677,\n",
       " 'command-a': 1147.7567901030293,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1126.527917793558,\n",
       " 'gemini-2.0-flash-001': 1122.711787366888,\n",
       " 'llama-3.1-405b': 1112.5545696469314,\n",
       " 'deepseek-v3-chat': 1091.5538878101115,\n",
       " 'gemini-1.5-pro-002': 1083.7210389698582,\n",
       " 'mistral-small-3.1-24b': 1076.9213791792906,\n",
       " 'gemma-3-12b': 1069.0676682530045,\n",
       " 'gpt-4o-2024-08-06': 1051.2384489958413,\n",
       " 'deepseek-r1': 1045.5131987432121,\n",
       " 'phi-4': 1043.4095425272337,\n",
       " 'llama-3.3-70b': 1042.681128173848,\n",
       " 'gemini-1.5-pro-001': 1035.1120001878635,\n",
       " 'gemma-2-9b-it': 1027.1483984916058,\n",
       " 'gemma-3-4b': 1015.5574347684051,\n",
       " 'claude-3-5-sonnet-v2': 1001.4204178114753,\n",
       " 'llama-3.1-70b': 1001.1786671594692,\n",
       " 'aya-expanse-8b': 991.5167601928323,\n",
       " 'gpt-4o-mini-2024-07-18': 990.854755650781,\n",
       " 'jamba-1.5-large': 984.091114434604,\n",
       " 'mistral-large-2411': 983.7083239297039,\n",
       " 'mistral-small-24b-instruct-2501': 980.3636992482191,\n",
       " 'hermes-3-llama-3.1-405b': 967.3336815237103,\n",
       " 'deepseek-r1-distill-llama-70b': 961.6182404622529,\n",
       " 'o3-mini': 958.1813309721468,\n",
       " 'qwq-32b': 949.1070141072328,\n",
       " 'phi-3.5-mini-instruct': 944.4157064253542,\n",
       " 'llama-3.1-8b': 944.1901635844074,\n",
       " 'gemma-2-27b-it-q8': 937.7236704773359,\n",
       " 'qwen2.5-7b-instruct': 936.2525944554335,\n",
       " 'ministral-8b-instruct-2410': 913.9965551386953,\n",
       " 'mixtral-8x7b-instruct-v0.1': 907.0948331348425,\n",
       " 'c4ai-command-r-08-2024': 894.0580762585279,\n",
       " 'lfm-40b': 887.1345784766563,\n",
       " 'qwen2.5-coder-32b-instruct': 867.3777234704729,\n",
       " 'mixtral-8x22b-instruct-v0.1': 859.8068912653481,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 849.3586783438435,\n",
       " 'mistral-nemo-2407': 842.2357792009127}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(1337)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_ranks(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank-comparia-SXEyBiqD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
