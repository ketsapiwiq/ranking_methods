{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia = pl.read_parquet(Path(\".\").resolve().parent / \"data\" / \"reactions.parquet\")\n",
    "comparia_model_a = (\n",
    "    comparia.group_by([\"model_a_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_a_name\")\n",
    "    .drop(\"model_a_name\")\n",
    ")\n",
    "comparia_model_b = (\n",
    "    comparia.group_by([\"model_b_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_b_name\")\n",
    "    .drop(\"model_b_name\")\n",
    ")\n",
    "number_by_model = (\n",
    "    pl.concat([comparia_model_a, comparia_model_b]).group_by(\"model_name\").sum().sort(\"len\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (34, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>3894</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>3206</td></tr><tr><td>&quot;llama-3.1-405b&quot;</td><td>2920</td></tr><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>2766</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>2760</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>282</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>237</td></tr><tr><td>&quot;gemma-3-12b&quot;</td><td>24</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>23</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>21</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (34, 2)\n",
       "┌────────────────────────┬──────┐\n",
       "│ model_name             ┆ len  │\n",
       "│ ---                    ┆ ---  │\n",
       "│ str                    ┆ u32  │\n",
       "╞════════════════════════╪══════╡\n",
       "│ gpt-4o-2024-08-06      ┆ 3894 │\n",
       "│ deepseek-v3-chat       ┆ 3206 │\n",
       "│ llama-3.1-405b         ┆ 2920 │\n",
       "│ gpt-4o-mini-2024-07-18 ┆ 2766 │\n",
       "│ claude-3-5-sonnet-v2   ┆ 2760 │\n",
       "│ …                      ┆ …    │\n",
       "│ gemini-2.0-flash-001   ┆ 282  │\n",
       "│ jamba-1.5-large        ┆ 237  │\n",
       "│ gemma-3-12b            ┆ 24   │\n",
       "│ gemma-3-4b             ┆ 23   │\n",
       "│ gemma-3-27b            ┆ 21   │\n",
       "└────────────────────────┴──────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(Path(\".\").resolve().parent / \"data\" / \"reactions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (34, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemma-3-4b&quot;</td><td>12</td><td>10</td><td>83.333333</td></tr><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1184</td><td>848</td><td>71.621622</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>127</td><td>89</td><td>70.07874</td></tr><tr><td>&quot;gemini-1.5-pro-001&quot;</td><td>328</td><td>222</td><td>67.682927</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>665</td><td>247</td><td>37.142857</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1199</td><td>368</td><td>30.692244</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1187</td><td>353</td><td>29.738837</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>301</td><td>76</td><td>25.249169</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (34, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemma-3-4b                      ┆ 12   ┆ 10   ┆ 83.333333 │\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ deepseek-v3-chat                ┆ 1184 ┆ 848  ┆ 71.621622 │\n",
       "│ gemini-2.0-flash-001            ┆ 127  ┆ 89   ┆ 70.07874  │\n",
       "│ gemini-1.5-pro-001              ┆ 328  ┆ 222  ┆ 67.682927 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 665  ┆ 247  ┆ 37.142857 │\n",
       "│ mistral-nemo-2407               ┆ 1199 ┆ 368  ┆ 30.692244 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1187 ┆ 353  ┆ 29.738837 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 301  ┆ 76   ┆ 25.249169 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import RankerELO\n",
    "import random\n",
    "\n",
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "\n",
    "matches_list = [\n",
    "    (match_dict[\"model_a_name\"], match_dict[\"model_b_name\"], match_dict[\"score_a\"], match_dict[\"score_b\"])\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches_list, model_names, seed=0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = RankerELO(K=40)\n",
    "    matches_shuffle = random.sample(matches_list, k=len(matches_list))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_ranks(matches_list=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_results = {\n",
    "    seed: get_shuffled_results(matches_list=matches_list, model_names=model_names, seed=seed) for seed in range(100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1169.781323403136\n",
      "deepseek-v3-chat : 1141.1423126006355\n",
      "gemini-2.0-flash-001 : 1116.575240785811\n",
      "gemma-3-4b : 1104.6213522598753\n",
      "llama-3.1-nemotron-70b-instruct : 1080.4550832487155\n",
      "gemma-3-27b : 1067.4643333268157\n",
      "gemini-1.5-pro-002 : 1065.8011522464794\n",
      "gemini-1.5-pro-001 : 1060.8104081834147\n",
      "mistral-large-2411 : 1050.1304917447856\n",
      "gemma-3-12b : 1045.9515378774577\n",
      "llama-3.1-405b : 1027.8624764354631\n",
      "claude-3-5-sonnet-v2 : 1027.063795796701\n",
      "gpt-4o-mini-2024-07-18 : 1025.2893501507383\n",
      "llama-3.3-70b : 1010.7720856990284\n",
      "gpt-4o-2024-08-06 : 1010.3616161810185\n",
      "jamba-1.5-large : 1009.2998487178018\n",
      "mistral-small-24b-instruct-2501 : 999.6523342483056\n",
      "phi-4 : 998.6798758954953\n",
      "gemma-2-27b-it-q8 : 996.4918085869062\n",
      "gemma-2-9b-it : 988.2834499143715\n",
      "llama-3.1-70b : 988.176783078807\n",
      "aya-expanse-8b : 979.3331691215346\n",
      "ministral-8b-instruct-2410 : 978.2844329390423\n",
      "c4ai-command-r-08-2024 : 969.8939771834646\n",
      "hermes-3-llama-3.1-405b : 950.5592849029724\n",
      "llama-3.1-8b : 949.7829703023925\n",
      "qwen2.5-coder-32b-instruct : 941.7910640481065\n",
      "qwen2.5-7b-instruct : 927.9666689124318\n",
      "lfm-40b : 917.7576033144096\n",
      "phi-3.5-mini-instruct : 915.4949757739823\n",
      "mixtral-8x7b-instruct-v0.1 : 897.7536059061675\n",
      "mixtral-8x22b-instruct-v0.1 : 872.099439495185\n",
      "mistral-nemo-2407 : 870.4342259161972\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 844.1819218023503\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1150.4700434124802\n",
      "gemini-2.0-flash-001 : 1143.9304843712302\n",
      "gpt-4o-mini-2024-07-18 : 1128.0470464832379\n",
      "deepseek-v3-chat : 1120.819926137853\n",
      "llama-3.1-nemotron-70b-instruct : 1100.979282658023\n",
      "gemma-3-4b : 1082.8852329960412\n",
      "gemini-1.5-pro-001 : 1081.4335874245248\n",
      "gemini-1.5-pro-002 : 1080.9932600863472\n",
      "gemma-3-27b : 1079.140483837468\n",
      "mistral-large-2411 : 1066.2872477012352\n",
      "llama-3.3-70b : 1053.6579622493116\n",
      "phi-4 : 1049.9066244908154\n",
      "gemma-3-12b : 1043.5684621754242\n",
      "jamba-1.5-large : 1023.7193228271046\n",
      "gpt-4o-2024-08-06 : 1016.9042562708933\n",
      "claude-3-5-sonnet-v2 : 1015.0694564926664\n",
      "c4ai-command-r-08-2024 : 989.2435047976638\n",
      "llama-3.1-405b : 986.3112983835166\n",
      "gemma-2-9b-it : 986.1843466884308\n",
      "qwen2.5-coder-32b-instruct : 976.572124972731\n",
      "mistral-small-24b-instruct-2501 : 966.149711898671\n",
      "llama-3.1-70b : 963.4000275566317\n",
      "aya-expanse-8b : 960.0425647311392\n",
      "llama-3.1-8b : 947.226331260453\n",
      "hermes-3-llama-3.1-405b : 937.501452933138\n",
      "ministral-8b-instruct-2410 : 937.4585184110467\n",
      "gemma-2-27b-it-q8 : 936.5284099460885\n",
      "qwen2.5-7b-instruct : 932.5433428068402\n",
      "phi-3.5-mini-instruct : 901.2247153747052\n",
      "lfm-40b : 894.2140983833962\n",
      "mistral-nemo-2407 : 890.5574846129908\n",
      "mixtral-8x7b-instruct-v0.1 : 887.9518274216897\n",
      "mixtral-8x22b-instruct-v0.1 : 839.9812351995313\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 829.096325006672\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.elo import RankerELO\n",
    "from random import sample, seed\n",
    "\n",
    "ranker_shuffle = RankerELO(K=40)\n",
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "\n",
    "matches_list = [\n",
    "    (match_dict[\"model_a_name\"], match_dict[\"model_b_name\"], match_dict[\"score_a\"], match_dict[\"score_b\"])\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "seed(42)\n",
    "matches_suffle = sample(matches_list, k=len(matches_list))\n",
    "ranker_shuffle.add_players(model_names)\n",
    "ranker_shuffle.compute_ranks(matches_list=matches_suffle)\n",
    "ranker_shuffle.get_all_rankings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1200.592947192445\n",
      "deepseek-v3-chat : 1124.1437361967505\n",
      "gemini-2.0-flash-001 : 1113.4882061588316\n",
      "gemini-1.5-pro-001 : 1106.368064695688\n",
      "gemma-3-4b : 1104.9780302254394\n",
      "llama-3.1-nemotron-70b-instruct : 1077.4993648446539\n",
      "gemma-3-27b : 1073.8445119546225\n",
      "llama-3.1-70b : 1062.6915774021036\n",
      "claude-3-5-sonnet-v2 : 1046.6285315942455\n",
      "gpt-4o-mini-2024-07-18 : 1045.9983440073072\n",
      "gemini-1.5-pro-002 : 1043.5379956858596\n",
      "gemma-3-12b : 1041.4913314082753\n",
      "c4ai-command-r-08-2024 : 1034.2841149353017\n",
      "mistral-small-24b-instruct-2501 : 1031.9022093591066\n",
      "mistral-large-2411 : 1029.6478028713036\n",
      "jamba-1.5-large : 1015.123090971581\n",
      "gemma-2-27b-it-q8 : 1010.1909846519338\n",
      "llama-3.3-70b : 1007.0649490552951\n",
      "phi-4 : 1006.7219536666561\n",
      "gpt-4o-2024-08-06 : 1002.3084013563594\n",
      "llama-3.1-405b : 993.675689573038\n",
      "aya-expanse-8b : 983.2797636586968\n",
      "gemma-2-9b-it : 980.5054275232847\n",
      "qwen2.5-7b-instruct : 971.7295749095838\n",
      "hermes-3-llama-3.1-405b : 942.4440351446967\n",
      "ministral-8b-instruct-2410 : 926.2546098395351\n",
      "llama-3.1-8b : 925.4856342853984\n",
      "phi-3.5-mini-instruct : 894.5046364295633\n",
      "qwen2.5-coder-32b-instruct : 888.676541015109\n",
      "mistral-nemo-2407 : 876.4042112647842\n",
      "lfm-40b : 871.9949139728732\n",
      "mixtral-8x7b-instruct-v0.1 : 869.8705971765446\n",
      "mixtral-8x22b-instruct-v0.1 : 850.719372052141\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 845.9488449209978\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.elo import RankerELO\n",
    "from random import sample, seed\n",
    "\n",
    "ranker_shuffle = RankerELO(K=40)\n",
    "\n",
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "\n",
    "matches_list = [\n",
    "    (match_dict[\"model_a_name\"], match_dict[\"model_b_name\"], match_dict[\"score_a\"], match_dict[\"score_b\"])\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "seed(1337)\n",
    "matches_suffle = sample(matches_list, k=len(matches_list))\n",
    "ranker_shuffle.add_players(model_names)\n",
    "ranker_shuffle.compute_ranks(matches_list=matches_suffle)\n",
    "ranker_shuffle.get_all_rankings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank-comparia-6UlSn295-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
