{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass()\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_TOKEN\"] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "comparia = datasets.load_dataset(\n",
    "    \"ministere-culture/comparia-reactions\",\n",
    "    cache_dir=\"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia: pl.DataFrame = comparia.to_polars()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia_model_a = (\n",
    "    comparia.group_by([\"model_a_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_a_name\")\n",
    "    .drop(\"model_a_name\")\n",
    ")\n",
    "comparia_model_b = (\n",
    "    comparia.group_by([\"model_b_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_b_name\")\n",
    "    .drop(\"model_b_name\")\n",
    ")\n",
    "number_by_model = (\n",
    "    pl.concat([comparia_model_a, comparia_model_b]).group_by(\"model_name\").sum().sort(\"len\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>3894</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>3857</td></tr><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>3816</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>3514</td></tr><tr><td>&quot;llama-3.1-405b&quot;</td><td>3409</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;gemma-3-12b&quot;</td><td>408</td></tr><tr><td>&quot;mistral-small-3.1-24b&quot;</td><td>383</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>381</td></tr><tr><td>&quot;gemma-2-27b-it-q8&quot;</td><td>296</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>237</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 2)\n",
       "┌────────────────────────┬──────┐\n",
       "│ model_name             ┆ len  │\n",
       "│ ---                    ┆ ---  │\n",
       "│ str                    ┆ u32  │\n",
       "╞════════════════════════╪══════╡\n",
       "│ gpt-4o-2024-08-06      ┆ 3894 │\n",
       "│ deepseek-v3-chat       ┆ 3857 │\n",
       "│ gpt-4o-mini-2024-07-18 ┆ 3816 │\n",
       "│ claude-3-5-sonnet-v2   ┆ 3514 │\n",
       "│ llama-3.1-405b         ┆ 3409 │\n",
       "│ …                      ┆ …    │\n",
       "│ gemma-3-12b            ┆ 408  │\n",
       "│ mistral-small-3.1-24b  ┆ 383  │\n",
       "│ gemma-3-4b             ┆ 381  │\n",
       "│ gemma-2-27b-it-q8      ┆ 296  │\n",
       "│ jamba-1.5-large        ┆ 237  │\n",
       "└────────────────────────┴──────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(comparia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;command-a&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;c5c35269ef1a484292a60b2fcbf801…</td><td>2</td><td>0</td></tr><tr><td>&quot;llama-3.1-nemotron-70b-instruc…</td><td>&quot;llama-3.1-8b&quot;</td><td>&quot;69a81c6dfadb4445a1ec7ddf58a11d…</td><td>3</td><td>0</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>&quot;75a36e57c9614fbc9b8e904d13c788…</td><td>0</td><td>1</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;7f1dd8b6e2a64ea893f71af885d7b1…</td><td>1</td><td>1</td></tr><tr><td>&quot;mistral-small-3.1-24b&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;a4d37bb370544e8497f7b250ca0e32…</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────────┬─────────────────────────┬─────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name             ┆ model_b_name            ┆ conversation_pair_id    ┆ score_a ┆ score_b │\n",
       "│ ---                      ┆ ---                     ┆ ---                     ┆ ---     ┆ ---     │\n",
       "│ str                      ┆ str                     ┆ str                     ┆ i64     ┆ i64     │\n",
       "╞══════════════════════════╪═════════════════════════╪═════════════════════════╪═════════╪═════════╡\n",
       "│ command-a                ┆ gemini-1.5-pro-002      ┆ c5c35269ef1a484292a60b2 ┆ 2       ┆ 0       │\n",
       "│                          ┆                         ┆ fcbf801…                ┆         ┆         │\n",
       "│ llama-3.1-nemotron-70b-i ┆ llama-3.1-8b            ┆ 69a81c6dfadb4445a1ec7dd ┆ 3       ┆ 0       │\n",
       "│ nstruc…                  ┆                         ┆ f58a11d…                ┆         ┆         │\n",
       "│ claude-3-5-sonnet-v2     ┆ qwen2.5-coder-32b-instr ┆ 75a36e57c9614fbc9b8e904 ┆ 0       ┆ 1       │\n",
       "│                          ┆ uct                     ┆ d13c788…                ┆         ┆         │\n",
       "│ jamba-1.5-large          ┆ gemini-1.5-pro-002      ┆ 7f1dd8b6e2a64ea893f71af ┆ 1       ┆ 1       │\n",
       "│                          ┆                         ┆ 885d7b1…                ┆         ┆         │\n",
       "│ mistral-small-3.1-24b    ┆ deepseek-v3-chat        ┆ a4d37bb370544e8497f7b25 ┆ 0       ┆ 1       │\n",
       "│                          ┆                         ┆ 0ca0e32…                ┆         ┆         │\n",
       "└──────────────────────────┴─────────────────────────┴─────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>275</td><td>202</td><td>73.454545</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1511</td><td>1065</td><td>70.483124</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>434</td><td>301</td><td>69.354839</td></tr><tr><td>&quot;command-a&quot;</td><td>208</td><td>141</td><td>67.788462</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1440</td><td>430</td><td>29.861111</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ gemma-3-27b                     ┆ 275  ┆ 202  ┆ 73.454545 │\n",
       "│ deepseek-v3-chat                ┆ 1511 ┆ 1065 ┆ 70.483124 │\n",
       "│ gemini-2.0-flash-001            ┆ 434  ┆ 301  ┆ 69.354839 │\n",
       "│ command-a                       ┆ 208  ┆ 141  ┆ 67.788462 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1440 ┆ 430  ┆ 29.861111 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.match import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1159.835765649278\n",
      "gemma-3-27b : 1152.618960183281\n",
      "gemini-2.0-flash-001 : 1125.6259159717804\n",
      "deepseek-v3-chat : 1122.7934338956784\n",
      "command-a : 1109.2156052313073\n",
      "llama-3.1-nemotron-70b-instruct : 1088.2077349488752\n",
      "deepseek-r1 : 1066.984214234589\n",
      "gemma-3-12b : 1066.4512967588537\n",
      "gemini-1.5-pro-002 : 1065.5034803505066\n",
      "gemma-3-4b : 1062.8008354011902\n",
      "gemini-1.5-pro-001 : 1049.610792610557\n",
      "mistral-small-3.1-24b : 1044.1573804933316\n",
      "mistral-large-2411 : 1031.1972652931388\n",
      "o3-mini : 1016.0236651676515\n",
      "llama-3.1-405b : 1013.8497280412064\n",
      "gpt-4o-2024-08-06 : 1012.1437886433353\n",
      "claude-3-5-sonnet-v2 : 1011.9123455668218\n",
      "gpt-4o-mini-2024-07-18 : 1011.1633080538566\n",
      "jamba-1.5-large : 996.5450212630784\n",
      "phi-4 : 994.1058393080427\n",
      "llama-3.3-70b : 992.4166532884456\n",
      "mistral-small-24b-instruct-2501 : 990.9888211898422\n",
      "gemma-2-27b-it-q8 : 989.0215035034687\n",
      "deepseek-r1-distill-llama-70b : 986.3702642005592\n",
      "gemma-2-9b-it : 981.4534250743222\n",
      "llama-3.1-70b : 981.016759005094\n",
      "aya-expanse-8b : 974.8766871759524\n",
      "ministral-8b-instruct-2410 : 967.605228356531\n",
      "qwq-32b : 962.96638122334\n",
      "hermes-3-llama-3.1-405b : 956.75343669508\n",
      "c4ai-command-r-08-2024 : 946.2039301265457\n",
      "llama-3.1-8b : 937.9487126648867\n",
      "qwen2.5-coder-32b-instruct : 936.1964586234637\n",
      "qwen2.5-7b-instruct : 927.1842706234039\n",
      "lfm-40b : 905.6144787256616\n",
      "mixtral-8x7b-instruct-v0.1 : 899.0588549065455\n",
      "phi-3.5-mini-instruct : 895.8833966224674\n",
      "mistral-nemo-2407 : 868.0086512716225\n",
      "mixtral-8x22b-instruct-v0.1 : 864.9904652102246\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 834.6952444461797\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1183.4867491157845,\n",
       " 'gemma-3-27b': 1180.7409053885328,\n",
       " 'deepseek-v3-chat': 1139.4939627497208,\n",
       " 'command-a': 1117.531631093939,\n",
       " 'gemini-2.0-flash-001': 1097.9617704624359,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1092.6948479646198,\n",
       " 'deepseek-r1': 1082.5117765662246,\n",
       " 'gemini-1.5-pro-001': 1055.2311933164472,\n",
       " 'gemma-3-4b': 1054.5029233755392,\n",
       " 'llama-3.1-405b': 1045.2969672940199,\n",
       " 'mistral-large-2411': 1039.7748720202499,\n",
       " 'mistral-small-3.1-24b': 1037.55214990131,\n",
       " 'gemma-3-12b': 1029.9889436928504,\n",
       " 'llama-3.3-70b': 1016.9411699555915,\n",
       " 'claude-3-5-sonnet-v2': 1005.3881412437157,\n",
       " 'deepseek-r1-distill-llama-70b': 1002.279239468485,\n",
       " 'gpt-4o-2024-08-06': 999.7796306088758,\n",
       " 'ministral-8b-instruct-2410': 997.3705857434142,\n",
       " 'c4ai-command-r-08-2024': 981.2995658320218,\n",
       " 'o3-mini': 981.053399770166,\n",
       " 'mistral-small-24b-instruct-2501': 980.4589842411491,\n",
       " 'gemini-1.5-pro-002': 975.9931450774732,\n",
       " 'jamba-1.5-large': 971.1860296890408,\n",
       " 'gpt-4o-mini-2024-07-18': 967.523192834037,\n",
       " 'lfm-40b': 965.654088927343,\n",
       " 'gemma-2-9b-it': 962.4634166965194,\n",
       " 'llama-3.1-70b': 961.0083807923223,\n",
       " 'gemma-2-27b-it-q8': 960.6006383606256,\n",
       " 'phi-4': 959.7096111867286,\n",
       " 'qwq-32b': 959.5438670758545,\n",
       " 'hermes-3-llama-3.1-405b': 952.7233610956027,\n",
       " 'qwen2.5-7b-instruct': 951.5397116483754,\n",
       " 'mixtral-8x22b-instruct-v0.1': 940.9050914560082,\n",
       " 'llama-3.1-8b': 936.9575299268704,\n",
       " 'qwen2.5-coder-32b-instruct': 934.5902448411757,\n",
       " 'mixtral-8x7b-instruct-v0.1': 928.234526837379,\n",
       " 'aya-expanse-8b': 923.849271682616,\n",
       " 'phi-3.5-mini-instruct': 902.6551260435356,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 896.1936897669272,\n",
       " 'mistral-nemo-2407': 827.3296662564659}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(42)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1183.4179921009365,\n",
       " 'gemma-3-27b': 1182.5980532698009,\n",
       " 'gemini-1.5-pro-002': 1136.4441252706813,\n",
       " 'command-a': 1116.8700754601125,\n",
       " 'deepseek-v3-chat': 1103.0714861195213,\n",
       " 'gemini-2.0-flash-001': 1088.4041617738817,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1085.318580098813,\n",
       " 'deepseek-r1': 1082.0732443672703,\n",
       " 'mistral-small-3.1-24b': 1076.8682172908802,\n",
       " 'gemma-3-4b': 1074.091100502742,\n",
       " 'gemini-1.5-pro-001': 1065.5802781049345,\n",
       " 'mistral-large-2411': 1064.9739292714796,\n",
       " 'llama-3.3-70b': 1038.1029852149766,\n",
       " 'gemma-3-12b': 1024.3882899362548,\n",
       " 'gpt-4o-2024-08-06': 1020.6206349017535,\n",
       " 'gemma-2-27b-it-q8': 1017.6556602981265,\n",
       " 'gemma-2-9b-it': 1015.4259778307485,\n",
       " 'llama-3.1-405b': 1010.3436327945215,\n",
       " 'phi-4': 1009.3227755806488,\n",
       " 'o3-mini': 1001.835494463063,\n",
       " 'c4ai-command-r-08-2024': 1000.3276030693978,\n",
       " 'claude-3-5-sonnet-v2': 991.220280300796,\n",
       " 'gpt-4o-mini-2024-07-18': 990.3480848172474,\n",
       " 'mistral-small-24b-instruct-2501': 987.8857128336056,\n",
       " 'jamba-1.5-large': 981.4081606650146,\n",
       " 'deepseek-r1-distill-llama-70b': 981.1491432185803,\n",
       " 'ministral-8b-instruct-2410': 975.8841339345349,\n",
       " 'lfm-40b': 954.025940328307,\n",
       " 'qwq-32b': 950.1883882053606,\n",
       " 'qwen2.5-7b-instruct': 949.6337946115609,\n",
       " 'llama-3.1-70b': 916.5008372863472,\n",
       " 'hermes-3-llama-3.1-405b': 914.8598154151471,\n",
       " 'qwen2.5-coder-32b-instruct': 914.4985756361999,\n",
       " 'llama-3.1-8b': 912.3140535878199,\n",
       " 'aya-expanse-8b': 899.0949749054188,\n",
       " 'mixtral-8x7b-instruct-v0.1': 894.0459333643274,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 869.3089597569062,\n",
       " 'phi-3.5-mini-instruct': 862.9559277573804,\n",
       " 'mistral-nemo-2407': 835.0822602572739,\n",
       " 'mixtral-8x22b-instruct-v0.1': 821.8607253976198}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(1337)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': np.float64(1071.5911431488494),\n",
       " 'gemma-3-27b': np.float64(1070.6149512161023),\n",
       " 'deepseek-v3-chat': np.float64(1058.7552040622897),\n",
       " 'gemini-2.0-flash-001': np.float64(1058.5208268807687),\n",
       " 'command-a': np.float64(1050.5695593881183),\n",
       " 'llama-3.1-nemotron-70b-instruct': np.float64(1038.0127107423189),\n",
       " 'gemma-3-12b': np.float64(1034.5409904079895),\n",
       " 'deepseek-r1': np.float64(1031.587219159151),\n",
       " 'gemma-3-4b': np.float64(1030.1160721559013),\n",
       " 'gemini-1.5-pro-002': np.float64(1028.6351487602299),\n",
       " 'gemini-1.5-pro-001': np.float64(1025.3303833271952),\n",
       " 'mistral-small-3.1-24b': np.float64(1019.7461220961129),\n",
       " 'mistral-large-2411': np.float64(1018.3135817966071),\n",
       " 'llama-3.1-405b': np.float64(1009.1366953720458),\n",
       " 'claude-3-5-sonnet-v2': np.float64(1006.6935189502086),\n",
       " 'gpt-4o-mini-2024-07-18': np.float64(1005.1632698064324),\n",
       " 'o3-mini': np.float64(1004.5772402173617),\n",
       " 'gpt-4o-2024-08-06': np.float64(1002.5159238018007),\n",
       " 'llama-3.3-70b': np.float64(1000.5323939643387),\n",
       " 'jamba-1.5-large': np.float64(999.2765808293385),\n",
       " 'mistral-small-24b-instruct-2501': np.float64(998.231329121701),\n",
       " 'phi-4': np.float64(995.9344225140206),\n",
       " 'gemma-2-27b-it-q8': np.float64(994.9193258803073),\n",
       " 'deepseek-r1-distill-llama-70b': np.float64(992.0372030340901),\n",
       " 'llama-3.1-70b': np.float64(991.4876165691794),\n",
       " 'gemma-2-9b-it': np.float64(990.112646572699),\n",
       " 'ministral-8b-instruct-2410': np.float64(987.0897413319843),\n",
       " 'aya-expanse-8b': np.float64(986.9600716966605),\n",
       " 'qwq-32b': np.float64(980.9493976214801),\n",
       " 'hermes-3-llama-3.1-405b': np.float64(976.2327599926756),\n",
       " 'c4ai-command-r-08-2024': np.float64(973.2419407001556),\n",
       " 'llama-3.1-8b': np.float64(971.2998070021312),\n",
       " 'qwen2.5-coder-32b-instruct': np.float64(969.3315289631795),\n",
       " 'qwen2.5-7b-instruct': np.float64(964.7674195261296),\n",
       " 'lfm-40b': np.float64(955.9367836691281),\n",
       " 'phi-3.5-mini-instruct': np.float64(953.6297878497253),\n",
       " 'mixtral-8x7b-instruct-v0.1': np.float64(950.9005188655187),\n",
       " 'mixtral-8x22b-instruct-v0.1': np.float64(939.3698833826313),\n",
       " 'mistral-nemo-2407': np.float64(937.3972390749905),\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': np.float64(925.941040548452)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.maximum_likelihood import MaximumLikelihoodRanker\n",
    "\n",
    "ranker = MaximumLikelihoodRanker()\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank-comparia-SXEyBiqD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
