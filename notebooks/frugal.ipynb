{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_TOKEN\"] = getpass(\"Enter your HuggingFace token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.utils import load_comparia\n",
    "\n",
    "reactions = load_comparia(\"ministere-culture/comparia-reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule des scores comme dans le notebook `rankers.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score\n",
    "\n",
    "matches = get_matches_with_score(reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;llama-3.3-70b&quot;</td><td>&quot;06b9efda752643ebb0565cb78c1f46…</td><td>0</td><td>6</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;24e7eb51020f4411b687749f79a1b3…</td><td>2</td><td>0</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;llama-3.1-nemotron-70b-instruc…</td><td>&quot;10dd55a4982348df8a210b732e0962…</td><td>-1</td><td>-2</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;8660169dd3904f42a2acfa5b352769…</td><td>3</td><td>0</td></tr><tr><td>&quot;llama-3.1-405b&quot;</td><td>&quot;llama-3.1-nemotron-70b-instruc…</td><td>&quot;9523c20b4efa4dcb895204583e5d6e…</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────┬───────────────────────────┬───────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name         ┆ model_b_name              ┆ conversation_pair_id      ┆ score_a ┆ score_b │\n",
       "│ ---                  ┆ ---                       ┆ ---                       ┆ ---     ┆ ---     │\n",
       "│ str                  ┆ str                       ┆ str                       ┆ i64     ┆ i64     │\n",
       "╞══════════════════════╪═══════════════════════════╪═══════════════════════════╪═════════╪═════════╡\n",
       "│ llama-3.1-8b         ┆ llama-3.3-70b             ┆ 06b9efda752643ebb0565cb78 ┆ 0       ┆ 6       │\n",
       "│                      ┆                           ┆ c1f46…                    ┆         ┆         │\n",
       "│ claude-3-5-sonnet-v2 ┆ gpt-4o-2024-08-06         ┆ 24e7eb51020f4411b687749f7 ┆ 2       ┆ 0       │\n",
       "│                      ┆                           ┆ 9a1b3…                    ┆         ┆         │\n",
       "│ llama-3.3-70b        ┆ llama-3.1-nemotron-70b-in ┆ 10dd55a4982348df8a210b732 ┆ -1      ┆ -2      │\n",
       "│                      ┆ struc…                    ┆ e0962…                    ┆         ┆         │\n",
       "│ deepseek-v3-chat     ┆ gemini-1.5-pro-002        ┆ 8660169dd3904f42a2acfa5b3 ┆ 3       ┆ 0       │\n",
       "│                      ┆                           ┆ 52769…                    ┆         ┆         │\n",
       "│ llama-3.1-405b       ┆ llama-3.1-nemotron-70b-in ┆ 9523c20b4efa4dcb895204583 ┆ 0       ┆ 1       │\n",
       "│                      ┆ struc…                    ┆ e5d6e…                    ┆         ┆         │\n",
       "└──────────────────────┴───────────────────────────┴───────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepseek-v3-chat': 1212.6624236322593,\n",
       " 'claude-3-7-sonnet': 1135.0979653746404,\n",
       " 'gemini-2.0-flash-001': 1127.6491187502902,\n",
       " 'command-a': 1109.0736501865697,\n",
       " 'gemma-3-27b': 1101.940135903943,\n",
       " 'gemini-1.5-pro-002': 1100.4153564892965,\n",
       " 'mistral-large-2411': 1094.3219154801855,\n",
       " 'grok-3-mini-beta': 1093.7771261344612,\n",
       " 'gemini-2.0-flash-exp': 1079.9107468559318,\n",
       " 'gemma-3-4b': 1074.074137515472,\n",
       " 'gemini-1.5-pro-001': 1073.9973563665326,\n",
       " 'mistral-saba': 1073.6896122095982,\n",
       " 'gemma-3-12b': 1072.9365403748707,\n",
       " 'gpt-4.1-mini': 1066.4007451068437,\n",
       " 'o4-mini': 1057.601475936693,\n",
       " 'deepseek-v3-0324': 1054.3763448653876,\n",
       " 'gpt-4o-mini-2024-07-18': 1051.529204861027,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1045.6443800662353,\n",
       " 'llama-4-scout': 1044.42804026603,\n",
       " 'deepseek-r1-distill-llama-70b': 1039.4057516599937,\n",
       " 'deepseek-r1': 1032.3990428270208,\n",
       " 'qwen2.5-7b-instruct': 1027.4715716462263,\n",
       " 'gemma-2-27b-it-q8': 1016.0217958881971,\n",
       " 'qwq-32b': 1014.3174253618948,\n",
       " 'o3-mini': 1013.354731842998,\n",
       " 'llama-3.3-70b': 1004.7079412529101,\n",
       " 'gpt-4o-2024-08-06': 994.9245187374013,\n",
       " 'llama-3.1-405b': 990.9290011881404,\n",
       " 'mistral-small-3.1-24b': 979.3113325482705,\n",
       " 'phi-4': 968.730593630965,\n",
       " 'aya-expanse-8b': 964.4740833113398,\n",
       " 'c4ai-command-r-08-2024': 964.4493026182439,\n",
       " 'jamba-1.5-large': 947.2974884208656,\n",
       " 'qwen2.5-coder-32b-instruct': 944.1442838616192,\n",
       " 'llama-3.1-70b': 939.8078782391656,\n",
       " 'ministral-8b-instruct-2410': 938.726829034465,\n",
       " 'gemma-2-9b-it': 937.2614647492525,\n",
       " 'claude-3-5-sonnet-v2': 929.8940092544711,\n",
       " 'llama-3.1-8b': 921.6225789217649,\n",
       " 'phi-3.5-mini-instruct': 909.0358379448667,\n",
       " 'lfm-40b': 888.5039571521824,\n",
       " 'mistral-small-24b-instruct-2501': 888.3273683703094,\n",
       " 'gpt-4.1-nano': 887.261338498941,\n",
       " 'mixtral-8x22b-instruct-v0.1': 862.7150437260882,\n",
       " 'mixtral-8x7b-instruct-v0.1': 857.4984031219888,\n",
       " 'mistral-nemo-2407': 849.1057311400435,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 810.3275474526712,\n",
       " 'hermes-3-llama-3.1-405b': 808.4468712214399}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = ELORanker(K=40)\n",
    "\n",
    "random.seed(1337)\n",
    "matches = random.sample(matches, k=len(matches))\n",
    "ranker.add_players(model_names)  # type: ignore\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul d'un score de frugalité\n",
    "\n",
    "Le score de frugalité est calculé à partir de données de consommation présentes dans le jeu de données `comparia-conversations`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of matches per model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>n_match</th><th>total_output_tokens</th></tr><tr><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;aya-expanse-8b&quot;</td><td>519</td><td>961445.0</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>1180</td><td>5.944341e6</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>598</td><td>511086.0</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>1994</td><td>2.818225e6</td></tr><tr><td>&quot;claude-3-7-sonnet&quot;</td><td>319</td><td>2.162331e6</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>462</td><td>851005.0</td></tr><tr><td>&quot;phi-4&quot;</td><td>1616</td><td>3.086417e6</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>427</td><td>870902.0</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>1641</td><td>4.787749e6</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>321</td><td>946986.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 3)\n",
       "┌─────────────────────────────────┬─────────┬─────────────────────┐\n",
       "│ model_name                      ┆ n_match ┆ total_output_tokens │\n",
       "│ ---                             ┆ ---     ┆ ---                 │\n",
       "│ str                             ┆ i64     ┆ f64                 │\n",
       "╞═════════════════════════════════╪═════════╪═════════════════════╡\n",
       "│ aya-expanse-8b                  ┆ 519     ┆ 961445.0            │\n",
       "│ c4ai-command-r-08-2024          ┆ 1180    ┆ 5.944341e6          │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 598     ┆ 511086.0            │\n",
       "│ claude-3-5-sonnet-v2            ┆ 1994    ┆ 2.818225e6          │\n",
       "│ claude-3-7-sonnet               ┆ 319     ┆ 2.162331e6          │\n",
       "│ …                               ┆ …       ┆ …                   │\n",
       "│ phi-3.5-mini-instruct           ┆ 462     ┆ 851005.0            │\n",
       "│ phi-4                           ┆ 1616    ┆ 3.086417e6          │\n",
       "│ qwen2.5-7b-instruct             ┆ 427     ┆ 870902.0            │\n",
       "│ qwen2.5-coder-32b-instruct      ┆ 1641    ┆ 4.787749e6          │\n",
       "│ qwq-32b                         ┆ 321     ┆ 946986.0            │\n",
       "└─────────────────────────────────┴─────────┴─────────────────────┘"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from rank_comparia.frugality import get_n_match, get_models_output_tokens\n",
    "\n",
    "number_by_model = get_n_match(ranker)\n",
    "total_tokens = get_models_output_tokens(reactions)\n",
    "\n",
    "number_by_model = number_by_model.join(total_tokens, on=\"model_name\")\n",
    "\n",
    "number_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>conso_all_conv</th><th>n_match</th><th>total_output_tokens</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;aya-expanse-8b&quot;</td><td>3.62259</td><td>519</td><td>961445.0</td><td>0.00698</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>44.921088</td><td>1180</td><td>5.944341e6</td><td>0.038069</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>1.853976</td><td>598</td><td>511086.0</td><td>0.0031</td><td>0.000004</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>378.314297</td><td>1994</td><td>2.818225e6</td><td>0.189726</td><td>0.000134</td></tr><tr><td>&quot;claude-3-7-sonnet&quot;</td><td>290.26807</td><td>319</td><td>2.162331e6</td><td>0.909931</td><td>0.000134</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>2.609332</td><td>462</td><td>851005.0</td><td>0.005648</td><td>0.000003</td></tr><tr><td>&quot;phi-4&quot;</td><td>14.228012</td><td>1616</td><td>3.086417e6</td><td>0.008804</td><td>0.000005</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>3.159217</td><td>427</td><td>870902.0</td><td>0.007399</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>34.16509</td><td>1641</td><td>4.787749e6</td><td>0.02082</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>6.757635</td><td>321</td><td>946986.0</td><td>0.021052</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 6)\n",
       "┌─────────────────┬────────────────┬─────────┬─────────────────┬─────────────────┬─────────────────┐\n",
       "│ model_name      ┆ conso_all_conv ┆ n_match ┆ total_output_to ┆ mean_conso_per_ ┆ mean_conso_per_ │\n",
       "│ ---             ┆ ---            ┆ ---     ┆ kens            ┆ match           ┆ token           │\n",
       "│ str             ┆ f64            ┆ i64     ┆ ---             ┆ ---             ┆ ---             │\n",
       "│                 ┆                ┆         ┆ f64             ┆ f64             ┆ f64             │\n",
       "╞═════════════════╪════════════════╪═════════╪═════════════════╪═════════════════╪═════════════════╡\n",
       "│ aya-expanse-8b  ┆ 3.62259        ┆ 519     ┆ 961445.0        ┆ 0.00698         ┆ 0.000004        │\n",
       "│ c4ai-command-r- ┆ 44.921088      ┆ 1180    ┆ 5.944341e6      ┆ 0.038069        ┆ 0.000008        │\n",
       "│ 08-2024         ┆                ┆         ┆                 ┆                 ┆                 │\n",
       "│ chocolatine-2-1 ┆ 1.853976       ┆ 598     ┆ 511086.0        ┆ 0.0031          ┆ 0.000004        │\n",
       "│ 4b-instruct-v2. ┆                ┆         ┆                 ┆                 ┆                 │\n",
       "│ …               ┆                ┆         ┆                 ┆                 ┆                 │\n",
       "│ claude-3-5-sonn ┆ 378.314297     ┆ 1994    ┆ 2.818225e6      ┆ 0.189726        ┆ 0.000134        │\n",
       "│ et-v2           ┆                ┆         ┆                 ┆                 ┆                 │\n",
       "│ claude-3-7-sonn ┆ 290.26807      ┆ 319     ┆ 2.162331e6      ┆ 0.909931        ┆ 0.000134        │\n",
       "│ et              ┆                ┆         ┆                 ┆                 ┆                 │\n",
       "│ …               ┆ …              ┆ …       ┆ …               ┆ …               ┆ …               │\n",
       "│ phi-3.5-mini-in ┆ 2.609332       ┆ 462     ┆ 851005.0        ┆ 0.005648        ┆ 0.000003        │\n",
       "│ struct          ┆                ┆         ┆                 ┆                 ┆                 │\n",
       "│ phi-4           ┆ 14.228012      ┆ 1616    ┆ 3.086417e6      ┆ 0.008804        ┆ 0.000005        │\n",
       "│ qwen2.5-7b-inst ┆ 3.159217       ┆ 427     ┆ 870902.0        ┆ 0.007399        ┆ 0.000004        │\n",
       "│ ruct            ┆                ┆         ┆                 ┆                 ┆                 │\n",
       "│ qwen2.5-coder-3 ┆ 34.16509       ┆ 1641    ┆ 4.787749e6      ┆ 0.02082         ┆ 0.000007        │\n",
       "│ 2b-instruct     ┆                ┆         ┆                 ┆                 ┆                 │\n",
       "│ qwq-32b         ┆ 6.757635       ┆ 321     ┆ 946986.0        ┆ 0.021052        ┆ 0.000007        │\n",
       "└─────────────────┴────────────────┴─────────┴─────────────────┴─────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.frugality import calculate_frugality_score, draw_chart\n",
    "\n",
    "frugal_scores = calculate_frugality_score(reactions, number_by_model, mean=True)\n",
    "\n",
    "frugal_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>elo_score</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1212.662424</td></tr><tr><td>&quot;claude-3-7-sonnet&quot;</td><td>1135.097965</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1127.649119</td></tr><tr><td>&quot;command-a&quot;</td><td>1109.07365</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1101.940136</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>862.715044</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>857.498403</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>849.105731</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>810.327547</td></tr><tr><td>&quot;hermes-3-llama-3.1-405b&quot;</td><td>808.446871</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 2)\n",
       "┌─────────────────────────────────┬─────────────┐\n",
       "│ model_name                      ┆ elo_score   │\n",
       "│ ---                             ┆ ---         │\n",
       "│ str                             ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╡\n",
       "│ deepseek-v3-chat                ┆ 1212.662424 │\n",
       "│ claude-3-7-sonnet               ┆ 1135.097965 │\n",
       "│ gemini-2.0-flash-001            ┆ 1127.649119 │\n",
       "│ command-a                       ┆ 1109.07365  │\n",
       "│ gemma-3-27b                     ┆ 1101.940136 │\n",
       "│ …                               ┆ …           │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 862.715044  │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 857.498403  │\n",
       "│ mistral-nemo-2407               ┆ 849.105731  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 810.327547  │\n",
       "│ hermes-3-llama-3.1-405b         ┆ 808.446871  │\n",
       "└─────────────────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_scores = pl.DataFrame(\n",
    "    {\n",
    "        \"model_name\": ranker.players.keys(),\n",
    "        \"elo_score\": ranker.players.values(),\n",
    "    },\n",
    "    strict=False,\n",
    ").sort(by=\"elo_score\", descending=True)\n",
    "\n",
    "elo_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "info_model = pl.read_json(source=Path(\".\").resolve().parent / \"data\" / \"models_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (39, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>model_name</th><th>organization</th><th>license</th><th>elo_score</th><th>conso_all_conv</th><th>n_match</th><th>total_output_tokens</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Aya-Expanse-8B&quot;</td><td>&quot;aya-expanse-8b&quot;</td><td>&quot;Cohere&quot;</td><td>&quot;CC-BY-NC-4.0&quot;</td><td>964.474083</td><td>3.62259</td><td>519</td><td>961445.0</td><td>0.00698</td><td>0.000004</td></tr><tr><td>&quot;Command R (08-2024)&quot;</td><td>&quot;c4ai-command-r-08-2024&quot;</td><td>&quot;Cohere&quot;</td><td>&quot;CC-BY-NC-4.0&quot;</td><td>964.449303</td><td>44.921088</td><td>1180</td><td>5.944341e6</td><td>0.038069</td><td>0.000008</td></tr><tr><td>&quot;Chocolatine-2-14b Instruct&quot;</td><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>&quot;jpacifico (individual)&quot;</td><td>&quot;Apache 2.0&quot;</td><td>810.327547</td><td>1.853976</td><td>598</td><td>511086.0</td><td>0.0031</td><td>0.000004</td></tr><tr><td>&quot;Claude 3.5 Sonnet V2&quot;</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;Anthropic&quot;</td><td>&quot;Proprietary&quot;</td><td>929.894009</td><td>378.314297</td><td>1994</td><td>2.818225e6</td><td>0.189726</td><td>0.000134</td></tr><tr><td>&quot;Command A&quot;</td><td>&quot;command-a&quot;</td><td>&quot;Cohere&quot;</td><td>&quot;CC-BY-NC-4.0&quot;</td><td>1109.07365</td><td>18.815316</td><td>457</td><td>1.03253e6</td><td>0.041171</td><td>0.000018</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Phi-3.5 Mini Instruct&quot;</td><td>&quot;phi-3.5-mini-instruct&quot;</td><td>&quot;Microsoft&quot;</td><td>&quot;MIT&quot;</td><td>909.035838</td><td>2.609332</td><td>462</td><td>851005.0</td><td>0.005648</td><td>0.000003</td></tr><tr><td>&quot;Phi 4&quot;</td><td>&quot;phi-4&quot;</td><td>&quot;Microsoft&quot;</td><td>&quot;MIT&quot;</td><td>968.730594</td><td>14.228012</td><td>1616</td><td>3.086417e6</td><td>0.008804</td><td>0.000005</td></tr><tr><td>&quot;Qwen2.5-7B&quot;</td><td>&quot;qwen2.5-7b-instruct&quot;</td><td>&quot;Alibaba&quot;</td><td>&quot;Apache 2.0&quot;</td><td>1027.471572</td><td>3.159217</td><td>427</td><td>870902.0</td><td>0.007399</td><td>0.000004</td></tr><tr><td>&quot;Qwen2.5-Coder-32B-Instruct&quot;</td><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>&quot;Alibaba&quot;</td><td>&quot;Apache 2.0&quot;</td><td>944.144284</td><td>34.16509</td><td>1641</td><td>4.787749e6</td><td>0.02082</td><td>0.000007</td></tr><tr><td>&quot;QwQ 32B&quot;</td><td>&quot;qwq-32b&quot;</td><td>&quot;Alibaba&quot;</td><td>&quot;Apache 2.0&quot;</td><td>1014.317425</td><td>6.757635</td><td>321</td><td>946986.0</td><td>0.021052</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (39, 10)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬─────────┬───────────┬───────────┬───────────┐\n",
       "│ name       ┆ model_nam ┆ organizat ┆ license   ┆ … ┆ n_match ┆ total_out ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ e         ┆ ion       ┆ ---       ┆   ┆ ---     ┆ put_token ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ ---       ┆ ---       ┆ str       ┆   ┆ i64     ┆ s         ┆ ch        ┆ en        │\n",
       "│            ┆ str       ┆ str       ┆           ┆   ┆         ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆         ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ Aya-Expans ┆ aya-expan ┆ Cohere    ┆ CC-BY-NC- ┆ … ┆ 519     ┆ 961445.0  ┆ 0.00698   ┆ 0.000004  │\n",
       "│ e-8B       ┆ se-8b     ┆           ┆ 4.0       ┆   ┆         ┆           ┆           ┆           │\n",
       "│ Command R  ┆ c4ai-comm ┆ Cohere    ┆ CC-BY-NC- ┆ … ┆ 1180    ┆ 5.944341e ┆ 0.038069  ┆ 0.000008  │\n",
       "│ (08-2024)  ┆ and-r-08- ┆           ┆ 4.0       ┆   ┆         ┆ 6         ┆           ┆           │\n",
       "│            ┆ 2024      ┆           ┆           ┆   ┆         ┆           ┆           ┆           │\n",
       "│ Chocolatin ┆ chocolati ┆ jpacifico ┆ Apache    ┆ … ┆ 598     ┆ 511086.0  ┆ 0.0031    ┆ 0.000004  │\n",
       "│ e-2-14b    ┆ ne-2-14b- ┆ (individu ┆ 2.0       ┆   ┆         ┆           ┆           ┆           │\n",
       "│ Instruct   ┆ instruct- ┆ al)       ┆           ┆   ┆         ┆           ┆           ┆           │\n",
       "│            ┆ v2.…      ┆           ┆           ┆   ┆         ┆           ┆           ┆           │\n",
       "│ Claude 3.5 ┆ claude-3- ┆ Anthropic ┆ Proprieta ┆ … ┆ 1994    ┆ 2.818225e ┆ 0.189726  ┆ 0.000134  │\n",
       "│ Sonnet V2  ┆ 5-sonnet- ┆           ┆ ry        ┆   ┆         ┆ 6         ┆           ┆           │\n",
       "│            ┆ v2        ┆           ┆           ┆   ┆         ┆           ┆           ┆           │\n",
       "│ Command A  ┆ command-a ┆ Cohere    ┆ CC-BY-NC- ┆ … ┆ 457     ┆ 1.03253e6 ┆ 0.041171  ┆ 0.000018  │\n",
       "│            ┆           ┆           ┆ 4.0       ┆   ┆         ┆           ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …       ┆ …         ┆ …         ┆ …         │\n",
       "│ Phi-3.5    ┆ phi-3.5-m ┆ Microsoft ┆ MIT       ┆ … ┆ 462     ┆ 851005.0  ┆ 0.005648  ┆ 0.000003  │\n",
       "│ Mini       ┆ ini-instr ┆           ┆           ┆   ┆         ┆           ┆           ┆           │\n",
       "│ Instruct   ┆ uct       ┆           ┆           ┆   ┆         ┆           ┆           ┆           │\n",
       "│ Phi 4      ┆ phi-4     ┆ Microsoft ┆ MIT       ┆ … ┆ 1616    ┆ 3.086417e ┆ 0.008804  ┆ 0.000005  │\n",
       "│            ┆           ┆           ┆           ┆   ┆         ┆ 6         ┆           ┆           │\n",
       "│ Qwen2.5-7B ┆ qwen2.5-7 ┆ Alibaba   ┆ Apache    ┆ … ┆ 427     ┆ 870902.0  ┆ 0.007399  ┆ 0.000004  │\n",
       "│            ┆ b-instruc ┆           ┆ 2.0       ┆   ┆         ┆           ┆           ┆           │\n",
       "│            ┆ t         ┆           ┆           ┆   ┆         ┆           ┆           ┆           │\n",
       "│ Qwen2.5-Co ┆ qwen2.5-c ┆ Alibaba   ┆ Apache    ┆ … ┆ 1641    ┆ 4.787749e ┆ 0.02082   ┆ 0.000007  │\n",
       "│ der-32B-In ┆ oder-32b- ┆           ┆ 2.0       ┆   ┆         ┆ 6         ┆           ┆           │\n",
       "│ struct     ┆ instruct  ┆           ┆           ┆   ┆         ┆           ┆           ┆           │\n",
       "│ QwQ 32B    ┆ qwq-32b   ┆ Alibaba   ┆ Apache    ┆ … ┆ 321     ┆ 946986.0  ┆ 0.021052  ┆ 0.000007  │\n",
       "│            ┆           ┆           ┆ 2.0       ┆   ┆         ┆           ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴─────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = info_model.join(elo_scores, on=\"model_name\").join(frugal_scores, on=\"model_name\")\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with more values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-44946b690dda46ad8cd326beef360b66.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-44946b690dda46ad8cd326beef360b66.vega-embed details,\n",
       "  #altair-viz-44946b690dda46ad8cd326beef360b66.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-44946b690dda46ad8cd326beef360b66\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-44946b690dda46ad8cd326beef360b66\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-44946b690dda46ad8cd326beef360b66\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d2ca849fbab02b71bda336d55cb7d797\"}, \"mark\": {\"type\": \"point\", \"filled\": true}, \"encoding\": {\"color\": {\"field\": \"organization\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": [{\"param\": \"param_6\", \"value\": 1}], \"value\": 0.3}, \"tooltip\": [{\"field\": \"model_name\", \"type\": \"nominal\"}, {\"field\": \"organization\", \"type\": \"nominal\"}, {\"field\": \"license\", \"type\": \"nominal\"}, {\"field\": \"elo_score\", \"type\": \"quantitative\"}, {\"field\": \"conso_all_conv\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"conso_all_conv\", \"scale\": {\"type\": \"log\"}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"elo_score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}, \"height\": 300, \"params\": [{\"name\": \"param_6\", \"select\": {\"type\": \"point\", \"fields\": [\"organization\"]}, \"bind\": \"legend\"}, {\"name\": \"param_5\", \"select\": {\"type\": \"point\", \"fields\": [\"license\"]}, \"bind\": {\"input\": \"select\", \"options\": [\"DeepSeek\", \"Proprietary\", \"Gemma\", \"MIT\", \"Apache 2.0\", \"Gemma license\", \"Llama 3.3 Community\", \"Mistral Research\", \"Jamba Open Model License\", \"Unknown\", \"MRL\", \"llama3\", \"Llama 3.1 Community\", \"CC-BY-NC-4.0\"], \"labels\": [\"Llama 3.3 Community \", \"Llama 3.1 Community \", \"Mistral Research \", \"DeepSeek \", \"Proprietary \", \"MRL \", \"MIT \", \"Gemma license \", \"Gemma \", \"Apache 2.0 \", \"Unknown \", \"CC-BY-NC-4.0 \", \"llama3 \", \"Jamba Open Model License \", \"All\"], \"name\": \"License \"}}], \"title\": \"\", \"transform\": [{\"filter\": {\"param\": \"param_5\"}}], \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-d2ca849fbab02b71bda336d55cb7d797\": [{\"name\": \"Aya-Expanse-8B\", \"model_name\": \"aya-expanse-8b\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 964.4740833113398, \"conso_all_conv\": 3.6225901576999946, \"n_match\": 519, \"total_output_tokens\": 961445.0, \"mean_conso_per_match\": 0.006979942500385346, \"mean_conso_per_token\": 3.767859999999994e-06}, {\"name\": \"Command R (08-2024)\", \"model_name\": \"c4ai-command-r-08-2024\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 964.4493026182439, \"conso_all_conv\": 44.92108771994969, \"n_match\": 1180, \"total_output_tokens\": 5944341.0, \"mean_conso_per_match\": 0.03806871840673703, \"mean_conso_per_token\": 7.556949999999948e-06}, {\"name\": \"Chocolatine-2-14b Instruct\", \"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"organization\": \"jpacifico (individual)\", \"license\": \"Apache 2.0\", \"elo_score\": 810.3275474526712, \"conso_all_conv\": 1.853976390340002, \"n_match\": 598, \"total_output_tokens\": 511086.0, \"mean_conso_per_match\": 0.003100294967123749, \"mean_conso_per_token\": 3.627523333333337e-06}, {\"name\": \"Claude 3.5 Sonnet V2\", \"model_name\": \"claude-3-5-sonnet-v2\", \"organization\": \"Anthropic\", \"license\": \"Proprietary\", \"elo_score\": 929.8940092544711, \"conso_all_conv\": 378.31429666249966, \"n_match\": 1994, \"total_output_tokens\": 2818225.0, \"mean_conso_per_match\": 0.1897263273131894, \"mean_conso_per_token\": 0.00013423849999999988}, {\"name\": \"Command A\", \"model_name\": \"command-a\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 1109.0736501865697, \"conso_all_conv\": 18.815315784433313, \"n_match\": 457, \"total_output_tokens\": 1032530.0, \"mean_conso_per_match\": 0.04117136933136392, \"mean_conso_per_token\": 1.8222536666666648e-05}, {\"name\": \"DeepSeek-R1\", \"model_name\": \"deepseek-r1\", \"organization\": \"DeepSeek\", \"license\": \"MIT\", \"elo_score\": 1032.3990428270208, \"conso_all_conv\": 54.55267994439995, \"n_match\": 486, \"total_output_tokens\": 1160060.0, \"mean_conso_per_match\": 0.11224831264279825, \"mean_conso_per_token\": 4.7025739999999955e-05}, {\"name\": \"DeepSeek-R1 distiil\", \"model_name\": \"deepseek-r1-distill-llama-70b\", \"organization\": \"DeepSeek\", \"license\": \"MIT\", \"elo_score\": 1039.4057516599937, \"conso_all_conv\": 9.250565728733326, \"n_match\": 454, \"total_output_tokens\": 741901.0, \"mean_conso_per_match\": 0.020375695437738605, \"mean_conso_per_token\": 1.2468733333333323e-05}, {\"name\": \"DeepSeek-V3 Chat\", \"model_name\": \"deepseek-v3-chat\", \"organization\": \"DeepSeek\", \"license\": \"DeepSeek\", \"elo_score\": 1212.6624236322593, \"conso_all_conv\": 445.6130906956012, \"n_match\": 1866, \"total_output_tokens\": 9475940.0, \"mean_conso_per_match\": 0.23880658665359122, \"mean_conso_per_token\": 4.702574000000013e-05}, {\"name\": \"Gemini 1.5 pro 001\", \"model_name\": \"gemini-1.5-pro-001\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1073.9973563665326, \"conso_all_conv\": 82.15188674586669, \"n_match\": 392, \"total_output_tokens\": 612722.0, \"mean_conso_per_match\": 0.2095711396578232, \"mean_conso_per_token\": 0.00013407693333333337}, {\"name\": \"Gemini 1.5 pro 002\", \"model_name\": \"gemini-1.5-pro-002\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1100.4153564892965, \"conso_all_conv\": 440.3189729905331, \"n_match\": 1672, \"total_output_tokens\": 3284077.0, \"mean_conso_per_match\": 0.26334866805653895, \"mean_conso_per_token\": 0.00013407693333333326}, {\"name\": \"Gemini 2.0 Flash\", \"model_name\": \"gemini-2.0-flash-001\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1127.6491187502902, \"conso_all_conv\": 19.000307364666675, \"n_match\": 806, \"total_output_tokens\": 2300660.0, \"mean_conso_per_match\": 0.023573582338296123, \"mean_conso_per_token\": 8.258633333333338e-06}, {\"name\": \"Gemini 2.0 Flash\", \"model_name\": \"gemini-2.0-flash-exp\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1079.9107468559318, \"conso_all_conv\": 25.408618675566665, \"n_match\": 1001, \"total_output_tokens\": 3076613.0, \"mean_conso_per_match\": 0.025383235440126536, \"mean_conso_per_token\": 8.258633333333333e-06}, {\"name\": \"Gemma 2 27B q8\", \"model_name\": \"gemma-2-27b-it-q8\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 1016.0217958881971, \"conso_all_conv\": 1.5577335389999991, \"n_match\": 170, \"total_output_tokens\": 242100.0, \"mean_conso_per_match\": 0.009163138464705877, \"mean_conso_per_token\": 6.434256666666663e-06}, {\"name\": \"Gemma 2 9B\", \"model_name\": \"gemma-2-9b-it\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 937.2614647492525, \"conso_all_conv\": 7.879733476710017, \"n_match\": 1520, \"total_output_tokens\": 2016207.0, \"mean_conso_per_match\": 0.005184035182046064, \"mean_conso_per_token\": 3.908196666666675e-06}, {\"name\": \"Gemma 3 12B\", \"model_name\": \"gemma-3-12b\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 1072.9365403748707, \"conso_all_conv\": 4.712925899566667, \"n_match\": 457, \"total_output_tokens\": 1088635.0, \"mean_conso_per_match\": 0.010312748139095551, \"mean_conso_per_token\": 4.329206666666667e-06}, {\"name\": \"Gemma-3 27B\", \"model_name\": \"gemma-3-27b\", \"organization\": \"Google\", \"license\": \"Gemma\", \"elo_score\": 1101.940135903943, \"conso_all_conv\": 9.046397582660008, \"n_match\": 579, \"total_output_tokens\": 1405974.0, \"mean_conso_per_match\": 0.01562417544500865, \"mean_conso_per_token\": 6.434256666666672e-06}, {\"name\": \"Gemma 3 4B\", \"model_name\": \"gemma-3-4b\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 1074.074137515472, \"conso_all_conv\": 3.6805289928866673, \"n_match\": 459, \"total_output_tokens\": 1147829.0, \"mean_conso_per_match\": 0.008018581683848948, \"mean_conso_per_token\": 3.206513333333334e-06}, {\"name\": \"GPT-4o mini\", \"model_name\": \"gpt-4o-mini-2024-07-18\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\", \"elo_score\": 1051.529204861027, \"conso_all_conv\": 28.75581949424996, \"n_match\": 2183, \"total_output_tokens\": 3805215.0, \"mean_conso_per_match\": 0.013172615434837361, \"mean_conso_per_token\": 7.5569499999999895e-06}, {\"name\": \"Hermes 3\", \"model_name\": \"hermes-3-llama-3.1-405b\", \"organization\": \"Nous Research\", \"license\": \"llama3\", \"elo_score\": 808.4468712214399, \"conso_all_conv\": 995.1062638958654, \"n_match\": 1381, \"total_output_tokens\": 4182418.0, \"mean_conso_per_match\": 0.7205693438782516, \"mean_conso_per_token\": 0.00023792606666666637}, {\"name\": \"Jamba Large\", \"model_name\": \"jamba-1.5-large\", \"organization\": \"AI21 Labs\", \"license\": \"Jamba Open Model License\", \"elo_score\": 947.2974884208656, \"conso_all_conv\": 27.637820667239993, \"n_match\": 77, \"total_output_tokens\": 581721.0, \"mean_conso_per_match\": 0.3589327359381817, \"mean_conso_per_token\": 4.751043999999999e-05}, {\"name\": \"Liquid Foundation Model\", \"model_name\": \"lfm-40b\", \"organization\": \"Liquid\", \"license\": \"Unknown\", \"elo_score\": 888.5039571521824, \"conso_all_conv\": 15.96704347946668, \"n_match\": 1069, \"total_output_tokens\": 1933376.0, \"mean_conso_per_match\": 0.014936429821764902, \"mean_conso_per_token\": 8.258633333333341e-06}, {\"name\": \"Llama 3.1 405B\", \"model_name\": \"llama-3.1-405b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 990.9290011881404, \"conso_all_conv\": 1017.4927275085383, \"n_match\": 2114, \"total_output_tokens\": 4276508.0, \"mean_conso_per_match\": 0.4813116024165271, \"mean_conso_per_token\": 0.00023792606666666783}, {\"name\": \"Llama-3.1-70B\", \"model_name\": \"llama-3.1-70b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 939.8078782391656, \"conso_all_conv\": 30.55808487246673, \"n_match\": 1597, \"total_output_tokens\": 2450777.0, \"mean_conso_per_match\": 0.01913468057136301, \"mean_conso_per_token\": 1.2468733333333359e-05}, {\"name\": \"Llama 3.1 8B\", \"model_name\": \"llama-3.1-8b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 921.6225789217649, \"conso_all_conv\": 11.279213249379985, \"n_match\": 1785, \"total_output_tokens\": 2993533.0, \"mean_conso_per_match\": 0.006318886974442569, \"mean_conso_per_token\": 3.767859999999995e-06}, {\"name\": \"Nemotron 70B Instruct\", \"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"organization\": \"Nvidia\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 1045.6443800662353, \"conso_all_conv\": 49.341271546666775, \"n_match\": 1269, \"total_output_tokens\": 3957200.0, \"mean_conso_per_match\": 0.03888201067507232, \"mean_conso_per_token\": 1.246873333333336e-05}, {\"name\": \"Llama 3.3 70B\", \"model_name\": \"llama-3.3-70b\", \"organization\": \"Meta\", \"license\": \"Llama 3.3 Community\", \"elo_score\": 1004.7079412529101, \"conso_all_conv\": 72.24350427753315, \"n_match\": 1207, \"total_output_tokens\": 5793973.0, \"mean_conso_per_match\": 0.059853773220822824, \"mean_conso_per_token\": 1.2468733333333301e-05}, {\"name\": \"Ministral 8B-Instruct\", \"model_name\": \"ministral-8b-instruct-2410\", \"organization\": \"Mistral\", \"license\": \"MRL\", \"elo_score\": 938.726829034465, \"conso_all_conv\": 12.161619686360076, \"n_match\": 1962, \"total_output_tokens\": 3227726.0, \"mean_conso_per_match\": 0.006198582918634086, \"mean_conso_per_token\": 3.767860000000024e-06}, {\"name\": \"Mistral-Large-2411\", \"model_name\": \"mistral-large-2411\", \"organization\": \"Mistral\", \"license\": \"Mistral Research\", \"elo_score\": 1094.3219154801855, \"conso_all_conv\": 180.43609736028264, \"n_match\": 1849, \"total_output_tokens\": 9064145.0, \"mean_conso_per_match\": 0.09758577466754063, \"mean_conso_per_token\": 1.990657666666659e-05}, {\"name\": \"Mistral Nemo Instruct\", \"model_name\": \"mistral-nemo-2407\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 849.1057311400435, \"conso_all_conv\": 9.09769793379999, \"n_match\": 1786, \"total_output_tokens\": 2101470.0, \"mean_conso_per_match\": 0.005093895819596859, \"mean_conso_per_token\": 4.329206666666662e-06}, {\"name\": \"Mistral-Small-24B-Instruct-2501\", \"model_name\": \"mistral-small-24b-instruct-2501\", \"organization\": \"Mistral\", \"license\": \"Apache 2.0\", \"elo_score\": 888.3273683703094, \"conso_all_conv\": 14.678287007359955, \"n_match\": 1094, \"total_output_tokens\": 2440992.0, \"mean_conso_per_match\": 0.013417081359561203, \"mean_conso_per_token\": 6.013246666666649e-06}, {\"name\": \"Mistral Small-3.1 24B\", \"model_name\": \"mistral-small-3.1-24b\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 979.3113325482705, \"conso_all_conv\": 5.058114592626664, \"n_match\": 513, \"total_output_tokens\": 841162.0, \"mean_conso_per_match\": 0.009859872500246909, \"mean_conso_per_token\": 6.013246666666663e-06}, {\"name\": \"Mixtral 8x22B Instruct\", \"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 862.7150437260882, \"conso_all_conv\": 50.96510783260014, \"n_match\": 1756, \"total_output_tokens\": 2889185.0, \"mean_conso_per_match\": 0.029023409927448826, \"mean_conso_per_token\": 1.763996000000005e-05}, {\"name\": \"Mixtral 8x7B Instruct\", \"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 857.4984031219888, \"conso_all_conv\": 4.14920547184, \"n_match\": 675, \"total_output_tokens\": 900068.0, \"mean_conso_per_match\": 0.006146971069392593, \"mean_conso_per_token\": 4.60988e-06}, {\"name\": \"o3-mini\", \"model_name\": \"o3-mini\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\", \"elo_score\": 1013.354731842998, \"conso_all_conv\": 57.0336039000001, \"n_match\": 437, \"total_output_tokens\": 928508.0, \"mean_conso_per_match\": 0.13051167940503455, \"mean_conso_per_token\": 6.142500000000011e-05}, {\"name\": \"Phi-3.5 Mini Instruct\", \"model_name\": \"phi-3.5-mini-instruct\", \"organization\": \"Microsoft\", \"license\": \"MIT\", \"elo_score\": 909.0358379448667, \"conso_all_conv\": 2.609331674216668, \"n_match\": 462, \"total_output_tokens\": 851005.0, \"mean_conso_per_match\": 0.0056479040567460346, \"mean_conso_per_token\": 3.066176666666668e-06}, {\"name\": \"Phi 4\", \"model_name\": \"phi-4\", \"organization\": \"Microsoft\", \"license\": \"MIT\", \"elo_score\": 968.730593630965, \"conso_all_conv\": 14.228011999959978, \"n_match\": 1616, \"total_output_tokens\": 3086417.0, \"mean_conso_per_match\": 0.008804462871262363, \"mean_conso_per_token\": 4.609879999999993e-06}, {\"name\": \"Qwen2.5-7B\", \"model_name\": \"qwen2.5-7b-instruct\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 1027.4715716462263, \"conso_all_conv\": 3.159217326046669, \"n_match\": 427, \"total_output_tokens\": 870902.0, \"mean_conso_per_match\": 0.007398635423996883, \"mean_conso_per_token\": 3.627523333333336e-06}, {\"name\": \"Qwen2.5-Coder-32B-Instruct\", \"model_name\": \"qwen2.5-coder-32b-instruct\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 944.1442838616192, \"conso_all_conv\": 34.16508959906006, \"n_match\": 1641, \"total_output_tokens\": 4787749.0, \"mean_conso_per_match\": 0.02081967678187694, \"mean_conso_per_token\": 7.135940000000013e-06}, {\"name\": \"QwQ 32B\", \"model_name\": \"qwq-32b\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 1014.3174253618948, \"conso_all_conv\": 6.757635276840006, \"n_match\": 321, \"total_output_tokens\": 946986.0, \"mean_conso_per_match\": 0.021051823292336465, \"mean_conso_per_token\": 7.135940000000006e-06}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_chart(final_df, title=\"\", log=True, scale=\"token\", mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
