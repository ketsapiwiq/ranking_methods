{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport polars as pl\\nfrom getpass import getpass\\n\\nhf_token = getpass()\\nos.environ[\"HF_HUB_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\\nos.environ[\"HF_DATASETS_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\\nos.environ[\"HF_TOKEN\"] = hf_token'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass()\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\"\n",
    "os.environ[\"HF_TOKEN\"] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import datasets\\n\\ncomparia = datasets.load_dataset(\\n    \"ministere-culture/comparia-reactions\",\\n    cache_dir=\"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\",\\n    split=\"train\",\\n)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "comparia = datasets.load_dataset(\n",
    "    \"ministere-culture/comparia-reactions\",\n",
    "    cache_dir=\"/home/jupyterhub-users/shared/projet_comparia/huggingface_hub/\",\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia: pl.DataFrame = comparia.to_polars()  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparia_model_a = (\n",
    "    comparia.group_by([\"model_a_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_a_name\")\n",
    "    .drop(\"model_a_name\")\n",
    ")\n",
    "comparia_model_b = (\n",
    "    comparia.group_by([\"model_b_name\"])\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .with_columns(model_name=\"model_b_name\")\n",
    "    .drop(\"model_b_name\")\n",
    ")\n",
    "number_by_model = (\n",
    "    pl.concat([comparia_model_a, comparia_model_b]).group_by(\"model_name\").sum().sort(\"len\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>3894</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>3857</td></tr><tr><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>3816</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>3514</td></tr><tr><td>&quot;llama-3.1-405b&quot;</td><td>3409</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;gemma-3-12b&quot;</td><td>408</td></tr><tr><td>&quot;mistral-small-3.1-24b&quot;</td><td>383</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>381</td></tr><tr><td>&quot;gemma-2-27b-it-q8&quot;</td><td>296</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>237</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 2)\n",
       "┌────────────────────────┬──────┐\n",
       "│ model_name             ┆ len  │\n",
       "│ ---                    ┆ ---  │\n",
       "│ str                    ┆ u32  │\n",
       "╞════════════════════════╪══════╡\n",
       "│ gpt-4o-2024-08-06      ┆ 3894 │\n",
       "│ deepseek-v3-chat       ┆ 3857 │\n",
       "│ gpt-4o-mini-2024-07-18 ┆ 3816 │\n",
       "│ claude-3-5-sonnet-v2   ┆ 3514 │\n",
       "│ llama-3.1-405b         ┆ 3409 │\n",
       "│ …                      ┆ …    │\n",
       "│ gemma-3-12b            ┆ 408  │\n",
       "│ mistral-small-3.1-24b  ┆ 383  │\n",
       "│ gemma-3-4b             ┆ 381  │\n",
       "│ gemma-2-27b-it-q8      ┆ 296  │\n",
       "│ jamba-1.5-large        ┆ 237  │\n",
       "└────────────────────────┴──────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(comparia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;aya-expanse-8b&quot;</td><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>&quot;0d343e022ffc480c904b9c72f9124e…</td><td>0</td><td>0</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>&quot;llama-3.1-70b&quot;</td><td>&quot;3f53ccb6592b4f44bede2a05d1dbdd…</td><td>1</td><td>0</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;gemini-2.0-flash-exp&quot;</td><td>&quot;6fb44fa3c1fc4e8cb785fe74ed606e…</td><td>-2</td><td>1</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;5270a7ab2c0f404ebf98b2ca24fd72…</td><td>-4</td><td>4</td></tr><tr><td>&quot;mistral-small-24b-instruct-250…</td><td>&quot;llama-3.1-nemotron-70b-instruc…</td><td>&quot;7c8e98541f724790856271617262f0…</td><td>2</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────────┬─────────────────────────┬─────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name             ┆ model_b_name            ┆ conversation_pair_id    ┆ score_a ┆ score_b │\n",
       "│ ---                      ┆ ---                     ┆ ---                     ┆ ---     ┆ ---     │\n",
       "│ str                      ┆ str                     ┆ str                     ┆ i64     ┆ i64     │\n",
       "╞══════════════════════════╪═════════════════════════╪═════════════════════════╪═════════╪═════════╡\n",
       "│ aya-expanse-8b           ┆ mixtral-8x22b-instruct- ┆ 0d343e022ffc480c904b9c7 ┆ 0       ┆ 0       │\n",
       "│                          ┆ v0.1                    ┆ 2f9124e…                ┆         ┆         │\n",
       "│ phi-3.5-mini-instruct    ┆ llama-3.1-70b           ┆ 3f53ccb6592b4f44bede2a0 ┆ 1       ┆ 0       │\n",
       "│                          ┆                         ┆ 5d1dbdd…                ┆         ┆         │\n",
       "│ llama-3.1-8b             ┆ gemini-2.0-flash-exp    ┆ 6fb44fa3c1fc4e8cb785fe7 ┆ -2      ┆ 1       │\n",
       "│                          ┆                         ┆ 4ed606e…                ┆         ┆         │\n",
       "│ chocolatine-2-14b-instru ┆ claude-3-5-sonnet-v2    ┆ 5270a7ab2c0f404ebf98b2c ┆ -4      ┆ 4       │\n",
       "│ ct-v2.…                  ┆                         ┆ a24fd72…                ┆         ┆         │\n",
       "│ mistral-small-24b-instru ┆ llama-3.1-nemotron-70b- ┆ 7c8e98541f7247908562716 ┆ 2       ┆ 3       │\n",
       "│ ct-250…                  ┆ instruc…                ┆ 17262f0…                ┆         ┆         │\n",
       "└──────────────────────────┴─────────────────────────┴─────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>275</td><td>202</td><td>73.454545</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1511</td><td>1065</td><td>70.483124</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>434</td><td>301</td><td>69.354839</td></tr><tr><td>&quot;command-a&quot;</td><td>208</td><td>141</td><td>67.788462</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1440</td><td>430</td><td>29.861111</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ gemma-3-27b                     ┆ 275  ┆ 202  ┆ 73.454545 │\n",
       "│ deepseek-v3-chat                ┆ 1511 ┆ 1065 ┆ 70.483124 │\n",
       "│ gemini-2.0-flash-001            ┆ 434  ┆ 301  ┆ 69.354839 │\n",
       "│ command-a                       ┆ 208  ┆ 141  ┆ 67.788462 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1440 ┆ 430  ┆ 29.861111 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1153.1917521849846\n",
      "gemma-3-27b : 1150.4243228233127\n",
      "deepseek-v3-chat : 1126.568574007991\n",
      "gemini-2.0-flash-001 : 1120.580618263385\n",
      "command-a : 1110.8499310552359\n",
      "llama-3.1-nemotron-70b-instruct : 1080.0654812644425\n",
      "gemma-3-12b : 1074.3541247061266\n",
      "deepseek-r1 : 1065.7916869459375\n",
      "gemma-3-4b : 1061.6427653019982\n",
      "gemini-1.5-pro-002 : 1053.2831114378766\n",
      "gemini-1.5-pro-001 : 1051.1822147050527\n",
      "mistral-small-3.1-24b : 1040.1165001938648\n",
      "mistral-large-2411 : 1038.283070801158\n",
      "gpt-4o-mini-2024-07-18 : 1016.5955618293206\n",
      "llama-3.1-405b : 1015.3381865046157\n",
      "claude-3-5-sonnet-v2 : 1014.5216611944884\n",
      "o3-mini : 1012.8998439472485\n",
      "llama-3.3-70b : 1006.6974833398053\n",
      "gpt-4o-2024-08-06 : 1004.6584967327492\n",
      "mistral-small-24b-instruct-2501 : 1000.9951336813177\n",
      "jamba-1.5-large : 996.1224560427638\n",
      "phi-4 : 993.5682938562879\n",
      "llama-3.1-70b : 987.3309540121828\n",
      "gemma-2-27b-it-q8 : 985.8051154675218\n",
      "deepseek-r1-distill-llama-70b : 980.7221978560152\n",
      "gemma-2-9b-it : 979.1377307864168\n",
      "aya-expanse-8b : 972.3830336451975\n",
      "ministral-8b-instruct-2410 : 971.8276651409395\n",
      "qwq-32b : 959.369871084673\n",
      "hermes-3-llama-3.1-405b : 954.0590192530191\n",
      "c4ai-command-r-08-2024 : 949.7187026527316\n",
      "llama-3.1-8b : 938.8655039181799\n",
      "qwen2.5-coder-32b-instruct : 937.2869015151693\n",
      "qwen2.5-7b-instruct : 926.0648594667929\n",
      "lfm-40b : 904.6504179524887\n",
      "phi-3.5-mini-instruct : 902.2315570480225\n",
      "mixtral-8x7b-instruct-v0.1 : 898.5270318300703\n",
      "mixtral-8x22b-instruct-v0.1 : 867.756467180666\n",
      "mistral-nemo-2407 : 861.0744164672343\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 835.4572839027186\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepseek-v3-chat': 1189.7121843811944,\n",
       " 'gemma-3-27b': 1184.2839363672344,\n",
       " 'gemini-2.0-flash-exp': 1121.0705518542718,\n",
       " 'gemini-2.0-flash-001': 1120.0818032951888,\n",
       " 'gemini-1.5-pro-001': 1116.457652774753,\n",
       " 'command-a': 1085.7927015314162,\n",
       " 'gemini-1.5-pro-002': 1085.2308721253512,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1080.9896320034711,\n",
       " 'deepseek-r1': 1067.4550685921402,\n",
       " 'mistral-large-2411': 1067.3900016647794,\n",
       " 'gemma-3-12b': 1063.6642148662647,\n",
       " 'gemma-2-27b-it-q8': 1052.5065862212975,\n",
       " 'gemma-3-4b': 1049.9509997819796,\n",
       " 'qwq-32b': 1040.7807222085173,\n",
       " 'o3-mini': 1036.1997403131288,\n",
       " 'claude-3-5-sonnet-v2': 1020.1520903021325,\n",
       " 'gpt-4o-mini-2024-07-18': 1018.4135685231082,\n",
       " 'llama-3.1-405b': 1011.6994140035113,\n",
       " 'gpt-4o-2024-08-06': 994.9352688883218,\n",
       " 'mistral-small-24b-instruct-2501': 977.1611384938334,\n",
       " 'mistral-small-3.1-24b': 976.9032263527009,\n",
       " 'phi-3.5-mini-instruct': 974.5508536779101,\n",
       " 'llama-3.3-70b': 970.2526924757079,\n",
       " 'jamba-1.5-large': 966.3613565003008,\n",
       " 'llama-3.1-70b': 959.5945554110565,\n",
       " 'phi-4': 959.0295085901589,\n",
       " 'mixtral-8x7b-instruct-v0.1': 958.0049518744452,\n",
       " 'c4ai-command-r-08-2024': 956.8251432878686,\n",
       " 'qwen2.5-coder-32b-instruct': 955.9378487494887,\n",
       " 'gemma-2-9b-it': 945.3341478437619,\n",
       " 'ministral-8b-instruct-2410': 938.4632533030677,\n",
       " 'qwen2.5-7b-instruct': 929.0931661195842,\n",
       " 'hermes-3-llama-3.1-405b': 925.7635123609463,\n",
       " 'llama-3.1-8b': 910.9152572106755,\n",
       " 'lfm-40b': 907.5569795121058,\n",
       " 'aya-expanse-8b': 905.9205141372767,\n",
       " 'mixtral-8x22b-instruct-v0.1': 896.7987179237139,\n",
       " 'deepseek-r1-distill-llama-70b': 888.140622868875,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 859.9607272485363,\n",
       " 'mistral-nemo-2407': 830.6648163599299}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(42)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1187.2567752933778,\n",
       " 'gemma-3-27b': 1130.4482957390255,\n",
       " 'deepseek-v3-chat': 1109.5086040897133,\n",
       " 'deepseek-r1': 1094.8254083367322,\n",
       " 'gemini-2.0-flash-001': 1092.5100639601135,\n",
       " 'gemma-3-12b': 1084.9237133106296,\n",
       " 'command-a': 1078.3891750326056,\n",
       " 'llama-3.1-405b': 1077.5172994913676,\n",
       " 'mistral-large-2411': 1075.6668303885447,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1052.522522165146,\n",
       " 'phi-4': 1052.1330917389332,\n",
       " 'gemini-1.5-pro-002': 1043.367789364427,\n",
       " 'gpt-4o-2024-08-06': 1040.7748146207252,\n",
       " 'gemini-1.5-pro-001': 1037.701988282026,\n",
       " 'llama-3.3-70b': 1029.5276520990058,\n",
       " 'claude-3-5-sonnet-v2': 1029.3040448608099,\n",
       " 'gpt-4o-mini-2024-07-18': 1016.0233377113445,\n",
       " 'mistral-small-3.1-24b': 1014.6516071792289,\n",
       " 'gemma-3-4b': 1003.9334853904393,\n",
       " 'ministral-8b-instruct-2410': 995.3251445393876,\n",
       " 'o3-mini': 990.2755142940731,\n",
       " 'gemma-2-9b-it': 988.0128484491373,\n",
       " 'jamba-1.5-large': 984.0416915670814,\n",
       " 'gemma-2-27b-it-q8': 983.5179013775755,\n",
       " 'mistral-small-24b-instruct-2501': 983.3483431488236,\n",
       " 'c4ai-command-r-08-2024': 973.1914198512476,\n",
       " 'deepseek-r1-distill-llama-70b': 967.4748205643748,\n",
       " 'llama-3.1-70b': 960.1273690218792,\n",
       " 'qwen2.5-7b-instruct': 956.3981314573372,\n",
       " 'hermes-3-llama-3.1-405b': 955.2117981982482,\n",
       " 'qwen2.5-coder-32b-instruct': 947.8363316276404,\n",
       " 'qwq-32b': 935.6736892482986,\n",
       " 'mistral-nemo-2407': 926.8840403344866,\n",
       " 'aya-expanse-8b': 923.51977364979,\n",
       " 'phi-3.5-mini-instruct': 903.6460802785439,\n",
       " 'llama-3.1-8b': 898.2630635744302,\n",
       " 'lfm-40b': 891.3448080697107,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 871.4363478217277,\n",
       " 'mixtral-8x7b-instruct-v0.1': 865.6561686894954,\n",
       " 'mixtral-8x22b-instruct-v0.1': 847.8282151825236}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "seed(1337)\n",
    "matches_shuffle = sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul frugalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>conversation_pair_id</th><th>model_a_name</th><th>model_b_name</th><th>model_pair_name</th><th>total_conv_a_kwh</th><th>total_conv_b_kwh</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>53859</td><td>&quot;6673f2f88dae46498fd37cb43a6cce…</td><td>&quot;ministral-8b-instruct-2410&quot;</td><td>&quot;mistral-large-2411&quot;</td><td>&quot;{ministral-8b-instruct-2410,mi…</td><td>0.002596</td><td>0.01268</td></tr><tr><td>24309</td><td>&quot;f615f573bf674c37a9b354cb80baa1…</td><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;ministral-8b-instruct-2410&quot;</td><td>&quot;gpt-4o-2024-08-06,ministral-8b…</td><td>0.0773955</td><td>0.006029</td></tr><tr><td>44528</td><td>&quot;2c64ef7296564a8a89fc06960fe229…</td><td>&quot;aya-expanse-8b&quot;</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;{aya-expanse-8b,gpt-4o-mini-20…</td><td>0.001304</td><td>0.00093</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 7)\n",
       "┌───────┬───────────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┐\n",
       "│ id    ┆ conversation_ ┆ model_a_name ┆ model_b_name ┆ model_pair_n ┆ total_conv_a ┆ total_conv_b │\n",
       "│ ---   ┆ pair_id       ┆ ---          ┆ ---          ┆ ame          ┆ _kwh         ┆ _kwh         │\n",
       "│ i64   ┆ ---           ┆ str          ┆ str          ┆ ---          ┆ ---          ┆ ---          │\n",
       "│       ┆ str           ┆              ┆              ┆ str          ┆ f64          ┆ f64          │\n",
       "╞═══════╪═══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╡\n",
       "│ 53859 ┆ 6673f2f88dae4 ┆ ministral-8b ┆ mistral-larg ┆ {ministral-8 ┆ 0.002596     ┆ 0.01268      │\n",
       "│       ┆ 6498fd37cb43a ┆ -instruct-24 ┆ e-2411       ┆ b-instruct-2 ┆              ┆              │\n",
       "│       ┆ 6cce…         ┆ 10           ┆              ┆ 410,mi…      ┆              ┆              │\n",
       "│ 24309 ┆ f615f573bf674 ┆ gpt-4o-2024- ┆ ministral-8b ┆ gpt-4o-2024- ┆ 0.0773955    ┆ 0.006029     │\n",
       "│       ┆ c37a9b354cb80 ┆ 08-06        ┆ -instruct-24 ┆ 08-06,minist ┆              ┆              │\n",
       "│       ┆ baa1…         ┆              ┆ 10           ┆ ral-8b…      ┆              ┆              │\n",
       "│ 44528 ┆ 2c64ef7296564 ┆ aya-expanse- ┆ gpt-4o-mini- ┆ {aya-expanse ┆ 0.001304     ┆ 0.00093      │\n",
       "│       ┆ a8a89fc06960f ┆ 8b           ┆ 2024-07-18   ┆ -8b,gpt-4o-m ┆              ┆              │\n",
       "│       ┆ e229…         ┆              ┆              ┆ ini-20…      ┆              ┆              │\n",
       "└───────┴───────────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_infos = pl.read_parquet(\n",
    "    \"../data/conversations.parquet\",\n",
    "    columns=[\n",
    "        \"id\",\n",
    "        \"conversation_pair_id\",\n",
    "        \"model_a_name\",\n",
    "        \"model_b_name\",\n",
    "        \"model_pair_name\",\n",
    "        \"total_conv_a_kwh\",\n",
    "        \"total_conv_b_kwh\",\n",
    "    ],\n",
    ").unique(subset=\"conversation_pair_id\", keep=\"first\")\n",
    "\n",
    "conv_infos.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>conso_all_conv</th><th>len</th><th>mean_conso</th></tr><tr><td>str</td><td>f64</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;llama-3.1-405b&quot;</td><td>2332.336888</td><td>3409</td><td>0.68417</td></tr><tr><td>&quot;gemini-1.5-pro-002&quot;</td><td>1233.994754</td><td>3011</td><td>0.409829</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>1007.772718</td><td>3514</td><td>0.286788</td></tr><tr><td>&quot;hermes-3-llama-3.1-405b&quot;</td><td>949.987392</td><td>2349</td><td>0.404422</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>575.585088</td><td>3857</td><td>0.149231</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>9.735039</td><td>756</td><td>0.012877</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>7.210222</td><td>965</td><td>0.007472</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>7.148588</td><td>381</td><td>0.018763</td></tr><tr><td>&quot;gemma-2-27b-it-q8&quot;</td><td>7.010399</td><td>296</td><td>0.023684</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>4.10397</td><td>1098</td><td>0.003738</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 4)\n",
       "┌─────────────────────────────────┬────────────────┬──────┬────────────┐\n",
       "│ model_name                      ┆ conso_all_conv ┆ len  ┆ mean_conso │\n",
       "│ ---                             ┆ ---            ┆ ---  ┆ ---        │\n",
       "│ str                             ┆ f64            ┆ u32  ┆ f64        │\n",
       "╞═════════════════════════════════╪════════════════╪══════╪════════════╡\n",
       "│ llama-3.1-405b                  ┆ 2332.336888    ┆ 3409 ┆ 0.68417    │\n",
       "│ gemini-1.5-pro-002              ┆ 1233.994754    ┆ 3011 ┆ 0.409829   │\n",
       "│ claude-3-5-sonnet-v2            ┆ 1007.772718    ┆ 3514 ┆ 0.286788   │\n",
       "│ hermes-3-llama-3.1-405b         ┆ 949.987392     ┆ 2349 ┆ 0.404422   │\n",
       "│ deepseek-v3-chat                ┆ 575.585088     ┆ 3857 ┆ 0.149231   │\n",
       "│ …                               ┆ …              ┆ …    ┆ …          │\n",
       "│ qwen2.5-7b-instruct             ┆ 9.735039       ┆ 756  ┆ 0.012877   │\n",
       "│ aya-expanse-8b                  ┆ 7.210222       ┆ 965  ┆ 0.007472   │\n",
       "│ gemma-3-4b                      ┆ 7.148588       ┆ 381  ┆ 0.018763   │\n",
       "│ gemma-2-27b-it-q8               ┆ 7.010399       ┆ 296  ┆ 0.023684   │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 4.10397        ┆ 1098 ┆ 0.003738   │\n",
       "└─────────────────────────────────┴────────────────┴──────┴────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.frugality import calculate_frugality_score, draw_chart\n",
    "\n",
    "frugal_scores = calculate_frugality_score(conv_infos, number_by_model, mean=True)\n",
    "\n",
    "frugal_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>elo_score</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1187.256775</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1130.448296</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1109.508604</td></tr><tr><td>&quot;deepseek-r1&quot;</td><td>1094.825408</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1092.510064</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>898.263064</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>891.344808</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>871.436348</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>865.656169</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>847.828215</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40, 2)\n",
       "┌─────────────────────────────────┬─────────────┐\n",
       "│ model_name                      ┆ elo_score   │\n",
       "│ ---                             ┆ ---         │\n",
       "│ str                             ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 1187.256775 │\n",
       "│ gemma-3-27b                     ┆ 1130.448296 │\n",
       "│ deepseek-v3-chat                ┆ 1109.508604 │\n",
       "│ deepseek-r1                     ┆ 1094.825408 │\n",
       "│ gemini-2.0-flash-001            ┆ 1092.510064 │\n",
       "│ …                               ┆ …           │\n",
       "│ llama-3.1-8b                    ┆ 898.263064  │\n",
       "│ lfm-40b                         ┆ 891.344808  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 871.436348  │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 865.656169  │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 847.828215  │\n",
       "└─────────────────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_scores = pl.DataFrame(\n",
    "    {\n",
    "        \"model_name\": ranker_shuffle.players.keys(),\n",
    "        \"elo_score\": ranker_shuffle.players.values(),\n",
    "    },\n",
    "    strict=False,\n",
    ").sort(by=\"elo_score\", descending=True)\n",
    "\n",
    "elo_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (47, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>model_name</th><th>organization</th><th>license</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;GPT-4o&quot;</td><td>&quot;chatgpt-4o-2024-08-06&quot;</td><td>&quot;OpenAI&quot;</td><td>&quot;Proprietary&quot;</td></tr><tr><td>&quot;Yi-1.5 9B Chat&quot;</td><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>&quot;01 AI&quot;</td><td>&quot;Proprietary&quot;</td></tr><tr><td>&quot;Claude 3.5 Sonnet V2&quot;</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;Anthropic&quot;</td><td>&quot;Proprietary&quot;</td></tr><tr><td>&quot;GPT-4o mini&quot;</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;OpenAI&quot;</td><td>&quot;Proprietary&quot;</td></tr><tr><td>&quot;Gemini 2.0 Flash&quot;</td><td>&quot;gemini-2.0-flash-exp&quot;</td><td>&quot;Google&quot;</td><td>&quot;Proprietary&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Phi 4&quot;</td><td>&quot;phi-4&quot;</td><td>&quot;Microsoft&quot;</td><td>&quot;MIT&quot;</td></tr><tr><td>&quot;QwQ 32B&quot;</td><td>&quot;qwq-32b&quot;</td><td>&quot;Alibaba&quot;</td><td>&quot;Apache 2.0&quot;</td></tr><tr><td>&quot;Aya 8b&quot;</td><td>&quot;aya-23-8b&quot;</td><td>&quot;Cohere&quot;</td><td>&quot;CC-BY-NC-4.0&quot;</td></tr><tr><td>&quot;Llama 3 8B&quot;</td><td>&quot;Meta-Llama-3-8B-Instruct&quot;</td><td>&quot;Meta&quot;</td><td>&quot;llama3&quot;</td></tr><tr><td>&quot;Phi 3 Mini&quot;</td><td>&quot;phi-3-mini-4k&quot;</td><td>&quot;Microsoft&quot;</td><td>&quot;MIT&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (47, 4)\n",
       "┌──────────────────────┬──────────────────────────┬──────────────┬──────────────┐\n",
       "│ name                 ┆ model_name               ┆ organization ┆ license      │\n",
       "│ ---                  ┆ ---                      ┆ ---          ┆ ---          │\n",
       "│ str                  ┆ str                      ┆ str          ┆ str          │\n",
       "╞══════════════════════╪══════════════════════════╪══════════════╪══════════════╡\n",
       "│ GPT-4o               ┆ chatgpt-4o-2024-08-06    ┆ OpenAI       ┆ Proprietary  │\n",
       "│ Yi-1.5 9B Chat       ┆ Yi-1.5-9B-Chat           ┆ 01 AI        ┆ Proprietary  │\n",
       "│ Claude 3.5 Sonnet V2 ┆ claude-3-5-sonnet-v2     ┆ Anthropic    ┆ Proprietary  │\n",
       "│ GPT-4o mini          ┆ gpt-4o-mini-2024-07-18   ┆ OpenAI       ┆ Proprietary  │\n",
       "│ Gemini 2.0 Flash     ┆ gemini-2.0-flash-exp     ┆ Google       ┆ Proprietary  │\n",
       "│ …                    ┆ …                        ┆ …            ┆ …            │\n",
       "│ Phi 4                ┆ phi-4                    ┆ Microsoft    ┆ MIT          │\n",
       "│ QwQ 32B              ┆ qwq-32b                  ┆ Alibaba      ┆ Apache 2.0   │\n",
       "│ Aya 8b               ┆ aya-23-8b                ┆ Cohere       ┆ CC-BY-NC-4.0 │\n",
       "│ Llama 3 8B           ┆ Meta-Llama-3-8B-Instruct ┆ Meta         ┆ llama3       │\n",
       "│ Phi 3 Mini           ┆ phi-3-mini-4k            ┆ Microsoft    ┆ MIT          │\n",
       "└──────────────────────┴──────────────────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "info_model = pl.read_json(source=Path(\".\").resolve().parent / \"data\" / \"models_data.json\")\n",
    "\n",
    "info_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (39, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>model_name</th><th>organization</th><th>license</th><th>elo_score</th><th>conso_all_conv</th><th>len</th><th>mean_conso</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Llama 3.1 405B&quot;</td><td>&quot;llama-3.1-405b&quot;</td><td>&quot;Meta&quot;</td><td>&quot;Llama 3.1 Community&quot;</td><td>1077.517299</td><td>2332.336888</td><td>3409</td><td>0.68417</td></tr><tr><td>&quot;Gemini 1.5 pro 002&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;Google&quot;</td><td>&quot;Proprietary&quot;</td><td>1043.367789</td><td>1233.994754</td><td>3011</td><td>0.409829</td></tr><tr><td>&quot;Claude 3.5 Sonnet V2&quot;</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;Anthropic&quot;</td><td>&quot;Proprietary&quot;</td><td>1029.304045</td><td>1007.772718</td><td>3514</td><td>0.286788</td></tr><tr><td>&quot;Hermes 3&quot;</td><td>&quot;hermes-3-llama-3.1-405b&quot;</td><td>&quot;Nous Research&quot;</td><td>&quot;llama3&quot;</td><td>955.211798</td><td>949.987392</td><td>2349</td><td>0.404422</td></tr><tr><td>&quot;DeepSeek-V3 Chat&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;DeepSeek&quot;</td><td>&quot;DeepSeek&quot;</td><td>1109.508604</td><td>575.585088</td><td>3857</td><td>0.149231</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Qwen2.5-7B&quot;</td><td>&quot;qwen2.5-7b-instruct&quot;</td><td>&quot;Alibaba&quot;</td><td>&quot;Apache 2.0&quot;</td><td>956.398131</td><td>9.735039</td><td>756</td><td>0.012877</td></tr><tr><td>&quot;Aya-Expanse-8B&quot;</td><td>&quot;aya-expanse-8b&quot;</td><td>&quot;Cohere&quot;</td><td>&quot;CC-BY-NC-4.0&quot;</td><td>923.519774</td><td>7.210222</td><td>965</td><td>0.007472</td></tr><tr><td>&quot;Gemma 3 4B&quot;</td><td>&quot;gemma-3-4b&quot;</td><td>&quot;Google&quot;</td><td>&quot;Gemma license&quot;</td><td>1003.933485</td><td>7.148588</td><td>381</td><td>0.018763</td></tr><tr><td>&quot;Gemma 2 27B q8&quot;</td><td>&quot;gemma-2-27b-it-q8&quot;</td><td>&quot;Google&quot;</td><td>&quot;Gemma license&quot;</td><td>983.517901</td><td>7.010399</td><td>296</td><td>0.023684</td></tr><tr><td>&quot;Chocolatine-2-14b Instruct&quot;</td><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>&quot;jpacifico (individual)&quot;</td><td>&quot;Apache 2.0&quot;</td><td>871.436348</td><td>4.10397</td><td>1098</td><td>0.003738</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (39, 8)\n",
       "┌─────────────┬────────────┬────────────┬────────────┬────────────┬────────────┬──────┬────────────┐\n",
       "│ name        ┆ model_name ┆ organizati ┆ license    ┆ elo_score  ┆ conso_all_ ┆ len  ┆ mean_conso │\n",
       "│ ---         ┆ ---        ┆ on         ┆ ---        ┆ ---        ┆ conv       ┆ ---  ┆ ---        │\n",
       "│ str         ┆ str        ┆ ---        ┆ str        ┆ f64        ┆ ---        ┆ u32  ┆ f64        │\n",
       "│             ┆            ┆ str        ┆            ┆            ┆ f64        ┆      ┆            │\n",
       "╞═════════════╪════════════╪════════════╪════════════╪════════════╪════════════╪══════╪════════════╡\n",
       "│ Llama 3.1   ┆ llama-3.1- ┆ Meta       ┆ Llama 3.1  ┆ 1077.51729 ┆ 2332.33688 ┆ 3409 ┆ 0.68417    │\n",
       "│ 405B        ┆ 405b       ┆            ┆ Community  ┆ 9          ┆ 8          ┆      ┆            │\n",
       "│ Gemini 1.5  ┆ gemini-1.5 ┆ Google     ┆ Proprietar ┆ 1043.36778 ┆ 1233.99475 ┆ 3011 ┆ 0.409829   │\n",
       "│ pro 002     ┆ -pro-002   ┆            ┆ y          ┆ 9          ┆ 4          ┆      ┆            │\n",
       "│ Claude 3.5  ┆ claude-3-5 ┆ Anthropic  ┆ Proprietar ┆ 1029.30404 ┆ 1007.77271 ┆ 3514 ┆ 0.286788   │\n",
       "│ Sonnet V2   ┆ -sonnet-v2 ┆            ┆ y          ┆ 5          ┆ 8          ┆      ┆            │\n",
       "│ Hermes 3    ┆ hermes-3-l ┆ Nous       ┆ llama3     ┆ 955.211798 ┆ 949.987392 ┆ 2349 ┆ 0.404422   │\n",
       "│             ┆ lama-3.1-4 ┆ Research   ┆            ┆            ┆            ┆      ┆            │\n",
       "│             ┆ 05b        ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "│ DeepSeek-V3 ┆ deepseek-v ┆ DeepSeek   ┆ DeepSeek   ┆ 1109.50860 ┆ 575.585088 ┆ 3857 ┆ 0.149231   │\n",
       "│ Chat        ┆ 3-chat     ┆            ┆            ┆ 4          ┆            ┆      ┆            │\n",
       "│ …           ┆ …          ┆ …          ┆ …          ┆ …          ┆ …          ┆ …    ┆ …          │\n",
       "│ Qwen2.5-7B  ┆ qwen2.5-7b ┆ Alibaba    ┆ Apache 2.0 ┆ 956.398131 ┆ 9.735039   ┆ 756  ┆ 0.012877   │\n",
       "│             ┆ -instruct  ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "│ Aya-Expanse ┆ aya-expans ┆ Cohere     ┆ CC-BY-NC-4 ┆ 923.519774 ┆ 7.210222   ┆ 965  ┆ 0.007472   │\n",
       "│ -8B         ┆ e-8b       ┆            ┆ .0         ┆            ┆            ┆      ┆            │\n",
       "│ Gemma 3 4B  ┆ gemma-3-4b ┆ Google     ┆ Gemma      ┆ 1003.93348 ┆ 7.148588   ┆ 381  ┆ 0.018763   │\n",
       "│             ┆            ┆            ┆ license    ┆ 5          ┆            ┆      ┆            │\n",
       "│ Gemma 2 27B ┆ gemma-2-27 ┆ Google     ┆ Gemma      ┆ 983.517901 ┆ 7.010399   ┆ 296  ┆ 0.023684   │\n",
       "│ q8          ┆ b-it-q8    ┆            ┆ license    ┆            ┆            ┆      ┆            │\n",
       "│ Chocolatine ┆ chocolatin ┆ jpacifico  ┆ Apache 2.0 ┆ 871.436348 ┆ 4.10397    ┆ 1098 ┆ 0.003738   │\n",
       "│ -2-14b      ┆ e-2-14b-in ┆ (individua ┆            ┆            ┆            ┆      ┆            │\n",
       "│ Instruct    ┆ struct-v2. ┆ l)         ┆            ┆            ┆            ┆      ┆            │\n",
       "│             ┆ …          ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "└─────────────┴────────────┴────────────┴────────────┴────────────┴────────────┴──────┴────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = info_model.join(elo_scores, on=\"model_name\").join(frugal_scores, on=\"model_name\")\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-6e45ecaa5d6a4bda8e7f3c45423a64d2.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-6e45ecaa5d6a4bda8e7f3c45423a64d2.vega-embed details,\n",
       "  #altair-viz-6e45ecaa5d6a4bda8e7f3c45423a64d2.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-6e45ecaa5d6a4bda8e7f3c45423a64d2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6e45ecaa5d6a4bda8e7f3c45423a64d2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6e45ecaa5d6a4bda8e7f3c45423a64d2\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-277d47cc3fe3945b8fd7b8a4141797ba\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"field\": \"organization\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"model_name\", \"type\": \"nominal\"}, {\"field\": \"organization\", \"type\": \"nominal\"}, {\"field\": \"license\", \"type\": \"nominal\"}, {\"field\": \"elo_score\", \"type\": \"quantitative\"}, {\"field\": \"conso_all_conv\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"conso_all_conv\", \"scale\": {\"type\": \"log\"}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"elo_score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-277d47cc3fe3945b8fd7b8a4141797ba\": [{\"name\": \"Llama 3.1 405B\", \"model_name\": \"llama-3.1-405b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 1077.5172994913676, \"conso_all_conv\": 2332.336887798672, \"len\": 3409, \"mean_conso\": 0.6841703982982317}, {\"name\": \"Gemini 1.5 pro 002\", \"model_name\": \"gemini-1.5-pro-002\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1043.367789364427, \"conso_all_conv\": 1233.9947540885344, \"len\": 3011, \"mean_conso\": 0.4098288788072183}, {\"name\": \"Claude 3.5 Sonnet V2\", \"model_name\": \"claude-3-5-sonnet-v2\", \"organization\": \"Anthropic\", \"license\": \"Proprietary\", \"elo_score\": 1029.3040448608099, \"conso_all_conv\": 1007.772718205001, \"len\": 3514, \"mean_conso\": 0.2867879107014801}, {\"name\": \"Hermes 3\", \"model_name\": \"hermes-3-llama-3.1-405b\", \"organization\": \"Nous Research\", \"license\": \"llama3\", \"elo_score\": 955.2117981982482, \"conso_all_conv\": 949.9873921696019, \"len\": 2349, \"mean_conso\": 0.4044220486034916}, {\"name\": \"DeepSeek-V3 Chat\", \"model_name\": \"deepseek-v3-chat\", \"organization\": \"DeepSeek\", \"license\": \"DeepSeek\", \"elo_score\": 1109.5086040897133, \"conso_all_conv\": 575.5850881431195, \"len\": 3857, \"mean_conso\": 0.14923129067750052}, {\"name\": \"Gemini 1.5 pro 001\", \"model_name\": \"gemini-1.5-pro-001\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1037.701988282026, \"conso_all_conv\": 490.502762444801, \"len\": 692, \"mean_conso\": 0.70881902087399}, {\"name\": \"o3-mini\", \"model_name\": \"o3-mini\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\", \"elo_score\": 990.2755142940731, \"conso_all_conv\": 211.844567025, \"len\": 710, \"mean_conso\": 0.2983726296126761}, {\"name\": \"DeepSeek-R1\", \"model_name\": \"deepseek-r1\", \"organization\": \"DeepSeek\", \"license\": \"MIT\", \"elo_score\": 1094.8254083367322, \"conso_all_conv\": 183.99728371782007, \"len\": 640, \"mean_conso\": 0.28749575580909387}, {\"name\": \"Mistral-Large-2411\", \"model_name\": \"mistral-large-2411\", \"organization\": \"Mistral\", \"license\": \"Mistral Research\", \"elo_score\": 1075.6668303885447, \"conso_all_conv\": 159.59206027865375, \"len\": 2830, \"mean_conso\": 0.056392954162068465}, {\"name\": \"Mixtral 8x22B Instruct\", \"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 847.8282151825236, \"conso_all_conv\": 105.6405872116398, \"len\": 3160, \"mean_conso\": 0.03343056557330373}, {\"name\": \"Llama-3.1-70B\", \"model_name\": \"llama-3.1-70b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 960.1273690218792, \"conso_all_conv\": 104.0292481652669, \"len\": 2779, \"mean_conso\": 0.0374340583538204}, {\"name\": \"GPT-4o mini\", \"model_name\": \"gpt-4o-mini-2024-07-18\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\", \"elo_score\": 1016.0233377113445, \"conso_all_conv\": 95.05007776020014, \"len\": 3816, \"mean_conso\": 0.024908301299842804}, {\"name\": \"Nemotron 70B Instruct\", \"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"organization\": \"Nvidia\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 1052.522522165146, \"conso_all_conv\": 79.76753697033308, \"len\": 1961, \"mean_conso\": 0.040676969388237165}, {\"name\": \"Gemini 2.0 Flash\", \"model_name\": \"gemini-2.0-flash-exp\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1187.2567752933778, \"conso_all_conv\": 60.61934318539992, \"len\": 1740, \"mean_conso\": 0.0348387029801149}, {\"name\": \"Llama 3.3 70B\", \"model_name\": \"llama-3.3-70b\", \"organization\": \"Meta\", \"license\": \"Llama 3.3 Community\", \"elo_score\": 1029.5276520990058, \"conso_all_conv\": 57.10678619793322, \"len\": 1758, \"mean_conso\": 0.03248395119336361}, {\"name\": \"Gemini 2.0 Flash\", \"model_name\": \"gemini-2.0-flash-001\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1092.5100639601135, \"conso_all_conv\": 53.76336439603338, \"len\": 905, \"mean_conso\": 0.059407032481804845}, {\"name\": \"Qwen2.5-Coder-32B-Instruct\", \"model_name\": \"qwen2.5-coder-32b-instruct\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 947.8363316276404, \"conso_all_conv\": 49.83678413322001, \"len\": 2880, \"mean_conso\": 0.017304438935145834}, {\"name\": \"Command A\", \"model_name\": \"command-a\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 1078.3891750326056, \"conso_all_conv\": 36.36172345061998, \"len\": 418, \"mean_conso\": 0.08698976902062196}, {\"name\": \"Liquid Foundation Model\", \"model_name\": \"lfm-40b\", \"organization\": \"Liquid\", \"license\": \"Unknown\", \"elo_score\": 891.3448080697107, \"conso_all_conv\": 33.28408445676661, \"len\": 2097, \"mean_conso\": 0.015872238653679833}, {\"name\": \"Mistral-Small-24B-Instruct-2501\", \"model_name\": \"mistral-small-24b-instruct-2501\", \"organization\": \"Mistral\", \"license\": \"Apache 2.0\", \"elo_score\": 983.3483431488236, \"conso_all_conv\": 31.614103157799917, \"len\": 2008, \"mean_conso\": 0.015744075277788802}, {\"name\": \"Ministral 8B-Instruct\", \"model_name\": \"ministral-8b-instruct-2410\", \"organization\": \"Mistral\", \"license\": \"MRL\", \"elo_score\": 995.3251445393876, \"conso_all_conv\": 31.530937016839847, \"len\": 2965, \"mean_conso\": 0.010634380106859982}, {\"name\": \"DeepSeek-R1 distiil\", \"model_name\": \"deepseek-r1-distill-llama-70b\", \"organization\": \"DeepSeek\", \"license\": \"MIT\", \"elo_score\": 967.4748205643748, \"conso_all_conv\": 30.17901044166662, \"len\": 593, \"mean_conso\": 0.05089209180719497}, {\"name\": \"Command R (08-2024)\", \"model_name\": \"c4ai-command-r-08-2024\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 973.1914198512476, \"conso_all_conv\": 29.072108079550038, \"len\": 2171, \"mean_conso\": 0.013391113809097207}, {\"name\": \"Mistral Nemo Instruct\", \"model_name\": \"mistral-nemo-2407\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 926.8840403344866, \"conso_all_conv\": 28.592232442380116, \"len\": 3186, \"mean_conso\": 0.008974335355423765}, {\"name\": \"Phi 4\", \"model_name\": \"phi-4\", \"organization\": \"Microsoft\", \"license\": \"MIT\", \"elo_score\": 1052.1330917389332, \"conso_all_conv\": 27.256583932600048, \"len\": 2439, \"mean_conso\": 0.011175311165477675}, {\"name\": \"Llama 3.1 8B\", \"model_name\": \"llama-3.1-8b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 898.2630635744302, \"conso_all_conv\": 27.034222178439844, \"len\": 2811, \"mean_conso\": 0.009617297110793257}, {\"name\": \"Gemma 2 9B\", \"model_name\": \"gemma-2-9b-it\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 988.0128484491373, \"conso_all_conv\": 24.166357537513257, \"len\": 2640, \"mean_conso\": 0.009153923309664112}, {\"name\": \"QwQ 32B\", \"model_name\": \"qwq-32b\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 935.6736892482986, \"conso_all_conv\": 21.335704190359987, \"len\": 509, \"mean_conso\": 0.04191690410679762}, {\"name\": \"Gemma-3 27B\", \"model_name\": \"gemma-3-27b\", \"organization\": \"Google\", \"license\": \"Gemma\", \"elo_score\": 1130.4482957390255, \"conso_all_conv\": 20.66145980901671, \"len\": 557, \"mean_conso\": 0.03709418278099948}, {\"name\": \"Mixtral 8x7B Instruct\", \"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 865.6561686894954, \"conso_all_conv\": 15.570395226319992, \"len\": 1151, \"mean_conso\": 0.013527710882988698}, {\"name\": \"Phi-3.5 Mini Instruct\", \"model_name\": \"phi-3.5-mini-instruct\", \"organization\": \"Microsoft\", \"license\": \"MIT\", \"elo_score\": 903.6460802785439, \"conso_all_conv\": 14.438303974783338, \"len\": 786, \"mean_conso\": 0.018369343479368114}, {\"name\": \"Jamba Large\", \"model_name\": \"jamba-1.5-large\", \"organization\": \"AI21 Labs\", \"license\": \"Jamba Open Model License\", \"elo_score\": 984.0416915670814, \"conso_all_conv\": 13.243440129120001, \"len\": 237, \"mean_conso\": 0.055879494215696206}, {\"name\": \"Gemma 3 12B\", \"model_name\": \"gemma-3-12b\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 1084.9237133106296, \"conso_all_conv\": 10.33663462687333, \"len\": 408, \"mean_conso\": 0.025334888791356203}, {\"name\": \"Mistral Small-3.1 24B\", \"model_name\": \"mistral-small-3.1-24b\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 1014.6516071792289, \"conso_all_conv\": 10.212038244393328, \"len\": 383, \"mean_conso\": 0.026663285233402945}, {\"name\": \"Qwen2.5-7B\", \"model_name\": \"qwen2.5-7b-instruct\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 956.3981314573372, \"conso_all_conv\": 9.735039268733312, \"len\": 756, \"mean_conso\": 0.012877036069753057}, {\"name\": \"Aya-Expanse-8B\", \"model_name\": \"aya-expanse-8b\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 923.51977364979, \"conso_all_conv\": 7.210222110320017, \"len\": 965, \"mean_conso\": 0.007471732756808308}, {\"name\": \"Gemma 3 4B\", \"model_name\": \"gemma-3-4b\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 1003.9334853904393, \"conso_all_conv\": 7.148587999279991, \"len\": 381, \"mean_conso\": 0.01876269816083987}, {\"name\": \"Gemma 2 27B q8\", \"model_name\": \"gemma-2-27b-it-q8\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 983.5179013775755, \"conso_all_conv\": 7.010399311370009, \"len\": 296, \"mean_conso\": 0.02368378145733111}, {\"name\": \"Chocolatine-2-14b Instruct\", \"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"organization\": \"jpacifico (individual)\", \"license\": \"Apache 2.0\", \"elo_score\": 871.4363478217277, \"conso_all_conv\": 4.103969502980007, \"len\": 1098, \"mean_conso\": 0.003737677142969041}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_chart(final_df, title=\"\", log=True, mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.utils import save_data, save_chart\n",
    "\n",
    "save_data(data=final_df, title=\"frugality\", savepath=\"../data\")\n",
    "\n",
    "save_chart(final_df, \"frugality representation\", log=True, savepath=\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
