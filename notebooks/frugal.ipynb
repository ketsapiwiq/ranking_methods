{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_TOKEN\"] = getpass(\"Enter your HuggingFace token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/92a324c10228176065909b52bbbaa16430e64c5a (last modified on Wed Jun  4 17:40:33 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.utils import load_comparia\n",
    "\n",
    "reactions = load_comparia(\"ministere-culture/comparia-reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule des scores comme dans le notebook `rankers.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score\n",
    "\n",
    "matches = get_matches_with_score(reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;c4ai-command-r-08-2024&quot;</td><td>&quot;ec6b9b5e01394dc4ad13e57129822c…</td><td>1</td><td>-1</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>&quot;mistral-small-3.1-24b&quot;</td><td>&quot;57ec39be908f4cd2ac3fa2dcb11d60…</td><td>0</td><td>2</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>&quot;gpt-4.1-mini&quot;</td><td>&quot;4bb4df04099c4d6588c311d316e8a3…</td><td>0</td><td>0</td></tr><tr><td>&quot;gemma-2-9b-it&quot;</td><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>&quot;133af454c27b4b5997a4f0dc3bec5d…</td><td>-2</td><td>-2</td></tr><tr><td>&quot;gemma-2-9b-it&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;aa2c4ba80b1747a79c79403265702c…</td><td>-2</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────┬───────────────────────────┬───────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name         ┆ model_b_name              ┆ conversation_pair_id      ┆ score_a ┆ score_b │\n",
       "│ ---                  ┆ ---                       ┆ ---                       ┆ ---     ┆ ---     │\n",
       "│ str                  ┆ str                       ┆ str                       ┆ i64     ┆ i64     │\n",
       "╞══════════════════════╪═══════════════════════════╪═══════════════════════════╪═════════╪═════════╡\n",
       "│ deepseek-v3-chat     ┆ c4ai-command-r-08-2024    ┆ ec6b9b5e01394dc4ad13e5712 ┆ 1       ┆ -1      │\n",
       "│                      ┆                           ┆ 9822c…                    ┆         ┆         │\n",
       "│ gemma-3-4b           ┆ mistral-small-3.1-24b     ┆ 57ec39be908f4cd2ac3fa2dcb ┆ 0       ┆ 2       │\n",
       "│                      ┆                           ┆ 11d60…                    ┆         ┆         │\n",
       "│ gemini-2.0-flash-001 ┆ gpt-4.1-mini              ┆ 4bb4df04099c4d6588c311d31 ┆ 0       ┆ 0       │\n",
       "│                      ┆                           ┆ 6e8a3…                    ┆         ┆         │\n",
       "│ gemma-2-9b-it        ┆ mixtral-8x22b-instruct-v0 ┆ 133af454c27b4b5997a4f0dc3 ┆ -2      ┆ -2      │\n",
       "│                      ┆ .1                        ┆ bec5d…                    ┆         ┆         │\n",
       "│ gemma-2-9b-it        ┆ gemini-1.5-pro-002        ┆ aa2c4ba80b1747a79c7940326 ┆ -2      ┆ 0       │\n",
       "│                      ┆                           ┆ 5702c…                    ┆         ┆         │\n",
       "└──────────────────────┴───────────────────────────┴───────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepseek-v3-chat': 1179.3292449408536,\n",
       " 'gemini-2.0-flash-exp': 1173.7789956398838,\n",
       " 'claude-3-7-sonnet': 1156.210708428794,\n",
       " 'gemini-2.0-flash-001': 1155.8158398416097,\n",
       " 'deepseek-r1': 1148.460911319317,\n",
       " 'gemma-3-27b': 1146.8920521943444,\n",
       " 'gpt-4.1-mini': 1141.5298136214453,\n",
       " 'command-a': 1112.2218084578326,\n",
       " 'mistral-small-3.1-24b': 1095.9679168980472,\n",
       " 'grok-3-mini-beta': 1086.7839826870804,\n",
       " 'deepseek-v3-0324': 1082.5799753295535,\n",
       " 'gemini-1.5-pro-001': 1068.6248683256833,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1066.0280109726627,\n",
       " 'gemma-2-9b-it': 1059.7734269172583,\n",
       " 'gemma-3-4b': 1059.6343222468988,\n",
       " 'llama-3.1-70b': 1059.6289588284665,\n",
       " 'llama-4-scout': 1056.3085689852485,\n",
       " 'jamba-1.5-large': 1038.961527895229,\n",
       " 'gemini-1.5-pro-002': 1035.6855914797313,\n",
       " 'mistral-large-2411': 1029.635311335044,\n",
       " 'gemma-3-12b': 1025.0725706277951,\n",
       " 'gpt-4.1-nano': 1012.7110939136552,\n",
       " 'claude-3-5-sonnet-v2': 1010.6840482473359,\n",
       " 'mistral-small-24b-instruct-2501': 996.3182269199416,\n",
       " 'gpt-4o-mini-2024-07-18': 996.1948497640711,\n",
       " 'gpt-4o-2024-08-06': 993.5220259480881,\n",
       " 'llama-3.3-70b': 992.7344904917275,\n",
       " 'deepseek-r1-distill-llama-70b': 961.7508397949451,\n",
       " 'llama-3.1-405b': 949.8798271667176,\n",
       " 'o3-mini': 943.5300370774175,\n",
       " 'phi-4': 942.4092687141602,\n",
       " 'aya-expanse-8b': 938.0458384329559,\n",
       " 'ministral-8b-instruct-2410': 935.2129266248544,\n",
       " 'mistral-saba': 934.1128695820956,\n",
       " 'o4-mini': 922.4666073783047,\n",
       " 'qwq-32b': 919.3761912785656,\n",
       " 'gemma-2-27b-it-q8': 914.5922544085564,\n",
       " 'qwen2.5-coder-32b-instruct': 914.3395825491064,\n",
       " 'c4ai-command-r-08-2024': 914.1668895670687,\n",
       " 'mixtral-8x22b-instruct-v0.1': 910.1680878139728,\n",
       " 'hermes-3-llama-3.1-405b': 905.5314765487819,\n",
       " 'phi-3.5-mini-instruct': 896.6672871049191,\n",
       " 'llama-3.1-8b': 876.912266904613,\n",
       " 'lfm-40b': 874.9948155889265,\n",
       " 'mixtral-8x7b-instruct-v0.1': 859.5985903818026,\n",
       " 'mistral-nemo-2407': 842.1128787758441,\n",
       " 'qwen2.5-7b-instruct': 840.7981552658027,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 822.2441667830092}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = ELORanker(K=40)\n",
    "\n",
    "random.seed(1337)\n",
    "matches = random.sample(matches, k=len(matches))\n",
    "ranker.add_players(model_names)  # type: ignore\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul d'un score de frugalité\n",
    "\n",
    "Le score de frugalité est calculé à partir de données de consommation présentes dans le jeu de données `comparia-conversations`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of matches per model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "number_by_model = pl.DataFrame(\n",
    "    zip(ranker.played_matches.keys(), ranker.played_matches.values()), schema=[\"model_name\", \"len\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>conso_all_conv</th><th>len</th><th>mean_conso</th></tr><tr><td>str</td><td>f64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;mistral-large-2411&quot;</td><td>180.436097</td><td>1849</td><td>0.097586</td></tr><tr><td>&quot;gemini-1.5-pro-002&quot;</td><td>440.318973</td><td>1672</td><td>0.263349</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>34.16509</td><td>1641</td><td>0.02082</td></tr><tr><td>&quot;gemma-2-9b-it&quot;</td><td>7.879733</td><td>1520</td><td>0.005184</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>445.613091</td><td>1866</td><td>0.238807</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;o3-mini&quot;</td><td>57.033604</td><td>437</td><td>0.130512</td></tr><tr><td>&quot;jamba-1.5-large&quot;</td><td>27.637821</td><td>77</td><td>0.358933</td></tr><tr><td>&quot;gemma-3-4b&quot;</td><td>3.680529</td><td>459</td><td>0.008019</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>50.856222</td><td>296</td><td>0.171812</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>2.609332</td><td>462</td><td>0.005648</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌────────────────────────────┬────────────────┬──────┬────────────┐\n",
       "│ model_name                 ┆ conso_all_conv ┆ len  ┆ mean_conso │\n",
       "│ ---                        ┆ ---            ┆ ---  ┆ ---        │\n",
       "│ str                        ┆ f64            ┆ i64  ┆ f64        │\n",
       "╞════════════════════════════╪════════════════╪══════╪════════════╡\n",
       "│ mistral-large-2411         ┆ 180.436097     ┆ 1849 ┆ 0.097586   │\n",
       "│ gemini-1.5-pro-002         ┆ 440.318973     ┆ 1672 ┆ 0.263349   │\n",
       "│ qwen2.5-coder-32b-instruct ┆ 34.16509       ┆ 1641 ┆ 0.02082    │\n",
       "│ gemma-2-9b-it              ┆ 7.879733       ┆ 1520 ┆ 0.005184   │\n",
       "│ deepseek-v3-chat           ┆ 445.613091     ┆ 1866 ┆ 0.238807   │\n",
       "│ …                          ┆ …              ┆ …    ┆ …          │\n",
       "│ o3-mini                    ┆ 57.033604      ┆ 437  ┆ 0.130512   │\n",
       "│ jamba-1.5-large            ┆ 27.637821      ┆ 77   ┆ 0.358933   │\n",
       "│ gemma-3-4b                 ┆ 3.680529       ┆ 459  ┆ 0.008019   │\n",
       "│ deepseek-v3-0324           ┆ 50.856222      ┆ 296  ┆ 0.171812   │\n",
       "│ phi-3.5-mini-instruct      ┆ 2.609332       ┆ 462  ┆ 0.005648   │\n",
       "└────────────────────────────┴────────────────┴──────┴────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.frugality import calculate_frugality_score, draw_chart\n",
    "\n",
    "frugal_scores = calculate_frugality_score(reactions, number_by_model, mean=True)\n",
    "\n",
    "frugal_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>elo_score</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1179.329245</td></tr><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1173.778996</td></tr><tr><td>&quot;claude-3-7-sonnet&quot;</td><td>1156.210708</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1155.81584</td></tr><tr><td>&quot;deepseek-r1&quot;</td><td>1148.460911</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>874.994816</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>859.59859</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>842.112879</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>840.798155</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>822.244167</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 2)\n",
       "┌─────────────────────────────────┬─────────────┐\n",
       "│ model_name                      ┆ elo_score   │\n",
       "│ ---                             ┆ ---         │\n",
       "│ str                             ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╡\n",
       "│ deepseek-v3-chat                ┆ 1179.329245 │\n",
       "│ gemini-2.0-flash-exp            ┆ 1173.778996 │\n",
       "│ claude-3-7-sonnet               ┆ 1156.210708 │\n",
       "│ gemini-2.0-flash-001            ┆ 1155.81584  │\n",
       "│ deepseek-r1                     ┆ 1148.460911 │\n",
       "│ …                               ┆ …           │\n",
       "│ lfm-40b                         ┆ 874.994816  │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 859.59859   │\n",
       "│ mistral-nemo-2407               ┆ 842.112879  │\n",
       "│ qwen2.5-7b-instruct             ┆ 840.798155  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 822.244167  │\n",
       "└─────────────────────────────────┴─────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_scores = pl.DataFrame(\n",
    "    {\n",
    "        \"model_name\": ranker.players.keys(),\n",
    "        \"elo_score\": ranker.players.values(),\n",
    "    },\n",
    "    strict=False,\n",
    ").sort(by=\"elo_score\", descending=True)\n",
    "\n",
    "elo_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "info_model = pl.read_json(source=Path(\".\").resolve().parent / \"data\" / \"models_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (39, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>model_name</th><th>organization</th><th>license</th><th>elo_score</th><th>conso_all_conv</th><th>len</th><th>mean_conso</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Mistral-Large-2411&quot;</td><td>&quot;mistral-large-2411&quot;</td><td>&quot;Mistral&quot;</td><td>&quot;Mistral Research&quot;</td><td>1029.635311</td><td>180.436097</td><td>1849</td><td>0.097586</td></tr><tr><td>&quot;Gemini 1.5 pro 002&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;Google&quot;</td><td>&quot;Proprietary&quot;</td><td>1035.685591</td><td>440.318973</td><td>1672</td><td>0.263349</td></tr><tr><td>&quot;Qwen2.5-Coder-32B-Instruct&quot;</td><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>&quot;Alibaba&quot;</td><td>&quot;Apache 2.0&quot;</td><td>914.339583</td><td>34.16509</td><td>1641</td><td>0.02082</td></tr><tr><td>&quot;Gemma 2 9B&quot;</td><td>&quot;gemma-2-9b-it&quot;</td><td>&quot;Google&quot;</td><td>&quot;Gemma license&quot;</td><td>1059.773427</td><td>7.879733</td><td>1520</td><td>0.005184</td></tr><tr><td>&quot;DeepSeek-V3 Chat&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;DeepSeek&quot;</td><td>&quot;DeepSeek&quot;</td><td>1179.329245</td><td>445.613091</td><td>1866</td><td>0.238807</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Mixtral 8x22B Instruct&quot;</td><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>&quot;Mistral AI&quot;</td><td>&quot;Apache 2.0&quot;</td><td>910.168088</td><td>50.965108</td><td>1756</td><td>0.029023</td></tr><tr><td>&quot;o3-mini&quot;</td><td>&quot;o3-mini&quot;</td><td>&quot;OpenAI&quot;</td><td>&quot;Proprietary&quot;</td><td>943.530037</td><td>57.033604</td><td>437</td><td>0.130512</td></tr><tr><td>&quot;Jamba Large&quot;</td><td>&quot;jamba-1.5-large&quot;</td><td>&quot;AI21 Labs&quot;</td><td>&quot;Jamba Open Model License&quot;</td><td>1038.961528</td><td>27.637821</td><td>77</td><td>0.358933</td></tr><tr><td>&quot;Gemma 3 4B&quot;</td><td>&quot;gemma-3-4b&quot;</td><td>&quot;Google&quot;</td><td>&quot;Gemma license&quot;</td><td>1059.634322</td><td>3.680529</td><td>459</td><td>0.008019</td></tr><tr><td>&quot;Phi-3.5 Mini Instruct&quot;</td><td>&quot;phi-3.5-mini-instruct&quot;</td><td>&quot;Microsoft&quot;</td><td>&quot;MIT&quot;</td><td>896.667287</td><td>2.609332</td><td>462</td><td>0.005648</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (39, 8)\n",
       "┌─────────────┬────────────┬────────────┬────────────┬────────────┬────────────┬──────┬────────────┐\n",
       "│ name        ┆ model_name ┆ organizati ┆ license    ┆ elo_score  ┆ conso_all_ ┆ len  ┆ mean_conso │\n",
       "│ ---         ┆ ---        ┆ on         ┆ ---        ┆ ---        ┆ conv       ┆ ---  ┆ ---        │\n",
       "│ str         ┆ str        ┆ ---        ┆ str        ┆ f64        ┆ ---        ┆ i64  ┆ f64        │\n",
       "│             ┆            ┆ str        ┆            ┆            ┆ f64        ┆      ┆            │\n",
       "╞═════════════╪════════════╪════════════╪════════════╪════════════╪════════════╪══════╪════════════╡\n",
       "│ Mistral-Lar ┆ mistral-la ┆ Mistral    ┆ Mistral    ┆ 1029.63531 ┆ 180.436097 ┆ 1849 ┆ 0.097586   │\n",
       "│ ge-2411     ┆ rge-2411   ┆            ┆ Research   ┆ 1          ┆            ┆      ┆            │\n",
       "│ Gemini 1.5  ┆ gemini-1.5 ┆ Google     ┆ Proprietar ┆ 1035.68559 ┆ 440.318973 ┆ 1672 ┆ 0.263349   │\n",
       "│ pro 002     ┆ -pro-002   ┆            ┆ y          ┆ 1          ┆            ┆      ┆            │\n",
       "│ Qwen2.5-Cod ┆ qwen2.5-co ┆ Alibaba    ┆ Apache 2.0 ┆ 914.339583 ┆ 34.16509   ┆ 1641 ┆ 0.02082    │\n",
       "│ er-32B-Inst ┆ der-32b-in ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "│ ruct        ┆ struct     ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "│ Gemma 2 9B  ┆ gemma-2-9b ┆ Google     ┆ Gemma      ┆ 1059.77342 ┆ 7.879733   ┆ 1520 ┆ 0.005184   │\n",
       "│             ┆ -it        ┆            ┆ license    ┆ 7          ┆            ┆      ┆            │\n",
       "│ DeepSeek-V3 ┆ deepseek-v ┆ DeepSeek   ┆ DeepSeek   ┆ 1179.32924 ┆ 445.613091 ┆ 1866 ┆ 0.238807   │\n",
       "│ Chat        ┆ 3-chat     ┆            ┆            ┆ 5          ┆            ┆      ┆            │\n",
       "│ …           ┆ …          ┆ …          ┆ …          ┆ …          ┆ …          ┆ …    ┆ …          │\n",
       "│ Mixtral     ┆ mixtral-8x ┆ Mistral AI ┆ Apache 2.0 ┆ 910.168088 ┆ 50.965108  ┆ 1756 ┆ 0.029023   │\n",
       "│ 8x22B       ┆ 22b-instru ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "│ Instruct    ┆ ct-v0.1    ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "│ o3-mini     ┆ o3-mini    ┆ OpenAI     ┆ Proprietar ┆ 943.530037 ┆ 57.033604  ┆ 437  ┆ 0.130512   │\n",
       "│             ┆            ┆            ┆ y          ┆            ┆            ┆      ┆            │\n",
       "│ Jamba Large ┆ jamba-1.5- ┆ AI21 Labs  ┆ Jamba Open ┆ 1038.96152 ┆ 27.637821  ┆ 77   ┆ 0.358933   │\n",
       "│             ┆ large      ┆            ┆ Model      ┆ 8          ┆            ┆      ┆            │\n",
       "│             ┆            ┆            ┆ License    ┆            ┆            ┆      ┆            │\n",
       "│ Gemma 3 4B  ┆ gemma-3-4b ┆ Google     ┆ Gemma      ┆ 1059.63432 ┆ 3.680529   ┆ 459  ┆ 0.008019   │\n",
       "│             ┆            ┆            ┆ license    ┆ 2          ┆            ┆      ┆            │\n",
       "│ Phi-3.5     ┆ phi-3.5-mi ┆ Microsoft  ┆ MIT        ┆ 896.667287 ┆ 2.609332   ┆ 462  ┆ 0.005648   │\n",
       "│ Mini        ┆ ni-instruc ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "│ Instruct    ┆ t          ┆            ┆            ┆            ┆            ┆      ┆            │\n",
       "└─────────────┴────────────┴────────────┴────────────┴────────────┴────────────┴──────┴────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = info_model.join(elo_scores, on=\"model_name\").join(frugal_scores, on=\"model_name\")\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1be00453be0243b1bd2ead147d3191a3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1be00453be0243b1bd2ead147d3191a3.vega-embed details,\n",
       "  #altair-viz-1be00453be0243b1bd2ead147d3191a3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1be00453be0243b1bd2ead147d3191a3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1be00453be0243b1bd2ead147d3191a3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1be00453be0243b1bd2ead147d3191a3\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-cbf6fd5c50654da070e425fda65838fe\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"field\": \"organization\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"model_name\", \"type\": \"nominal\"}, {\"field\": \"organization\", \"type\": \"nominal\"}, {\"field\": \"license\", \"type\": \"nominal\"}, {\"field\": \"elo_score\", \"type\": \"quantitative\"}, {\"field\": \"conso_all_conv\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"conso_all_conv\", \"scale\": {\"type\": \"linear\"}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"elo_score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-cbf6fd5c50654da070e425fda65838fe\": [{\"name\": \"Mistral-Large-2411\", \"model_name\": \"mistral-large-2411\", \"organization\": \"Mistral\", \"license\": \"Mistral Research\", \"elo_score\": 1029.635311335044, \"conso_all_conv\": 180.43609736028264, \"len\": 1849, \"mean_conso\": 0.09758577466754063}, {\"name\": \"Gemini 1.5 pro 002\", \"model_name\": \"gemini-1.5-pro-002\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1035.6855914797313, \"conso_all_conv\": 440.3189729905331, \"len\": 1672, \"mean_conso\": 0.26334866805653895}, {\"name\": \"Qwen2.5-Coder-32B-Instruct\", \"model_name\": \"qwen2.5-coder-32b-instruct\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 914.3395825491064, \"conso_all_conv\": 34.16508959906006, \"len\": 1641, \"mean_conso\": 0.02081967678187694}, {\"name\": \"Gemma 2 9B\", \"model_name\": \"gemma-2-9b-it\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 1059.7734269172583, \"conso_all_conv\": 7.879733476710017, \"len\": 1520, \"mean_conso\": 0.005184035182046064}, {\"name\": \"DeepSeek-V3 Chat\", \"model_name\": \"deepseek-v3-chat\", \"organization\": \"DeepSeek\", \"license\": \"DeepSeek\", \"elo_score\": 1179.3292449408536, \"conso_all_conv\": 445.6130906956012, \"len\": 1866, \"mean_conso\": 0.23880658665359122}, {\"name\": \"Mixtral 8x7B Instruct\", \"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 859.5985903818026, \"conso_all_conv\": 4.14920547184, \"len\": 675, \"mean_conso\": 0.006146971069392593}, {\"name\": \"Llama 3.3 70B\", \"model_name\": \"llama-3.3-70b\", \"organization\": \"Meta\", \"license\": \"Llama 3.3 Community\", \"elo_score\": 992.7344904917275, \"conso_all_conv\": 72.24350427753315, \"len\": 1207, \"mean_conso\": 0.059853773220822824}, {\"name\": \"DeepSeek-R1\", \"model_name\": \"deepseek-r1\", \"organization\": \"DeepSeek\", \"license\": \"MIT\", \"elo_score\": 1148.460911319317, \"conso_all_conv\": 54.55267994439995, \"len\": 486, \"mean_conso\": 0.11224831264279825}, {\"name\": \"Mistral Nemo Instruct\", \"model_name\": \"mistral-nemo-2407\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 842.1128787758441, \"conso_all_conv\": 9.09769793379999, \"len\": 1786, \"mean_conso\": 0.005093895819596859}, {\"name\": \"Gemma-3 27B\", \"model_name\": \"gemma-3-27b\", \"organization\": \"Google\", \"license\": \"Gemma\", \"elo_score\": 1146.8920521943444, \"conso_all_conv\": 9.046397582660008, \"len\": 579, \"mean_conso\": 0.01562417544500865}, {\"name\": \"Nemotron 70B Instruct\", \"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"organization\": \"Nvidia\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 1066.0280109726627, \"conso_all_conv\": 49.341271546666775, \"len\": 1269, \"mean_conso\": 0.03888201067507232}, {\"name\": \"Gemma 2 27B q8\", \"model_name\": \"gemma-2-27b-it-q8\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 914.5922544085564, \"conso_all_conv\": 1.5577335389999991, \"len\": 170, \"mean_conso\": 0.009163138464705877}, {\"name\": \"Gemma 3 12B\", \"model_name\": \"gemma-3-12b\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 1025.0725706277951, \"conso_all_conv\": 4.712925899566667, \"len\": 457, \"mean_conso\": 0.010312748139095551}, {\"name\": \"Ministral 8B-Instruct\", \"model_name\": \"ministral-8b-instruct-2410\", \"organization\": \"Mistral\", \"license\": \"MRL\", \"elo_score\": 935.2129266248544, \"conso_all_conv\": 12.161619686360076, \"len\": 1962, \"mean_conso\": 0.006198582918634086}, {\"name\": \"Mistral-Small-24B-Instruct-2501\", \"model_name\": \"mistral-small-24b-instruct-2501\", \"organization\": \"Mistral\", \"license\": \"Apache 2.0\", \"elo_score\": 996.3182269199416, \"conso_all_conv\": 14.678287007359955, \"len\": 1094, \"mean_conso\": 0.013417081359561203}, {\"name\": \"Liquid Foundation Model\", \"model_name\": \"lfm-40b\", \"organization\": \"Liquid\", \"license\": \"Unknown\", \"elo_score\": 874.9948155889265, \"conso_all_conv\": 15.96704347946668, \"len\": 1069, \"mean_conso\": 0.014936429821764902}, {\"name\": \"Chocolatine-2-14b Instruct\", \"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"organization\": \"jpacifico (individual)\", \"license\": \"Apache 2.0\", \"elo_score\": 822.2441667830092, \"conso_all_conv\": 1.853976390340002, \"len\": 598, \"mean_conso\": 0.003100294967123749}, {\"name\": \"Aya-Expanse-8B\", \"model_name\": \"aya-expanse-8b\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 938.0458384329559, \"conso_all_conv\": 3.6225901576999946, \"len\": 519, \"mean_conso\": 0.006979942500385346}, {\"name\": \"Gemini 2.0 Flash\", \"model_name\": \"gemini-2.0-flash-exp\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1173.7789956398838, \"conso_all_conv\": 25.408618675566665, \"len\": 1001, \"mean_conso\": 0.025383235440126536}, {\"name\": \"GPT-4o mini\", \"model_name\": \"gpt-4o-mini-2024-07-18\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\", \"elo_score\": 996.1948497640711, \"conso_all_conv\": 28.75581949424996, \"len\": 2183, \"mean_conso\": 0.013172615434837361}, {\"name\": \"Claude 3.5 Sonnet V2\", \"model_name\": \"claude-3-5-sonnet-v2\", \"organization\": \"Anthropic\", \"license\": \"Proprietary\", \"elo_score\": 1010.6840482473359, \"conso_all_conv\": 378.31429666249966, \"len\": 1994, \"mean_conso\": 0.1897263273131894}, {\"name\": \"Llama 3.1 8B\", \"model_name\": \"llama-3.1-8b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 876.912266904613, \"conso_all_conv\": 11.279213249379985, \"len\": 1785, \"mean_conso\": 0.006318886974442569}, {\"name\": \"QwQ 32B\", \"model_name\": \"qwq-32b\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 919.3761912785656, \"conso_all_conv\": 6.757635276840006, \"len\": 321, \"mean_conso\": 0.021051823292336465}, {\"name\": \"Phi 4\", \"model_name\": \"phi-4\", \"organization\": \"Microsoft\", \"license\": \"MIT\", \"elo_score\": 942.4092687141602, \"conso_all_conv\": 14.228011999959978, \"len\": 1616, \"mean_conso\": 0.008804462871262363}, {\"name\": \"Llama-3.1-70B\", \"model_name\": \"llama-3.1-70b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 1059.6289588284665, \"conso_all_conv\": 30.55808487246673, \"len\": 1597, \"mean_conso\": 0.01913468057136301}, {\"name\": \"Command R (08-2024)\", \"model_name\": \"c4ai-command-r-08-2024\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 914.1668895670687, \"conso_all_conv\": 44.92108771994969, \"len\": 1180, \"mean_conso\": 0.03806871840673703}, {\"name\": \"Hermes 3\", \"model_name\": \"hermes-3-llama-3.1-405b\", \"organization\": \"Nous Research\", \"license\": \"llama3\", \"elo_score\": 905.5314765487819, \"conso_all_conv\": 995.1062638958654, \"len\": 1381, \"mean_conso\": 0.7205693438782516}, {\"name\": \"DeepSeek-R1 distiil\", \"model_name\": \"deepseek-r1-distill-llama-70b\", \"organization\": \"DeepSeek\", \"license\": \"MIT\", \"elo_score\": 961.7508397949451, \"conso_all_conv\": 9.250565728733326, \"len\": 454, \"mean_conso\": 0.020375695437738605}, {\"name\": \"Llama 3.1 405B\", \"model_name\": \"llama-3.1-405b\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\", \"elo_score\": 949.8798271667176, \"conso_all_conv\": 1017.4927275085383, \"len\": 2114, \"mean_conso\": 0.4813116024165271}, {\"name\": \"Mistral Small-3.1 24B\", \"model_name\": \"mistral-small-3.1-24b\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 1095.9679168980472, \"conso_all_conv\": 5.058114592626664, \"len\": 513, \"mean_conso\": 0.009859872500246909}, {\"name\": \"Gemini 1.5 pro 001\", \"model_name\": \"gemini-1.5-pro-001\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1068.6248683256833, \"conso_all_conv\": 82.15188674586669, \"len\": 392, \"mean_conso\": 0.2095711396578232}, {\"name\": \"Qwen2.5-7B\", \"model_name\": \"qwen2.5-7b-instruct\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\", \"elo_score\": 840.7981552658027, \"conso_all_conv\": 3.159217326046669, \"len\": 427, \"mean_conso\": 0.007398635423996883}, {\"name\": \"Command A\", \"model_name\": \"command-a\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\", \"elo_score\": 1112.2218084578326, \"conso_all_conv\": 18.815315784433313, \"len\": 457, \"mean_conso\": 0.04117136933136392}, {\"name\": \"Gemini 2.0 Flash\", \"model_name\": \"gemini-2.0-flash-001\", \"organization\": \"Google\", \"license\": \"Proprietary\", \"elo_score\": 1155.8158398416097, \"conso_all_conv\": 19.000307364666675, \"len\": 806, \"mean_conso\": 0.023573582338296123}, {\"name\": \"Mixtral 8x22B Instruct\", \"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\", \"elo_score\": 910.1680878139728, \"conso_all_conv\": 50.96510783260014, \"len\": 1756, \"mean_conso\": 0.029023409927448826}, {\"name\": \"o3-mini\", \"model_name\": \"o3-mini\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\", \"elo_score\": 943.5300370774175, \"conso_all_conv\": 57.0336039000001, \"len\": 437, \"mean_conso\": 0.13051167940503455}, {\"name\": \"Jamba Large\", \"model_name\": \"jamba-1.5-large\", \"organization\": \"AI21 Labs\", \"license\": \"Jamba Open Model License\", \"elo_score\": 1038.961527895229, \"conso_all_conv\": 27.637820667239993, \"len\": 77, \"mean_conso\": 0.3589327359381817}, {\"name\": \"Gemma 3 4B\", \"model_name\": \"gemma-3-4b\", \"organization\": \"Google\", \"license\": \"Gemma license\", \"elo_score\": 1059.6343222468988, \"conso_all_conv\": 3.6805289928866673, \"len\": 459, \"mean_conso\": 0.008018581683848948}, {\"name\": \"Phi-3.5 Mini Instruct\", \"model_name\": \"phi-3.5-mini-instruct\", \"organization\": \"Microsoft\", \"license\": \"MIT\", \"elo_score\": 896.6672871049191, \"conso_all_conv\": 2.609331674216668, \"len\": 462, \"mean_conso\": 0.0056479040567460346}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_chart(final_df, title=\"\", log=False, mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rank_comparia.utils import save_data, save_chart\n",
    "\n",
    "save_data(data=final_df, title=\"frugality\", save_path=Path(\"../data\"))\n",
    "\n",
    "save_chart(final_df, \"frugality representation\", log=True, save_path=Path(\"../data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
