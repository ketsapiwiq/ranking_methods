{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de scores à partir du jeu de données `comparia`\n",
    "\n",
    "Dans ce notebook nous illustrons l'utilisation des classes `Ranker` pour calculer des scores à partir des données `comparia`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_TOKEN\"] = getpass(\"Enter your HuggingFace token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/92a324c10228176065909b52bbbaa16430e64c5a (last modified on Wed Jun  4 17:40:33 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.utils import load_comparia\n",
    "\n",
    "reactions = load_comparia(\"ministere-culture/comparia-reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme des données\n",
    "\n",
    "Ici nous utilisons des fonctions *legacy* avec une heuristique simple pour déterminer le résultat d'un *match* (une paire de conversation) à partir des réactions associées. On soustrait le nombre de réactions négatives au nombre de réactions positives pour chaque modèle. Le modèle avec la différence la plus élevée est vainqueur du match. Si les différences sont identiques pour les deux modèle, le *match* est une égalité (on filtre les égalités dans la fonction `get_winners`).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;gemini-1.5-pro-001&quot;</td><td>&quot;ministral-8b-instruct-2410&quot;</td><td>&quot;4450f89de7904d76af3ba953240c66…</td><td>0</td><td>1</td></tr><tr><td>&quot;ministral-8b-instruct-2410&quot;</td><td>&quot;llama-3.1-nemotron-70b-instruc…</td><td>&quot;f8e3b39c027c489ebcb75864416cd9…</td><td>2</td><td>-1</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;mistral-nemo-2407&quot;</td><td>&quot;9f06161e5b0a42d9bba227ed7766f8…</td><td>-2</td><td>-2</td></tr><tr><td>&quot;mistral-large-2411&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;f27ef52c27b64b6e93c1cd42e2fbb4…</td><td>1</td><td>1</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>&quot;lfm-40b&quot;</td><td>&quot;4a4f535270bb435fb9c6b5b4d5cfb9…</td><td>3</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────────┬─────────────────────────┬─────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name             ┆ model_b_name            ┆ conversation_pair_id    ┆ score_a ┆ score_b │\n",
       "│ ---                      ┆ ---                     ┆ ---                     ┆ ---     ┆ ---     │\n",
       "│ str                      ┆ str                     ┆ str                     ┆ i64     ┆ i64     │\n",
       "╞══════════════════════════╪═════════════════════════╪═════════════════════════╪═════════╪═════════╡\n",
       "│ gemini-1.5-pro-001       ┆ ministral-8b-instruct-2 ┆ 4450f89de7904d76af3ba95 ┆ 0       ┆ 1       │\n",
       "│                          ┆ 410                     ┆ 3240c66…                ┆         ┆         │\n",
       "│ ministral-8b-instruct-24 ┆ llama-3.1-nemotron-70b- ┆ f8e3b39c027c489ebcb7586 ┆ 2       ┆ -1      │\n",
       "│ 10                       ┆ instruc…                ┆ 4416cd9…                ┆         ┆         │\n",
       "│ claude-3-5-sonnet-v2     ┆ mistral-nemo-2407       ┆ 9f06161e5b0a42d9bba227e ┆ -2      ┆ -2      │\n",
       "│                          ┆                         ┆ d7766f8…                ┆         ┆         │\n",
       "│ mistral-large-2411       ┆ gemini-1.5-pro-002      ┆ f27ef52c27b64b6e93c1cd4 ┆ 1       ┆ 1       │\n",
       "│                          ┆                         ┆ 2e2fbb4…                ┆         ┆         │\n",
       "│ qwen2.5-coder-32b-instru ┆ lfm-40b                 ┆ 4a4f535270bb435fb9c6b5b ┆ 3       ┆ 2       │\n",
       "│ ct                       ┆                         ┆ 4d5cfb9…                ┆         ┆         │\n",
       "└──────────────────────────┴─────────────────────────┴─────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(reactions)\n",
    "\n",
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule des taux de victoire par modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1530</td><td>1080</td><td>70.588235</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>495</td><td>348</td><td>70.30303</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>688</td><td>480</td><td>69.767442</td></tr><tr><td>&quot;gemini-1.5-pro-001&quot;</td><td>328</td><td>222</td><td>67.682927</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1461</td><td>435</td><td>29.774127</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ deepseek-v3-chat                ┆ 1530 ┆ 1080 ┆ 70.588235 │\n",
       "│ gemma-3-27b                     ┆ 495  ┆ 348  ┆ 70.30303  │\n",
       "│ gemini-2.0-flash-001            ┆ 688  ┆ 480  ┆ 69.767442 │\n",
       "│ gemini-1.5-pro-001              ┆ 328  ┆ 222  ┆ 67.682927 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1461 ┆ 435  ┆ 29.774127 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des scores\n",
    "\n",
    "Pour chaque *match* on calcule un score, on mélange les matchs et on les ajoute un par un à un `ELORanker` qui met à jour les scores à chaque ajout de match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 sets de scores sont calculés avec des ordres d'ajout des matchs différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores moyens sont calculés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1152.8366412019461\n",
      "gemma-3-27b : 1144.7063170304061\n",
      "gemini-2.0-flash-001 : 1136.3821727630689\n",
      "deepseek-v3-0324 : 1121.7816151994991\n",
      "deepseek-v3-chat : 1117.4537219092451\n",
      "command-a : 1112.2775244821546\n",
      "claude-3-7-sonnet : 1109.096220513812\n",
      "gpt-4.1-mini : 1097.665189885303\n",
      "gemma-3-12b : 1089.1013268150045\n",
      "llama-3.1-nemotron-70b-instruct : 1080.5783685002398\n",
      "deepseek-r1 : 1071.1763386118964\n",
      "grok-3-mini-beta : 1068.2694511090176\n",
      "gemma-3-4b : 1059.3082770360838\n",
      "gemini-1.5-pro-002 : 1048.3084756377436\n",
      "gemini-1.5-pro-001 : 1044.9355084180904\n",
      "llama-4-scout : 1042.4478038824443\n",
      "mistral-large-2411 : 1033.376497764221\n",
      "mistral-small-3.1-24b : 1031.5392038354798\n",
      "claude-3-5-sonnet-v2 : 1010.4206329041114\n",
      "o3-mini : 1009.1088800159082\n",
      "o4-mini : 1001.9211577791461\n",
      "gpt-4o-2024-08-06 : 994.4100249379924\n",
      "jamba-1.5-large : 992.4584658748473\n",
      "gpt-4o-mini-2024-07-18 : 990.7846827251981\n",
      "llama-3.1-405b : 990.3972941832486\n",
      "mistral-saba : 987.137596178378\n",
      "llama-3.3-70b : 985.6541098958028\n",
      "gpt-4.1-nano : 982.898287127365\n",
      "gemma-2-27b-it-q8 : 978.7362175741233\n",
      "mistral-small-24b-instruct-2501 : 974.6193092048412\n",
      "phi-4 : 973.8950726483786\n",
      "deepseek-r1-distill-llama-70b : 971.8243658475083\n",
      "aya-expanse-8b : 968.0070929080731\n",
      "gemma-2-9b-it : 964.886359635131\n",
      "llama-3.1-70b : 960.9634725950091\n",
      "ministral-8b-instruct-2410 : 959.6497531164886\n",
      "qwq-32b : 953.7709116917861\n",
      "hermes-3-llama-3.1-405b : 936.0170847682593\n",
      "c4ai-command-r-08-2024 : 932.8001569747589\n",
      "qwen2.5-coder-32b-instruct : 930.9946182472574\n",
      "llama-3.1-8b : 928.3483957234545\n",
      "qwen2.5-7b-instruct : 900.8509323367716\n",
      "lfm-40b : 892.9541687870703\n",
      "phi-3.5-mini-instruct : 890.0269858355588\n",
      "mixtral-8x7b-instruct-v0.1 : 880.2252498149933\n",
      "mistral-nemo-2407 : 841.2435689582437\n",
      "mixtral-8x22b-instruct-v0.1 : 839.2753061497502\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 814.4791909648927\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux calculs des scores avec des ordres de matchs différents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepseek-v3-0324': 1236.3719091756216,\n",
       " 'gemini-2.0-flash-001': 1213.4842721586701,\n",
       " 'gemini-2.0-flash-exp': 1203.5753442579917,\n",
       " 'gemma-3-27b': 1198.4349094171573,\n",
       " 'claude-3-7-sonnet': 1152.7797633880423,\n",
       " 'deepseek-v3-chat': 1143.1466198974388,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1136.792135210341,\n",
       " 'gemini-1.5-pro-002': 1117.1623088312801,\n",
       " 'gemma-2-27b-it-q8': 1106.2182669601466,\n",
       " 'gpt-4.1-mini': 1085.0620689453488,\n",
       " 'command-a': 1083.9635942434466,\n",
       " 'llama-4-scout': 1080.2956506184617,\n",
       " 'deepseek-r1': 1063.4064758803981,\n",
       " 'grok-3-mini-beta': 1058.007952951965,\n",
       " 'claude-3-5-sonnet-v2': 1051.1853144913307,\n",
       " 'gemini-1.5-pro-001': 1048.5352869605028,\n",
       " 'o4-mini': 1046.2094059365756,\n",
       " 'gemma-3-12b': 1043.0737942198189,\n",
       " 'mistral-large-2411': 1029.1756086376288,\n",
       " 'mistral-small-3.1-24b': 1028.2980367179614,\n",
       " 'o3-mini': 1023.2584618001066,\n",
       " 'gemma-2-9b-it': 1006.6588356523501,\n",
       " 'gpt-4o-mini-2024-07-18': 1004.0451285027407,\n",
       " 'llama-3.1-70b': 1002.0562626858222,\n",
       " 'llama-3.1-405b': 995.032086931601,\n",
       " 'deepseek-r1-distill-llama-70b': 985.7367279021745,\n",
       " 'gemma-3-4b': 975.9033833191278,\n",
       " 'llama-3.3-70b': 969.8481080355424,\n",
       " 'gpt-4.1-nano': 959.2789749932667,\n",
       " 'qwen2.5-7b-instruct': 956.3408643627369,\n",
       " 'gpt-4o-2024-08-06': 931.9024697439977,\n",
       " 'mistral-saba': 930.6094394543953,\n",
       " 'aya-expanse-8b': 930.5224402155096,\n",
       " 'mistral-small-24b-instruct-2501': 928.4183181932988,\n",
       " 'phi-4': 928.0964807603492,\n",
       " 'mixtral-8x7b-instruct-v0.1': 925.9550512908356,\n",
       " 'c4ai-command-r-08-2024': 921.7642787728282,\n",
       " 'jamba-1.5-large': 920.758527446454,\n",
       " 'hermes-3-llama-3.1-405b': 918.9420631252564,\n",
       " 'ministral-8b-instruct-2410': 907.7340228265494,\n",
       " 'qwq-32b': 902.7279503976446,\n",
       " 'mistral-nemo-2407': 890.8557905292345,\n",
       " 'llama-3.1-8b': 883.2933678490298,\n",
       " 'qwen2.5-coder-32b-instruct': 875.5705450803334,\n",
       " 'mixtral-8x22b-instruct-v0.1': 822.7276336446083,\n",
       " 'lfm-40b': 821.6472740835354,\n",
       " 'phi-3.5-mini-instruct': 787.4078362206343,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 767.7289572799266}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "random.seed(42)\n",
    "matches_shuffle = random.sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': 1221.5728805040792,\n",
       " 'gemini-2.0-flash-001': 1150.9215453400564,\n",
       " 'claude-3-7-sonnet': 1134.422645443624,\n",
       " 'gemma-3-12b': 1115.3388508066523,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1114.83223717991,\n",
       " 'gemma-3-27b': 1110.5979760900896,\n",
       " 'deepseek-r1': 1105.520595090032,\n",
       " 'grok-3-mini-beta': 1104.974653247346,\n",
       " 'deepseek-v3-0324': 1088.0302373366842,\n",
       " 'mistral-small-3.1-24b': 1064.320830945207,\n",
       " 'deepseek-v3-chat': 1057.7471390694056,\n",
       " 'gemini-1.5-pro-001': 1053.0681126101822,\n",
       " 'mistral-small-24b-instruct-2501': 1050.7599525466683,\n",
       " 'gpt-4.1-mini': 1049.8798396426466,\n",
       " 'llama-4-scout': 1047.041144963684,\n",
       " 'llama-3.1-70b': 1045.0424891233636,\n",
       " 'gemma-3-4b': 1037.3034731891182,\n",
       " 'qwq-32b': 1035.0909878284276,\n",
       " 'ministral-8b-instruct-2410': 1031.7153063316618,\n",
       " 'o3-mini': 1025.3558987188956,\n",
       " 'llama-3.1-405b': 1001.2216524746405,\n",
       " 'gpt-4o-2024-08-06': 1000.0718565058323,\n",
       " 'jamba-1.5-large': 996.8618735655315,\n",
       " 'mistral-saba': 995.4473493238643,\n",
       " 'gemini-1.5-pro-002': 993.2797029065762,\n",
       " 'llama-3.3-70b': 988.7120370572942,\n",
       " 'claude-3-5-sonnet-v2': 983.4466910499576,\n",
       " 'c4ai-command-r-08-2024': 981.2524347589815,\n",
       " 'gpt-4o-mini-2024-07-18': 973.7843349449739,\n",
       " 'gemma-2-27b-it-q8': 972.6171885835823,\n",
       " 'gemma-2-9b-it': 970.9554424014432,\n",
       " 'lfm-40b': 969.3337508766454,\n",
       " 'mistral-large-2411': 966.0810733332173,\n",
       " 'qwen2.5-coder-32b-instruct': 958.9861564685356,\n",
       " 'hermes-3-llama-3.1-405b': 957.5483792848922,\n",
       " 'command-a': 949.3717849885331,\n",
       " 'phi-3.5-mini-instruct': 944.2875829250556,\n",
       " 'phi-4': 940.7716083099237,\n",
       " 'gpt-4.1-nano': 935.7625261806722,\n",
       " 'deepseek-r1-distill-llama-70b': 930.8457683783422,\n",
       " 'aya-expanse-8b': 924.3725677707315,\n",
       " 'o4-mini': 912.5186540990398,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 884.2877483183721,\n",
       " 'mistral-nemo-2407': 884.0585504713601,\n",
       " 'qwen2.5-7b-instruct': 865.0191479746056,\n",
       " 'llama-3.1-8b': 856.1306272524853,\n",
       " 'mixtral-8x22b-instruct-v0.1': 811.9281746951137,\n",
       " 'mixtral-8x7b-instruct-v0.1': 807.5085390920743}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "random.seed(1337)\n",
    "matches_shuffle = random.sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on calcule les scores avec un `Ranker` alternatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': np.float64(1143.1512358130012),\n",
       " 'gemma-3-27b': np.float64(1136.3184203836174),\n",
       " 'gemini-2.0-flash-001': np.float64(1133.400570032988),\n",
       " 'deepseek-v3-chat': np.float64(1114.0328789363393),\n",
       " 'deepseek-v3-0324': np.float64(1113.2067915235539),\n",
       " 'claude-3-7-sonnet': np.float64(1105.1612084450092),\n",
       " 'command-a': np.float64(1101.8786858020478),\n",
       " 'gpt-4.1-mini': np.float64(1093.6685242271394),\n",
       " 'gemma-3-12b': np.float64(1081.4653106195133),\n",
       " 'llama-3.1-nemotron-70b-instruct': np.float64(1078.196872612909),\n",
       " 'grok-3-mini-beta': np.float64(1071.2724072426324),\n",
       " 'deepseek-r1': np.float64(1064.2931624791943),\n",
       " 'gemma-3-4b': np.float64(1055.3168065207053),\n",
       " 'gemini-1.5-pro-002': np.float64(1047.884270532969),\n",
       " 'llama-4-scout': np.float64(1038.2019664020102),\n",
       " 'gemini-1.5-pro-001': np.float64(1037.4923002507746),\n",
       " 'mistral-small-3.1-24b': np.float64(1030.0445144875346),\n",
       " 'mistral-large-2411': np.float64(1028.6925455484807),\n",
       " 'o3-mini': np.float64(1006.2210001085826),\n",
       " 'claude-3-5-sonnet-v2': np.float64(1002.9586930415215),\n",
       " 'o4-mini': np.float64(1002.2210887330519),\n",
       " 'gpt-4o-mini-2024-07-18': np.float64(999.3491370088385),\n",
       " 'mistral-saba': np.float64(996.2399607255587),\n",
       " 'gpt-4o-2024-08-06': np.float64(993.5576631670546),\n",
       " 'llama-3.3-70b': np.float64(990.765165414004),\n",
       " 'llama-3.1-405b': np.float64(990.3338930578011),\n",
       " 'gpt-4.1-nano': np.float64(987.5804923433841),\n",
       " 'jamba-1.5-large': np.float64(985.7386697199976),\n",
       " 'mistral-small-24b-instruct-2501': np.float64(985.0343495551712),\n",
       " 'phi-4': np.float64(980.6013968645213),\n",
       " 'gemma-2-27b-it-q8': np.float64(974.6081627145344),\n",
       " 'llama-3.1-70b': np.float64(968.6630865442116),\n",
       " 'gemma-2-9b-it': np.float64(967.0569404993886),\n",
       " 'deepseek-r1-distill-llama-70b': np.float64(961.7384805979112),\n",
       " 'aya-expanse-8b': np.float64(960.6598616976838),\n",
       " 'qwq-32b': np.float64(958.2356609829194),\n",
       " 'ministral-8b-instruct-2410': np.float64(957.8237000706682),\n",
       " 'hermes-3-llama-3.1-405b': np.float64(939.7716775444147),\n",
       " 'c4ai-command-r-08-2024': np.float64(934.8510999183768),\n",
       " 'llama-3.1-8b': np.float64(928.9460566541117),\n",
       " 'qwen2.5-coder-32b-instruct': np.float64(927.4127141222016),\n",
       " 'qwen2.5-7b-instruct': np.float64(912.2611208222494),\n",
       " 'lfm-40b': np.float64(896.5231395095763),\n",
       " 'phi-3.5-mini-instruct': np.float64(889.3352897771736),\n",
       " 'mixtral-8x7b-instruct-v0.1': np.float64(883.6849028582083),\n",
       " 'mixtral-8x22b-instruct-v0.1': np.float64(859.7838306178774),\n",
       " 'mistral-nemo-2407': np.float64(855.2771876657266),\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': np.float64(829.08710580286)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.maximum_likelihood import MaximumLikelihoodRanker\n",
    "\n",
    "ranker = MaximumLikelihoodRanker()\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes `Ranker` ont une méthode `compute_boostrap_scores` qui permettent de calculer des scores et intervalles de confiance bootstrap (les matchs qui servent au calcul des scores pour chaque échantillon bootstrap sont issus de ré-échantillonages avec remise de l'échantillon de matchs initial). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 22993 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:04<00:00, 23.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1155.859289</td><td>1044.442026</td><td>1274.769562</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1142.655273</td><td>1029.583229</td><td>1239.132195</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1140.367437</td><td>1017.22942</td><td>1238.438644</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>1114.776689</td><td>1008.863562</td><td>1235.314884</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1114.200893</td><td>1006.377414</td><td>1203.025085</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>886.571652</td><td>756.061861</td><td>1018.108256</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>873.88268</td><td>781.99617</td><td>985.558817</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>858.155122</td><td>770.765492</td><td>993.206626</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>857.208879</td><td>751.981659</td><td>965.433334</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>815.502416</td><td>716.268523</td><td>922.603257</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model                           ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 1155.859289 ┆ 1044.442026 ┆ 1274.769562 │\n",
       "│ gemini-2.0-flash-001            ┆ 1142.655273 ┆ 1029.583229 ┆ 1239.132195 │\n",
       "│ gemma-3-27b                     ┆ 1140.367437 ┆ 1017.22942  ┆ 1238.438644 │\n",
       "│ deepseek-v3-0324                ┆ 1114.776689 ┆ 1008.863562 ┆ 1235.314884 │\n",
       "│ deepseek-v3-chat                ┆ 1114.200893 ┆ 1006.377414 ┆ 1203.025085 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 886.571652  ┆ 756.061861  ┆ 1018.108256 │\n",
       "│ phi-3.5-mini-instruct           ┆ 873.88268   ┆ 781.99617   ┆ 985.558817  │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 858.155122  ┆ 770.765492  ┆ 993.206626  │\n",
       "│ mistral-nemo-2407               ┆ 857.208879  ┆ 751.981659  ┆ 965.433334  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 815.502416  ┆ 716.268523  ┆ 922.603257  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = ELORanker(K=40)\n",
    "\n",
    "ranker.add_players(model_names)  # type: ignore\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 22993 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:06<00:00, 15.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1144.325284</td><td>1119.460207</td><td>1162.371241</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1137.418884</td><td>1100.19138</td><td>1163.874126</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1135.156265</td><td>1113.097957</td><td>1157.500833</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>1118.98235</td><td>1080.592383</td><td>1158.408431</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1113.222689</td><td>1097.716567</td><td>1129.206429</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>885.512672</td><td>852.759295</td><td>916.903774</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>883.558106</td><td>853.418372</td><td>913.701314</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>859.604307</td><td>842.88358</td><td>875.133647</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>854.648057</td><td>840.199542</td><td>870.119204</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>826.818361</td><td>803.18146</td><td>859.249549</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model                           ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 1144.325284 ┆ 1119.460207 ┆ 1162.371241 │\n",
       "│ gemma-3-27b                     ┆ 1137.418884 ┆ 1100.19138  ┆ 1163.874126 │\n",
       "│ gemini-2.0-flash-001            ┆ 1135.156265 ┆ 1113.097957 ┆ 1157.500833 │\n",
       "│ deepseek-v3-0324                ┆ 1118.98235  ┆ 1080.592383 ┆ 1158.408431 │\n",
       "│ deepseek-v3-chat                ┆ 1113.222689 ┆ 1097.716567 ┆ 1129.206429 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ phi-3.5-mini-instruct           ┆ 885.512672  ┆ 852.759295  ┆ 916.903774  │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 883.558106  ┆ 853.418372  ┆ 913.701314  │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 859.604307  ┆ 842.88358   ┆ 875.133647  │\n",
       "│ mistral-nemo-2407               ┆ 854.648057  ┆ 840.199542  ┆ 870.119204  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 826.818361  ┆ 803.18146   ┆ 859.249549  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = MaximumLikelihoodRanker()\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
