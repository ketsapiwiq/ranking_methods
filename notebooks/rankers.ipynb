{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de scores à partir du jeu de données `comparia`\n",
    "\n",
    "Dans ce notebook nous illustrons l'utilisation des classes `Ranker` pour calculer des scores à partir des données `comparia`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_TOKEN\"] = getpass(\"Enter your HuggingFace token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/92a324c10228176065909b52bbbaa16430e64c5a (last modified on Wed Jun  4 17:40:33 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.utils import load_comparia\n",
    "\n",
    "reactions = load_comparia(\"ministere-culture/comparia-reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme des données\n",
    "\n",
    "Ici nous utilisons des fonctions *legacy* avec une heuristique simple pour déterminer le résultat d'un *match* (une paire de conversation) à partir des réactions associées. On soustrait le nombre de réactions négatives au nombre de réactions positives pour chaque modèle. Le modèle avec la différence la plus élevée est vainqueur du match. Si les différences sont identiques pour les deux modèle, le *match* est une égalité (on filtre les égalités dans la fonction `get_winners`).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;mistral-nemo-2407&quot;</td><td>&quot;gemini-2.0-flash-exp&quot;</td><td>&quot;c8b9ec214d2f4dafb0a95c78d8a892…</td><td>1</td><td>0</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;dff1c1d545e948f89c1fcd1d7a2abc…</td><td>0</td><td>2</td></tr><tr><td>&quot;phi-4&quot;</td><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>&quot;eb8ae1d9580944d89b6a48162949e7…</td><td>-1</td><td>1</td></tr><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;b01da0ffc514436ba0bafb5fc93532…</td><td>0</td><td>1</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;080356cf942546dd92483be99cb025…</td><td>1</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────────┬─────────────────────────┬─────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name             ┆ model_b_name            ┆ conversation_pair_id    ┆ score_a ┆ score_b │\n",
       "│ ---                      ┆ ---                     ┆ ---                     ┆ ---     ┆ ---     │\n",
       "│ str                      ┆ str                     ┆ str                     ┆ i64     ┆ i64     │\n",
       "╞══════════════════════════╪═════════════════════════╪═════════════════════════╪═════════╪═════════╡\n",
       "│ mistral-nemo-2407        ┆ gemini-2.0-flash-exp    ┆ c8b9ec214d2f4dafb0a95c7 ┆ 1       ┆ 0       │\n",
       "│                          ┆                         ┆ 8d8a892…                ┆         ┆         │\n",
       "│ mistral-nemo-2407        ┆ gpt-4o-mini-2024-07-18  ┆ dff1c1d545e948f89c1fcd1 ┆ 0       ┆ 2       │\n",
       "│                          ┆                         ┆ d7a2abc…                ┆         ┆         │\n",
       "│ phi-4                    ┆ qwen2.5-coder-32b-instr ┆ eb8ae1d9580944d89b6a481 ┆ -1      ┆ 1       │\n",
       "│                          ┆ uct                     ┆ 62949e7…                ┆         ┆         │\n",
       "│ gemini-2.0-flash-exp     ┆ gpt-4o-2024-08-06       ┆ b01da0ffc514436ba0bafb5 ┆ 0       ┆ 1       │\n",
       "│                          ┆                         ┆ fc93532…                ┆         ┆         │\n",
       "│ mixtral-8x7b-instruct-v0 ┆ gpt-4o-mini-2024-07-18  ┆ 080356cf942546dd92483be ┆ 1       ┆ 0       │\n",
       "│ .1                       ┆                         ┆ 99cb025…                ┆         ┆         │\n",
       "└──────────────────────────┴─────────────────────────┴─────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(reactions)\n",
    "\n",
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule des taux de victoire par modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1530</td><td>1080</td><td>70.588235</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>495</td><td>348</td><td>70.30303</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>688</td><td>480</td><td>69.767442</td></tr><tr><td>&quot;gemini-1.5-pro-001&quot;</td><td>328</td><td>222</td><td>67.682927</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1461</td><td>435</td><td>29.774127</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ deepseek-v3-chat                ┆ 1530 ┆ 1080 ┆ 70.588235 │\n",
       "│ gemma-3-27b                     ┆ 495  ┆ 348  ┆ 70.30303  │\n",
       "│ gemini-2.0-flash-001            ┆ 688  ┆ 480  ┆ 69.767442 │\n",
       "│ gemini-1.5-pro-001              ┆ 328  ┆ 222  ┆ 67.682927 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1461 ┆ 435  ┆ 29.774127 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des scores\n",
    "\n",
    "Pour chaque *match* on calcule un score, on mélange les matchs et on les ajoute un par un à un `ELORanker` qui met à jour les scores à chaque ajout de match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 sets de scores sont calculés avec des ordres d'ajout des matchs différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores moyens sont calculés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1147.8481175501213\n",
      "gemma-3-27b : 1145.7125030288078\n",
      "gemini-2.0-flash-001 : 1129.5428311878898\n",
      "deepseek-v3-0324 : 1125.3260784689844\n",
      "deepseek-v3-chat : 1124.6133978301414\n",
      "command-a : 1107.5363513892096\n",
      "claude-3-7-sonnet : 1103.229348265574\n",
      "gpt-4.1-mini : 1098.503816385903\n",
      "gemma-3-12b : 1088.4978148565012\n",
      "llama-3.1-nemotron-70b-instruct : 1080.3102454203633\n",
      "grok-3-mini-beta : 1070.8061027704755\n",
      "deepseek-r1 : 1069.1528137014666\n",
      "gemma-3-4b : 1062.2977150873512\n",
      "gemini-1.5-pro-002 : 1048.9745576207565\n",
      "gemini-1.5-pro-001 : 1037.9813083316171\n",
      "llama-4-scout : 1036.8566662260016\n",
      "mistral-large-2411 : 1023.6826125523356\n",
      "mistral-small-3.1-24b : 1021.6568432057678\n",
      "o4-mini : 1006.6902726205205\n",
      "claude-3-5-sonnet-v2 : 1005.5743258490104\n",
      "gpt-4o-2024-08-06 : 1004.3699633518434\n",
      "o3-mini : 1002.3993567426545\n",
      "gpt-4o-mini-2024-07-18 : 1001.2141806253848\n",
      "llama-3.1-405b : 996.804254959252\n",
      "mistral-saba : 994.494144668334\n",
      "mistral-small-24b-instruct-2501 : 994.4299252148985\n",
      "llama-3.3-70b : 994.2891944979352\n",
      "gpt-4.1-nano : 986.739953989637\n",
      "gemma-2-27b-it-q8 : 982.2396040409143\n",
      "jamba-1.5-large : 979.8303788845215\n",
      "phi-4 : 976.4718139543411\n",
      "llama-3.1-70b : 972.1126757632949\n",
      "gemma-2-9b-it : 965.8704659630685\n",
      "deepseek-r1-distill-llama-70b : 960.9596064664403\n",
      "qwq-32b : 958.0529372532322\n",
      "aya-expanse-8b : 952.8349750028981\n",
      "ministral-8b-instruct-2410 : 949.059789596187\n",
      "c4ai-command-r-08-2024 : 930.64174746361\n",
      "qwen2.5-coder-32b-instruct : 930.1935967612812\n",
      "hermes-3-llama-3.1-405b : 927.5972112000188\n",
      "llama-3.1-8b : 924.34479080001\n",
      "qwen2.5-7b-instruct : 906.3102478328152\n",
      "lfm-40b : 900.5943151633633\n",
      "phi-3.5-mini-instruct : 878.0081851638894\n",
      "mixtral-8x7b-instruct-v0.1 : 876.7175815654987\n",
      "mixtral-8x22b-instruct-v0.1 : 852.1983375611312\n",
      "mistral-nemo-2407 : 843.203738459216\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 823.2233047055346\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux calculs des scores avec des ordres de matchs différents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemma-3-27b': 1175.7675169152285,\n",
       " 'deepseek-r1': 1174.2652704264415,\n",
       " 'gemini-1.5-pro-002': 1172.0786055985104,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1132.3337169470485,\n",
       " 'claude-3-7-sonnet': 1128.863574152478,\n",
       " 'llama-3.3-70b': 1119.6917588766162,\n",
       " 'deepseek-v3-0324': 1118.149224110632,\n",
       " 'grok-3-mini-beta': 1115.0312086006782,\n",
       " 'gemini-1.5-pro-001': 1100.5184241312677,\n",
       " 'mistral-large-2411': 1096.7574765960023,\n",
       " 'mistral-small-3.1-24b': 1082.2690858138126,\n",
       " 'command-a': 1081.9517099869151,\n",
       " 'gemma-3-12b': 1074.0889420030878,\n",
       " 'gemma-2-27b-it-q8': 1070.6257559112175,\n",
       " 'gemma-2-9b-it': 1067.4373937253715,\n",
       " 'gpt-4o-mini-2024-07-18': 1058.2175255408786,\n",
       " 'llama-3.1-70b': 1057.9762109737276,\n",
       " 'gemma-3-4b': 1054.437991134534,\n",
       " 'gemini-2.0-flash-001': 1051.1481451057036,\n",
       " 'mistral-saba': 1047.1976969808816,\n",
       " 'mistral-small-24b-instruct-2501': 1046.9249610246507,\n",
       " 'gemini-2.0-flash-exp': 1028.484044771889,\n",
       " 'gpt-4.1-mini': 1027.632715985455,\n",
       " 'deepseek-v3-chat': 1025.384156513145,\n",
       " 'claude-3-5-sonnet-v2': 1024.9415256233124,\n",
       " 'hermes-3-llama-3.1-405b': 1022.3970851729522,\n",
       " 'deepseek-r1-distill-llama-70b': 1017.4510749638059,\n",
       " 'o3-mini': 1013.7380223887683,\n",
       " 'ministral-8b-instruct-2410': 1008.2425590539386,\n",
       " 'gpt-4o-2024-08-06': 1001.9550128856029,\n",
       " 'aya-expanse-8b': 988.7260794124983,\n",
       " 'llama-3.1-405b': 984.7530513516216,\n",
       " 'o4-mini': 966.6699454225663,\n",
       " 'jamba-1.5-large': 949.3052996762863,\n",
       " 'gpt-4.1-nano': 925.0009459306407,\n",
       " 'phi-4': 920.9478960184097,\n",
       " 'llama-4-scout': 917.0678276323683,\n",
       " 'qwq-32b': 907.6139996262476,\n",
       " 'c4ai-command-r-08-2024': 859.008315409827,\n",
       " 'lfm-40b': 855.7279849453727,\n",
       " 'qwen2.5-coder-32b-instruct': 853.7498499055094,\n",
       " 'phi-3.5-mini-instruct': 852.2530304035283,\n",
       " 'mistral-nemo-2407': 850.9370017291585,\n",
       " 'qwen2.5-7b-instruct': 835.1811357890869,\n",
       " 'llama-3.1-8b': 829.8010010162474,\n",
       " 'mixtral-8x22b-instruct-v0.1': 823.6623165106794,\n",
       " 'mixtral-8x7b-instruct-v0.1': 796.2337336642545,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 687.4021936411597}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "random.seed(42)\n",
    "matches_shuffle = random.sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-001': 1171.92148019597,\n",
       " 'gemini-2.0-flash-exp': 1169.0353339957626,\n",
       " 'gemma-3-27b': 1168.9292503999961,\n",
       " 'deepseek-r1': 1143.5056696392357,\n",
       " 'gpt-4.1-mini': 1135.4871025277052,\n",
       " 'command-a': 1118.5292852098798,\n",
       " 'deepseek-v3-0324': 1113.9310815347837,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1099.7292452690317,\n",
       " 'gemma-3-12b': 1089.6004058492053,\n",
       " 'claude-3-7-sonnet': 1083.3614620013254,\n",
       " 'gemini-1.5-pro-001': 1082.626905044981,\n",
       " 'gemini-1.5-pro-002': 1056.7671938056449,\n",
       " 'deepseek-v3-chat': 1048.2244121294304,\n",
       " 'o3-mini': 1045.2339253978762,\n",
       " 'o4-mini': 1042.195219022252,\n",
       " 'llama-3.1-405b': 1039.021646735078,\n",
       " 'jamba-1.5-large': 1036.8735697183015,\n",
       " 'gemma-3-4b': 1035.1880985062458,\n",
       " 'deepseek-r1-distill-llama-70b': 1032.6497520747007,\n",
       " 'aya-expanse-8b': 1032.2632356843005,\n",
       " 'mistral-small-3.1-24b': 1022.610683586296,\n",
       " 'hermes-3-llama-3.1-405b': 1015.2924618594501,\n",
       " 'grok-3-mini-beta': 1012.240710581544,\n",
       " 'llama-4-scout': 1010.0772783145576,\n",
       " 'mistral-saba': 1001.1459385154576,\n",
       " 'claude-3-5-sonnet-v2': 990.1910289776838,\n",
       " 'gpt-4o-2024-08-06': 989.0073862048146,\n",
       " 'phi-4': 986.4325555984207,\n",
       " 'qwen2.5-coder-32b-instruct': 984.8882814137972,\n",
       " 'gemma-2-27b-it-q8': 982.2985577544863,\n",
       " 'gpt-4o-mini-2024-07-18': 978.2328252092109,\n",
       " 'mistral-large-2411': 975.2526926675783,\n",
       " 'mistral-small-24b-instruct-2501': 967.8886093602339,\n",
       " 'qwen2.5-7b-instruct': 965.0677943638706,\n",
       " 'ministral-8b-instruct-2410': 957.5342301139939,\n",
       " 'gpt-4.1-nano': 954.6790197780915,\n",
       " 'lfm-40b': 952.7924962443365,\n",
       " 'llama-3.3-70b': 944.239943397345,\n",
       " 'gemma-2-9b-it': 937.497689300957,\n",
       " 'qwq-32b': 915.1655800486953,\n",
       " 'llama-3.1-8b': 907.5131838669447,\n",
       " 'c4ai-command-r-08-2024': 893.9884284227046,\n",
       " 'llama-3.1-70b': 878.2560671240475,\n",
       " 'phi-3.5-mini-instruct': 877.5883359326158,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 813.2316469156912,\n",
       " 'mixtral-8x22b-instruct-v0.1': 808.2757784488632,\n",
       " 'mixtral-8x7b-instruct-v0.1': 773.5006724878679,\n",
       " 'mistral-nemo-2407': 760.0358487687307}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "random.seed(1337)\n",
    "matches_shuffle = random.sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation d'un Ranker par maximum de vraisemblance\n",
    "\n",
    "Ici on calcule les scores avec un `Ranker` alternatif, défini dans `src/rank_comparia/maximum_likelihood.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': np.float64(1143.1512358130012),\n",
       " 'gemma-3-27b': np.float64(1136.3184203836174),\n",
       " 'gemini-2.0-flash-001': np.float64(1133.400570032988),\n",
       " 'deepseek-v3-chat': np.float64(1114.0328789363393),\n",
       " 'deepseek-v3-0324': np.float64(1113.2067915235539),\n",
       " 'claude-3-7-sonnet': np.float64(1105.1612084450092),\n",
       " 'command-a': np.float64(1101.8786858020478),\n",
       " 'gpt-4.1-mini': np.float64(1093.6685242271394),\n",
       " 'gemma-3-12b': np.float64(1081.4653106195133),\n",
       " 'llama-3.1-nemotron-70b-instruct': np.float64(1078.196872612909),\n",
       " 'grok-3-mini-beta': np.float64(1071.2724072426324),\n",
       " 'deepseek-r1': np.float64(1064.2931624791943),\n",
       " 'gemma-3-4b': np.float64(1055.3168065207053),\n",
       " 'gemini-1.5-pro-002': np.float64(1047.884270532969),\n",
       " 'llama-4-scout': np.float64(1038.2019664020102),\n",
       " 'gemini-1.5-pro-001': np.float64(1037.4923002507746),\n",
       " 'mistral-small-3.1-24b': np.float64(1030.0445144875346),\n",
       " 'mistral-large-2411': np.float64(1028.6925455484807),\n",
       " 'o3-mini': np.float64(1006.2210001085826),\n",
       " 'claude-3-5-sonnet-v2': np.float64(1002.9586930415215),\n",
       " 'o4-mini': np.float64(1002.2210887330519),\n",
       " 'gpt-4o-mini-2024-07-18': np.float64(999.3491370088385),\n",
       " 'mistral-saba': np.float64(996.2399607255587),\n",
       " 'gpt-4o-2024-08-06': np.float64(993.5576631670547),\n",
       " 'llama-3.3-70b': np.float64(990.7651654140041),\n",
       " 'llama-3.1-405b': np.float64(990.3338930578011),\n",
       " 'gpt-4.1-nano': np.float64(987.5804923433841),\n",
       " 'jamba-1.5-large': np.float64(985.7386697199976),\n",
       " 'mistral-small-24b-instruct-2501': np.float64(985.0343495551712),\n",
       " 'phi-4': np.float64(980.6013968645213),\n",
       " 'gemma-2-27b-it-q8': np.float64(974.6081627145344),\n",
       " 'llama-3.1-70b': np.float64(968.6630865442116),\n",
       " 'gemma-2-9b-it': np.float64(967.0569404993886),\n",
       " 'deepseek-r1-distill-llama-70b': np.float64(961.7384805979112),\n",
       " 'aya-expanse-8b': np.float64(960.6598616976838),\n",
       " 'qwq-32b': np.float64(958.2356609829194),\n",
       " 'ministral-8b-instruct-2410': np.float64(957.8237000706683),\n",
       " 'hermes-3-llama-3.1-405b': np.float64(939.7716775444147),\n",
       " 'c4ai-command-r-08-2024': np.float64(934.8510999183768),\n",
       " 'llama-3.1-8b': np.float64(928.9460566541117),\n",
       " 'qwen2.5-coder-32b-instruct': np.float64(927.4127141222015),\n",
       " 'qwen2.5-7b-instruct': np.float64(912.2611208222494),\n",
       " 'lfm-40b': np.float64(896.5231395095763),\n",
       " 'phi-3.5-mini-instruct': np.float64(889.3352897771736),\n",
       " 'mixtral-8x7b-instruct-v0.1': np.float64(883.6849028582083),\n",
       " 'mixtral-8x22b-instruct-v0.1': np.float64(859.7838306178774),\n",
       " 'mistral-nemo-2407': np.float64(855.2771876657266),\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': np.float64(829.08710580286)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.maximum_likelihood import MaximumLikelihoodRanker\n",
    "\n",
    "ranker = MaximumLikelihoodRanker()\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes `Ranker` ont une méthode `compute_boostrap_scores` qui permettent de calculer des scores et intervalles de confiance bootstrap (les matchs qui servent au calcul des scores pour chaque échantillon bootstrap sont issus de ré-échantillonages avec remise de l'échantillon de matchs initial). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 22993 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:04<00:00, 24.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1153.018523</td><td>1041.897383</td><td>1287.775123</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1147.807565</td><td>1023.970027</td><td>1258.39757</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1133.735125</td><td>1026.499754</td><td>1252.080781</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1132.257993</td><td>997.639738</td><td>1243.592212</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>1117.417997</td><td>995.152635</td><td>1219.643944</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>893.843588</td><td>774.208085</td><td>1012.10676</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>889.784753</td><td>792.780578</td><td>990.414233</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>851.233953</td><td>766.146503</td><td>950.10665</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>850.156447</td><td>764.034211</td><td>952.399245</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>815.096847</td><td>693.662437</td><td>920.069715</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model                           ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 1153.018523 ┆ 1041.897383 ┆ 1287.775123 │\n",
       "│ gemma-3-27b                     ┆ 1147.807565 ┆ 1023.970027 ┆ 1258.39757  │\n",
       "│ deepseek-v3-chat                ┆ 1133.735125 ┆ 1026.499754 ┆ 1252.080781 │\n",
       "│ gemini-2.0-flash-001            ┆ 1132.257993 ┆ 997.639738  ┆ 1243.592212 │\n",
       "│ deepseek-v3-0324                ┆ 1117.417997 ┆ 995.152635  ┆ 1219.643944 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 893.843588  ┆ 774.208085  ┆ 1012.10676  │\n",
       "│ lfm-40b                         ┆ 889.784753  ┆ 792.780578  ┆ 990.414233  │\n",
       "│ mistral-nemo-2407               ┆ 851.233953  ┆ 766.146503  ┆ 950.10665   │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 850.156447  ┆ 764.034211  ┆ 952.399245  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 815.096847  ┆ 693.662437  ┆ 920.069715  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = ELORanker(K=40)\n",
    "\n",
    "ranker.add_players(model_names)  # type: ignore\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 22993 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:05<00:00, 16.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1144.740823</td><td>1121.58747</td><td>1167.795144</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1138.644425</td><td>1114.739581</td><td>1168.384904</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1133.733449</td><td>1115.320508</td><td>1156.431579</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>1113.812728</td><td>1080.199238</td><td>1148.106654</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1113.630365</td><td>1097.878134</td><td>1132.646018</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>889.556082</td><td>858.835227</td><td>922.926601</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>884.614638</td><td>856.992706</td><td>904.549497</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>860.767683</td><td>845.844134</td><td>875.150503</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>857.140384</td><td>840.639206</td><td>868.92556</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>826.864417</td><td>801.086394</td><td>849.115648</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model                           ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 1144.740823 ┆ 1121.58747  ┆ 1167.795144 │\n",
       "│ gemma-3-27b                     ┆ 1138.644425 ┆ 1114.739581 ┆ 1168.384904 │\n",
       "│ gemini-2.0-flash-001            ┆ 1133.733449 ┆ 1115.320508 ┆ 1156.431579 │\n",
       "│ deepseek-v3-0324                ┆ 1113.812728 ┆ 1080.199238 ┆ 1148.106654 │\n",
       "│ deepseek-v3-chat                ┆ 1113.630365 ┆ 1097.878134 ┆ 1132.646018 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ phi-3.5-mini-instruct           ┆ 889.556082  ┆ 858.835227  ┆ 922.926601  │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 884.614638  ┆ 856.992706  ┆ 904.549497  │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 860.767683  ┆ 845.844134  ┆ 875.150503  │\n",
       "│ mistral-nemo-2407               ┆ 857.140384  ┆ 840.639206  ┆ 868.92556   │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 826.864417  ┆ 801.086394  ┆ 849.115648  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = MaximumLikelihoodRanker()\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajout de la notion de frugalité dans le score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.frugality import draw_ranked_frugality, get_normalized_log_cost, calculate_frugality_score\n",
    "\n",
    "conversations = load_comparia(\"ministere-culture/comparia-conversations\")\n",
    "frugality_score = calculate_frugality_score(conversations, None, True)\n",
    "graph = draw_ranked_frugality(frugal_log_score=get_normalized_log_cost(frugality_score), bootstraped_scores=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e4ce7a7163ea479095fc22888f140b4c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e4ce7a7163ea479095fc22888f140b4c.vega-embed details,\n",
       "  #altair-viz-e4ce7a7163ea479095fc22888f140b4c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e4ce7a7163ea479095fc22888f140b4c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e4ce7a7163ea479095fc22888f140b4c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e4ce7a7163ea479095fc22888f140b4c\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"legend\": {\"labelLimit\": 300}}, \"data\": {\"name\": \"data-4e061bcb9812fde4dd4ec0a607259ee7\"}, \"mark\": {\"type\": \"point\", \"tooltip\": true}, \"encoding\": {\"color\": {\"field\": \"model\", \"type\": \"nominal\"}, \"x\": {\"field\": \"median\", \"scale\": {\"domainMin\": 800.0, \"domainMax\": 1200.0}, \"title\": \"elo score\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"scale\": {\"domainMin\": 300.0, \"domainMax\": 1200.0}, \"title\": \"frugality elo score\", \"type\": \"quantitative\"}}, \"height\": 450, \"params\": [{\"name\": \"param_1\", \"bind\": {\"input\": \"range\", \"max\": 1, \"min\": 0, \"name\": \"frugality coefficient:  \"}, \"value\": 1}], \"title\": \"frugality elo ranking\", \"transform\": [{\"calculate\": \"(datum.median - (param_1 * (datum.cost * 366)))\", \"as\": \"y\"}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-4e061bcb9812fde4dd4ec0a607259ee7\": [{\"model\": \"aya-expanse-8b\", \"median\": 960.3081575662809, \"cost\": -0.30225179113580936}, {\"model\": \"c4ai-command-r-08-2024\", \"median\": 936.7969825418959, \"cost\": 8.881784197001252e-16}, {\"model\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"median\": 826.8644167100958, \"cost\": -0.31873633411705704}, {\"model\": \"claude-3-5-sonnet-v2\", \"median\": 1003.6930138390869, \"cost\": 1.249530541893717}, {\"model\": \"claude-3-7-sonnet\", \"median\": 1101.1296132470445, \"cost\": 1.2495305418937153}, {\"model\": \"command-a\", \"median\": 1104.7010689401723, \"cost\": 0.38226228402165496}, {\"model\": \"deepseek-r1\", \"median\": 1065.1692483584234, \"cost\": 0.7939890896114417}, {\"model\": \"deepseek-r1-distill-llama-70b\", \"median\": 958.795247414386, \"cost\": 0.21747578810586177}, {\"model\": \"deepseek-v3-0324\", \"median\": 1113.8127282675782, \"cost\": 0.7939890896114417}, {\"model\": \"deepseek-v3-chat\", \"median\": 1113.6303647174595, \"cost\": 0.7939890896114408}, {\"model\": \"gemini-1.5-pro-001\", \"median\": 1040.475111731873, \"cost\": 1.2466857817034938}, {\"model\": \"gemini-1.5-pro-002\", \"median\": 1048.713939314613, \"cost\": 1.24900751927514}, {\"model\": \"gemini-2.0-flash-001\", \"median\": 1133.7334490882204, \"cost\": 0.03856163599175755}, {\"model\": \"gemini-2.0-flash-exp\", \"median\": 1144.740823128046, \"cost\": 0.03856163599175666}, {\"model\": \"gemma-2-27b-it-q8\", \"median\": 974.7647426203287, \"cost\": -0.06984816755028067}, {\"model\": \"gemma-2-9b-it\", \"median\": 966.9401962886741, \"cost\": -0.28674553916989964}, {\"model\": \"gemma-3-12b\", \"median\": 1078.8536096673813, \"cost\": -0.24193823019243865}, {\"model\": \"gemma-3-27b\", \"median\": 1138.6444246345932, \"cost\": -0.06984816755027978}, {\"model\": \"gemma-3-4b\", \"median\": 1055.7159950223233, \"cost\": -0.37231349860838137}, {\"model\": \"gpt-4.1-mini\", \"median\": 1093.7840106814815, \"cost\": 0.21747578810586266}, {\"model\": \"gpt-4.1-nano\", \"median\": 988.8574812232749, \"cost\": 0.0}, {\"model\": \"gpt-4o-2024-08-06\", \"median\": 993.2081124071967, \"cost\": 0.9099986164021088}, {\"model\": \"gpt-4o-mini-2024-07-18\", \"median\": 999.6432478446309, \"cost\": -3.5659937475784886e-05}, {\"model\": \"grok-3-mini-beta\", \"median\": 1068.5955440215735, \"cost\": 0.9099986164021105}, {\"model\": \"hermes-3-llama-3.1-405b\", \"median\": 940.1453057437682, \"cost\": 1.498095476260533}, {\"model\": \"jamba-1.5-large\", \"median\": 980.0289682748489, \"cost\": 0.7984425037421765}, {\"model\": \"lfm-40b\", \"median\": 896.1389017167962, \"cost\": 0.03856163599175755}, {\"model\": \"llama-3.1-405b\", \"median\": 991.7009116804984, \"cost\": 1.498095476260533}, {\"model\": \"llama-3.1-70b\", \"median\": 965.1079825796389, \"cost\": 0.21747578810586354}, {\"model\": \"llama-3.1-8b\", \"median\": 929.3794002983744, \"cost\": -0.3022517911358129}, {\"model\": \"llama-3.1-nemotron-70b-instruct\", \"median\": 1078.1660787086137, \"cost\": 0.21747578810586088}, {\"model\": \"llama-3.3-70b\", \"median\": 990.8688086546213, \"cost\": 0.21747578810586088}, {\"model\": \"llama-4-scout\", \"median\": 1041.788501569019, \"cost\": -0.1767017271339153}, {\"model\": \"ministral-8b-instruct-2410\", \"median\": 958.1070277943245, \"cost\": -0.3022517911358129}, {\"model\": \"mistral-large-2411\", \"median\": 1027.2644318732107, \"cost\": 0.4206500320907649}, {\"model\": \"mistral-nemo-2407\", \"median\": 857.1403842144284, \"cost\": -0.241938230192436}, {\"model\": \"mistral-saba\", \"median\": 999.5085195132749, \"cost\": -0.09923752954196186}, {\"model\": \"mistral-small-24b-instruct-2501\", \"median\": 985.034866927088, \"cost\": -0.09923752954196363}, {\"model\": \"mistral-small-3.1-24b\", \"median\": 1029.0238733463584, \"cost\": -0.09923752954196186}, {\"model\": \"mixtral-8x22b-instruct-v0.1\", \"median\": 860.7676825115018, \"cost\": 0.36807215387247805}, {\"model\": \"mixtral-8x7b-instruct-v0.1\", \"median\": 884.6146375056313, \"cost\": -0.21472558478401726}, {\"model\": \"o3-mini\", \"median\": 1002.9322428953703, \"cost\": 0.9099986164021105}, {\"model\": \"o4-mini\", \"median\": 1001.6143552663964, \"cost\": 0.9099986164021105}, {\"model\": \"phi-3.5-mini-instruct\", \"median\": 889.5560818757956, \"cost\": -0.3917493743738403}, {\"model\": \"phi-4\", \"median\": 980.3364724811101, \"cost\": -0.21465692835301375}, {\"model\": \"qwen2.5-7b-instruct\", \"median\": 910.9423975041723, \"cost\": -0.31873633411705793}, {\"model\": \"qwen2.5-coder-32b-instruct\", \"median\": 927.6683281591932, \"cost\": -0.02489535897645556}, {\"model\": \"qwq-32b\", \"median\": 959.4601136686683, \"cost\": -0.02489535897645645}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
