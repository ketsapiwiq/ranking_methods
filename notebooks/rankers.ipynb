{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de scores à partir du jeu de données `comparia`\n",
    "\n",
    "Dans ce notebook nous illustrons l'utilisation des classes `Ranker` pour calculer des scores à partir des données `comparia`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/5a02c58f54f2db3fc51f076d24a840f04efa01fa (last modified on Tue Sep 30 13:43:20 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.utils import load_comparia\n",
    "\n",
    "token = None\n",
    "\n",
    "reactions = load_comparia(\"ministere-culture/comparia-reactions\", token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme des données\n",
    "\n",
    "Ici nous utilisons des fonctions *legacy* avec une heuristique simple pour déterminer le résultat d'un *match* (une paire de conversation) à partir des réactions associées. On soustrait le nombre de réactions négatives au nombre de réactions positives pour chaque modèle. Le modèle avec la différence la plus élevée est vainqueur du match. Si les différences sont identiques pour les deux modèle, le *match* est une égalité (on filtre les égalités dans la fonction `get_winners`).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;deepseek-r1-distill-llama-70b&quot;</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;2276d42cda9b4cdf896323796721ea…</td><td>3</td><td>0</td></tr><tr><td>&quot;llama-3.1-nemotron-70b-instruc…</td><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>&quot;9e603a6802ec40de94388200a3b3dc…</td><td>0</td><td>-3</td></tr><tr><td>&quot;llama-3.1-8b&quot;</td><td>&quot;llama-3.1-405b&quot;</td><td>&quot;d11b8deefbbf425e82edac13f29fe7…</td><td>2</td><td>1</td></tr><tr><td>&quot;hermes-3-llama-3.1-405b&quot;</td><td>&quot;llama-3.1-70b&quot;</td><td>&quot;c1a5acc9e7a745f1837f0e5d846772…</td><td>-2</td><td>-2</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>&quot;o3-mini&quot;</td><td>&quot;8cdab6f5d8f44d539a2a0f33ad22bf…</td><td>2</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────────┬─────────────────────────┬─────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name             ┆ model_b_name            ┆ conversation_pair_id    ┆ score_a ┆ score_b │\n",
       "│ ---                      ┆ ---                     ┆ ---                     ┆ ---     ┆ ---     │\n",
       "│ str                      ┆ str                     ┆ str                     ┆ i64     ┆ i64     │\n",
       "╞══════════════════════════╪═════════════════════════╪═════════════════════════╪═════════╪═════════╡\n",
       "│ deepseek-r1-distill-llam ┆ claude-3-5-sonnet-v2    ┆ 2276d42cda9b4cdf8963237 ┆ 3       ┆ 0       │\n",
       "│ a-70b                    ┆                         ┆ 96721ea…                ┆         ┆         │\n",
       "│ llama-3.1-nemotron-70b-i ┆ qwen2.5-coder-32b-instr ┆ 9e603a6802ec40de9438820 ┆ 0       ┆ -3      │\n",
       "│ nstruc…                  ┆ uct                     ┆ 0a3b3dc…                ┆         ┆         │\n",
       "│ llama-3.1-8b             ┆ llama-3.1-405b          ┆ d11b8deefbbf425e82edac1 ┆ 2       ┆ 1       │\n",
       "│                          ┆                         ┆ 3f29fe7…                ┆         ┆         │\n",
       "│ hermes-3-llama-3.1-405b  ┆ llama-3.1-70b           ┆ c1a5acc9e7a745f1837f0e5 ┆ -2      ┆ -2      │\n",
       "│                          ┆                         ┆ d846772…                ┆         ┆         │\n",
       "│ gemini-2.0-flash-001     ┆ o3-mini                 ┆ 8cdab6f5d8f44d539a2a0f3 ┆ 2       ┆ 0       │\n",
       "│                          ┆                         ┆ 3ad22bf…                ┆         ┆         │\n",
       "└──────────────────────────┴─────────────────────────┴─────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(reactions)\n",
    "\n",
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule des taux de victoire par modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>matches</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1530</td><td>1080</td><td>70.588235</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>495</td><td>348</td><td>70.30303</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>688</td><td>480</td><td>69.767442</td></tr><tr><td>&quot;gemini-1.5-pro-001&quot;</td><td>328</td><td>222</td><td>67.682927</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1461</td><td>435</td><td>29.774127</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬─────────┬──────┬───────────┐\n",
       "│ model_name                      ┆ matches ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---     ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32     ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪═════════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856     ┆ 647  ┆ 75.584112 │\n",
       "│ deepseek-v3-chat                ┆ 1530    ┆ 1080 ┆ 70.588235 │\n",
       "│ gemma-3-27b                     ┆ 495     ┆ 348  ┆ 70.30303  │\n",
       "│ gemini-2.0-flash-001            ┆ 688     ┆ 480  ┆ 69.767442 │\n",
       "│ gemini-1.5-pro-001              ┆ 328     ┆ 222  ┆ 67.682927 │\n",
       "│ …                               ┆ …       ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585     ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887     ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459    ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1461    ┆ 435  ┆ 29.774127 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499     ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴─────────┴──────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des scores\n",
    "\n",
    "Pour chaque *match* on calcule un score, on mélange les matchs et on les ajoute un par un à un `ELORanker` qui met à jour les scores à chaque ajout de match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 sets de scores sont calculés avec des ordres d'ajout des matchs différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores moyens sont calculés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1149.7600338965026\n",
      "gemma-3-27b : 1145.6220675334805\n",
      "gemini-2.0-flash-001 : 1140.1673630525236\n",
      "deepseek-v3-chat : 1117.7780800034252\n",
      "claude-3-7-sonnet : 1112.231287537241\n",
      "deepseek-v3-0324 : 1109.901416165925\n",
      "command-a : 1101.9762156523593\n",
      "gpt-4.1-mini : 1096.6951244552292\n",
      "gemma-3-12b : 1087.0556016448456\n",
      "llama-3.1-nemotron-70b-instruct : 1076.7824321432136\n",
      "grok-3-mini-beta : 1076.0651567130722\n",
      "deepseek-r1 : 1071.477265680711\n",
      "gemma-3-4b : 1061.133589658061\n",
      "gemini-1.5-pro-002 : 1051.3243868214545\n",
      "llama-4-scout : 1037.8032023669548\n",
      "gemini-1.5-pro-001 : 1037.3937535429066\n",
      "mistral-large-2411 : 1032.3269729226088\n",
      "mistral-small-3.1-24b : 1024.6608968152257\n",
      "claude-3-5-sonnet-v2 : 1006.9001525583038\n",
      "o4-mini : 1005.4739126029199\n",
      "gpt-4o-mini-2024-07-18 : 1004.5908532800541\n",
      "o3-mini : 999.0178481656511\n",
      "gpt-4.1-nano : 996.4487961017362\n",
      "llama-3.3-70b : 993.7061815960126\n",
      "mistral-saba : 993.2464174218336\n",
      "gpt-4o-2024-08-06 : 991.2592904973827\n",
      "mistral-small-24b-instruct-2501 : 983.7346750432073\n",
      "llama-3.1-405b : 983.1241892575563\n",
      "gemma-2-27b-it-q8 : 982.5697992278501\n",
      "jamba-1.5-large : 981.7785195481185\n",
      "phi-4 : 976.5834735356892\n",
      "llama-3.1-70b : 970.4622806641211\n",
      "deepseek-r1-distill-llama-70b : 968.7876497832412\n",
      "gemma-2-9b-it : 965.5445639323675\n",
      "qwq-32b : 961.2260768054676\n",
      "ministral-8b-instruct-2410 : 959.0400072561133\n",
      "aya-expanse-8b : 956.6270988529752\n",
      "hermes-3-llama-3.1-405b : 938.6828231814853\n",
      "llama-3.1-8b : 930.2289890869662\n",
      "c4ai-command-r-08-2024 : 928.5134789933159\n",
      "qwen2.5-coder-32b-instruct : 921.9869282823436\n",
      "qwen2.5-7b-instruct : 897.9127406503286\n",
      "mixtral-8x7b-instruct-v0.1 : 882.7591974018078\n",
      "lfm-40b : 882.0290362369171\n",
      "phi-3.5-mini-instruct : 881.3444347091358\n",
      "mixtral-8x22b-instruct-v0.1 : 855.8716889422294\n",
      "mistral-nemo-2407 : 853.6225675842384\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 816.7714821948966\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux calculs des scores avec des ordres de matchs différents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4.1-mini': 1185.493097751954,\n",
       " 'gemini-2.0-flash-001': 1175.05935674024,\n",
       " 'gemini-2.0-flash-exp': 1141.2356325460535,\n",
       " 'claude-3-7-sonnet': 1138.4313153049895,\n",
       " 'command-a': 1135.805419915371,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1134.3952522668783,\n",
       " 'o3-mini': 1129.406559564824,\n",
       " 'deepseek-v3-0324': 1129.1817238871029,\n",
       " 'gemma-3-27b': 1107.1520354735362,\n",
       " 'grok-3-mini-beta': 1101.3270625304315,\n",
       " 'o4-mini': 1097.5163374943552,\n",
       " 'deepseek-v3-chat': 1095.2648937046413,\n",
       " 'deepseek-r1': 1081.2666860633276,\n",
       " 'gemini-1.5-pro-002': 1071.0964823222112,\n",
       " 'gemma-3-12b': 1063.9251743128825,\n",
       " 'llama-4-scout': 1057.9315061144282,\n",
       " 'mistral-saba': 1055.131850109499,\n",
       " 'gpt-4.1-nano': 1050.640918442269,\n",
       " 'gemini-1.5-pro-001': 1041.3902843440005,\n",
       " 'jamba-1.5-large': 1037.9679337504474,\n",
       " 'claude-3-5-sonnet-v2': 1036.2063287117253,\n",
       " 'mistral-small-3.1-24b': 1016.7154478338211,\n",
       " 'qwq-32b': 1013.1401011343322,\n",
       " 'deepseek-r1-distill-llama-70b': 1001.8564753573025,\n",
       " 'mistral-large-2411': 997.0198868640581,\n",
       " 'gemma-3-4b': 996.5189077030014,\n",
       " 'mistral-small-24b-instruct-2501': 995.4067309462131,\n",
       " 'gpt-4o-mini-2024-07-18': 993.4144690040473,\n",
       " 'llama-3.3-70b': 985.9318069959961,\n",
       " 'ministral-8b-instruct-2410': 973.7185750775419,\n",
       " 'lfm-40b': 968.2417063650649,\n",
       " 'phi-4': 958.8323417906443,\n",
       " 'gpt-4o-2024-08-06': 944.1332223595182,\n",
       " 'llama-3.1-8b': 943.0202162945341,\n",
       " 'llama-3.1-405b': 940.5549880562992,\n",
       " 'qwen2.5-7b-instruct': 939.2073766810079,\n",
       " 'gemma-2-27b-it-q8': 938.3421867759266,\n",
       " 'c4ai-command-r-08-2024': 933.0130910063187,\n",
       " 'hermes-3-llama-3.1-405b': 913.9276942028246,\n",
       " 'aya-expanse-8b': 908.2780229156106,\n",
       " 'gemma-2-9b-it': 890.1296250856146,\n",
       " 'llama-3.1-70b': 864.6205228311283,\n",
       " 'qwen2.5-coder-32b-instruct': 855.3044138967463,\n",
       " 'mixtral-8x7b-instruct-v0.1': 845.2554513382316,\n",
       " 'phi-3.5-mini-instruct': 828.5592919343483,\n",
       " 'mistral-nemo-2407': 781.0411977865821,\n",
       " 'mixtral-8x22b-instruct-v0.1': 777.0209462759412,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 730.9694521361835}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "random.seed(42)\n",
    "matches_shuffle = random.sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claude-3-7-sonnet': 1168.5374763730636,\n",
       " 'command-a': 1156.1491953627,\n",
       " 'gemma-3-27b': 1140.5073274661925,\n",
       " 'gemini-2.0-flash-001': 1117.398502831557,\n",
       " 'gemini-2.0-flash-exp': 1114.0765257436406,\n",
       " 'mistral-small-3.1-24b': 1092.0629598889764,\n",
       " 'gpt-4.1-mini': 1091.9791204062508,\n",
       " 'deepseek-v3-chat': 1091.8955246876528,\n",
       " 'llama-4-scout': 1086.7513518365213,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1081.0139150292869,\n",
       " 'deepseek-v3-0324': 1076.5567744886228,\n",
       " 'o3-mini': 1070.975017608004,\n",
       " 'o4-mini': 1067.035865387678,\n",
       " 'gpt-4o-mini-2024-07-18': 1038.869223948626,\n",
       " 'mistral-saba': 1036.959243234743,\n",
       " 'jamba-1.5-large': 1034.5212155339914,\n",
       " 'qwen2.5-coder-32b-instruct': 1033.83075479585,\n",
       " 'gemma-3-12b': 1023.405510181561,\n",
       " 'ministral-8b-instruct-2410': 1022.8050708721671,\n",
       " 'aya-expanse-8b': 1009.3704770503061,\n",
       " 'deepseek-r1-distill-llama-70b': 1008.0840885023439,\n",
       " 'claude-3-5-sonnet-v2': 1006.2331514651354,\n",
       " 'grok-3-mini-beta': 999.1875817744526,\n",
       " 'llama-3.1-70b': 994.4368529285404,\n",
       " 'gemma-2-9b-it': 990.8341535177742,\n",
       " 'phi-3.5-mini-instruct': 989.8827187246233,\n",
       " 'mistral-small-24b-instruct-2501': 987.4090094129316,\n",
       " 'llama-3.1-405b': 978.9613454059472,\n",
       " 'llama-3.1-8b': 978.570484067352,\n",
       " 'gemini-1.5-pro-001': 977.8860923752926,\n",
       " 'gpt-4o-2024-08-06': 977.0666864509775,\n",
       " 'phi-4': 976.710343485778,\n",
       " 'gemma-3-4b': 971.7933720392263,\n",
       " 'qwq-32b': 967.8337380501207,\n",
       " 'gemma-2-27b-it-q8': 964.3355184743845,\n",
       " 'deepseek-r1': 963.9099083515711,\n",
       " 'hermes-3-llama-3.1-405b': 962.8931663624228,\n",
       " 'c4ai-command-r-08-2024': 959.7901045024302,\n",
       " 'gemini-1.5-pro-002': 945.8001216272452,\n",
       " 'gpt-4.1-nano': 943.9846968284501,\n",
       " 'llama-3.3-70b': 938.4823978035121,\n",
       " 'mixtral-8x7b-instruct-v0.1': 934.93174491995,\n",
       " 'lfm-40b': 925.7421841362226,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 892.2117541570931,\n",
       " 'mistral-large-2411': 861.7281188787784,\n",
       " 'qwen2.5-7b-instruct': 804.9499584053139,\n",
       " 'mistral-nemo-2407': 803.9790917302828,\n",
       " 'mixtral-8x22b-instruct-v0.1': 737.6705628944563}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "random.seed(1337)\n",
    "matches_shuffle = random.sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation d'un Ranker par maximum de vraisemblance\n",
    "\n",
    "Ici on calcule les scores avec un `Ranker` alternatif, défini dans `src/rank_comparia/maximum_likelihood.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': np.float64(1143.1512358130012),\n",
       " 'gemma-3-27b': np.float64(1136.3184203836174),\n",
       " 'gemini-2.0-flash-001': np.float64(1133.400570032988),\n",
       " 'deepseek-v3-chat': np.float64(1114.0328789363393),\n",
       " 'deepseek-v3-0324': np.float64(1113.2067915235539),\n",
       " 'claude-3-7-sonnet': np.float64(1105.1612084450092),\n",
       " 'command-a': np.float64(1101.8786858020478),\n",
       " 'gpt-4.1-mini': np.float64(1093.6685242271394),\n",
       " 'gemma-3-12b': np.float64(1081.4653106195133),\n",
       " 'llama-3.1-nemotron-70b-instruct': np.float64(1078.196872612909),\n",
       " 'grok-3-mini-beta': np.float64(1071.2724072426324),\n",
       " 'deepseek-r1': np.float64(1064.2931624791943),\n",
       " 'gemma-3-4b': np.float64(1055.3168065207053),\n",
       " 'gemini-1.5-pro-002': np.float64(1047.884270532969),\n",
       " 'llama-4-scout': np.float64(1038.2019664020102),\n",
       " 'gemini-1.5-pro-001': np.float64(1037.4923002507746),\n",
       " 'mistral-small-3.1-24b': np.float64(1030.0445144875346),\n",
       " 'mistral-large-2411': np.float64(1028.6925455484807),\n",
       " 'o3-mini': np.float64(1006.2210001085825),\n",
       " 'claude-3-5-sonnet-v2': np.float64(1002.9586930415215),\n",
       " 'o4-mini': np.float64(1002.2210887330519),\n",
       " 'gpt-4o-mini-2024-07-18': np.float64(999.3491370088385),\n",
       " 'mistral-saba': np.float64(996.2399607255587),\n",
       " 'gpt-4o-2024-08-06': np.float64(993.5576631670546),\n",
       " 'llama-3.3-70b': np.float64(990.765165414004),\n",
       " 'llama-3.1-405b': np.float64(990.3338930578011),\n",
       " 'gpt-4.1-nano': np.float64(987.5804923433841),\n",
       " 'jamba-1.5-large': np.float64(985.7386697199976),\n",
       " 'mistral-small-24b-instruct-2501': np.float64(985.034349555171),\n",
       " 'phi-4': np.float64(980.6013968645213),\n",
       " 'gemma-2-27b-it-q8': np.float64(974.6081627145344),\n",
       " 'llama-3.1-70b': np.float64(968.6630865442116),\n",
       " 'gemma-2-9b-it': np.float64(967.0569404993886),\n",
       " 'deepseek-r1-distill-llama-70b': np.float64(961.7384805979112),\n",
       " 'aya-expanse-8b': np.float64(960.6598616976838),\n",
       " 'qwq-32b': np.float64(958.2356609829194),\n",
       " 'ministral-8b-instruct-2410': np.float64(957.8237000706683),\n",
       " 'hermes-3-llama-3.1-405b': np.float64(939.7716775444147),\n",
       " 'c4ai-command-r-08-2024': np.float64(934.8510999183768),\n",
       " 'llama-3.1-8b': np.float64(928.9460566541117),\n",
       " 'qwen2.5-coder-32b-instruct': np.float64(927.4127141222015),\n",
       " 'qwen2.5-7b-instruct': np.float64(912.2611208222494),\n",
       " 'lfm-40b': np.float64(896.5231395095763),\n",
       " 'phi-3.5-mini-instruct': np.float64(889.3352897771736),\n",
       " 'mixtral-8x7b-instruct-v0.1': np.float64(883.6849028582083),\n",
       " 'mixtral-8x22b-instruct-v0.1': np.float64(859.7838306178774),\n",
       " 'mistral-nemo-2407': np.float64(855.2771876657266),\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': np.float64(829.08710580286)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.maximum_likelihood import MaximumLikelihoodRanker\n",
    "\n",
    "ranker = MaximumLikelihoodRanker()\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes `Ranker` ont une méthode `compute_boostrap_scores` qui permettent de calculer des scores et intervalles de confiance bootstrap (les matchs qui servent au calcul des scores pour chaque échantillon bootstrap sont issus de ré-échantillonages avec remise de l'échantillon de matchs initial). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 22993 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:04<00:00, 23.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>rank</th><th>rank_p2.5</th><th>rank_p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1152.000254</td><td>1053.123136</td><td>1262.464787</td><td>1</td><td>1</td><td>16</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1141.022557</td><td>1036.195015</td><td>1236.557939</td><td>2</td><td>1</td><td>18</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1129.024535</td><td>1009.508868</td><td>1232.417883</td><td>3</td><td>1</td><td>23</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>1116.323379</td><td>1000.538134</td><td>1210.532661</td><td>4</td><td>1</td><td>26</td></tr><tr><td>&quot;command-a&quot;</td><td>1114.870281</td><td>1003.453468</td><td>1236.458954</td><td>5</td><td>1</td><td>26</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>882.380214</td><td>771.627778</td><td>998.907549</td><td>44</td><td>26</td><td>48</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>879.390624</td><td>775.675877</td><td>1003.517693</td><td>45</td><td>24</td><td>48</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>861.395916</td><td>771.10219</td><td>958.908885</td><td>46</td><td>31</td><td>48</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>838.852441</td><td>717.000266</td><td>954.458342</td><td>47</td><td>33</td><td>48</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>807.618002</td><td>712.812881</td><td>944.814266</td><td>48</td><td>33</td><td>48</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 7)\n",
       "┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       "│ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       "│ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       "│ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       "╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       "│ gemini-2.0-flash-exp   ┆ 1152.000254 ┆ 1053.123136 ┆ 1262.464787 ┆ 1    ┆ 1         ┆ 16         │\n",
       "│ gemma-3-27b            ┆ 1141.022557 ┆ 1036.195015 ┆ 1236.557939 ┆ 2    ┆ 1         ┆ 18         │\n",
       "│ gemini-2.0-flash-001   ┆ 1129.024535 ┆ 1009.508868 ┆ 1232.417883 ┆ 3    ┆ 1         ┆ 23         │\n",
       "│ deepseek-v3-0324       ┆ 1116.323379 ┆ 1000.538134 ┆ 1210.532661 ┆ 4    ┆ 1         ┆ 26         │\n",
       "│ command-a              ┆ 1114.870281 ┆ 1003.453468 ┆ 1236.458954 ┆ 5    ┆ 1         ┆ 26         │\n",
       "│ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       "│ mixtral-8x7b-instruct- ┆ 882.380214  ┆ 771.627778  ┆ 998.907549  ┆ 44   ┆ 26        ┆ 48         │\n",
       "│ v0.1                   ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       "│ phi-3.5-mini-instruct  ┆ 879.390624  ┆ 775.675877  ┆ 1003.517693 ┆ 45   ┆ 24        ┆ 48         │\n",
       "│ mixtral-8x22b-instruct ┆ 861.395916  ┆ 771.10219   ┆ 958.908885  ┆ 46   ┆ 31        ┆ 48         │\n",
       "│ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       "│ mistral-nemo-2407      ┆ 838.852441  ┆ 717.000266  ┆ 954.458342  ┆ 47   ┆ 33        ┆ 48         │\n",
       "│ chocolatine-2-14b-inst ┆ 807.618002  ┆ 712.812881  ┆ 944.814266  ┆ 48   ┆ 33        ┆ 48         │\n",
       "│ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       "└────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = ELORanker(K=40)\n",
    "\n",
    "ranker.add_players(model_names)  # type: ignore\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 22993 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:06<00:00, 15.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>rank</th><th>rank_p2.5</th><th>rank_p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1144.729114</td><td>1121.742313</td><td>1167.21675</td><td>1</td><td>1</td><td>4</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1133.627056</td><td>1110.422788</td><td>1158.197063</td><td>2</td><td>1</td><td>6</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1132.57884</td><td>1110.02133</td><td>1163.233521</td><td>3</td><td>1</td><td>6</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>1113.265848</td><td>1070.393128</td><td>1144.563903</td><td>4</td><td>1</td><td>11</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1112.383248</td><td>1096.916518</td><td>1128.96423</td><td>5</td><td>2</td><td>8</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>889.187149</td><td>863.661018</td><td>919.916999</td><td>44</td><td>42</td><td>45</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>881.976693</td><td>859.420482</td><td>908.405145</td><td>45</td><td>43</td><td>46</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>859.889721</td><td>844.835259</td><td>873.09579</td><td>46</td><td>45</td><td>48</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>854.536247</td><td>841.993482</td><td>869.60709</td><td>47</td><td>46</td><td>48</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>830.899205</td><td>798.558449</td><td>858.491556</td><td>48</td><td>46</td><td>48</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 7)\n",
       "┌────────────────────────┬─────────────┬─────────────┬─────────────┬──────┬───────────┬────────────┐\n",
       "│ model_name             ┆ median      ┆ p2.5        ┆ p97.5       ┆ rank ┆ rank_p2.5 ┆ rank_p97.5 │\n",
       "│ ---                    ┆ ---         ┆ ---         ┆ ---         ┆ ---  ┆ ---       ┆ ---        │\n",
       "│ str                    ┆ f64         ┆ f64         ┆ f64         ┆ u32  ┆ i64       ┆ i64        │\n",
       "╞════════════════════════╪═════════════╪═════════════╪═════════════╪══════╪═══════════╪════════════╡\n",
       "│ gemini-2.0-flash-exp   ┆ 1144.729114 ┆ 1121.742313 ┆ 1167.21675  ┆ 1    ┆ 1         ┆ 4          │\n",
       "│ gemini-2.0-flash-001   ┆ 1133.627056 ┆ 1110.422788 ┆ 1158.197063 ┆ 2    ┆ 1         ┆ 6          │\n",
       "│ gemma-3-27b            ┆ 1132.57884  ┆ 1110.02133  ┆ 1163.233521 ┆ 3    ┆ 1         ┆ 6          │\n",
       "│ deepseek-v3-0324       ┆ 1113.265848 ┆ 1070.393128 ┆ 1144.563903 ┆ 4    ┆ 1         ┆ 11         │\n",
       "│ deepseek-v3-chat       ┆ 1112.383248 ┆ 1096.916518 ┆ 1128.96423  ┆ 5    ┆ 2         ┆ 8          │\n",
       "│ …                      ┆ …           ┆ …           ┆ …           ┆ …    ┆ …         ┆ …          │\n",
       "│ phi-3.5-mini-instruct  ┆ 889.187149  ┆ 863.661018  ┆ 919.916999  ┆ 44   ┆ 42        ┆ 45         │\n",
       "│ mixtral-8x7b-instruct- ┆ 881.976693  ┆ 859.420482  ┆ 908.405145  ┆ 45   ┆ 43        ┆ 46         │\n",
       "│ v0.1                   ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       "│ mixtral-8x22b-instruct ┆ 859.889721  ┆ 844.835259  ┆ 873.09579   ┆ 46   ┆ 45        ┆ 48         │\n",
       "│ -v0.1                  ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       "│ mistral-nemo-2407      ┆ 854.536247  ┆ 841.993482  ┆ 869.60709   ┆ 47   ┆ 46        ┆ 48         │\n",
       "│ chocolatine-2-14b-inst ┆ 830.899205  ┆ 798.558449  ┆ 858.491556  ┆ 48   ┆ 46        ┆ 48         │\n",
       "│ ruct-v2.…              ┆             ┆             ┆             ┆      ┆           ┆            │\n",
       "└────────────────────────┴─────────────┴─────────────┴─────────────┴──────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = MaximumLikelihoodRanker()\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajout de la notion de frugalité dans le score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.frugality import get_normalized_log_cost, calculate_frugality_score\n",
    "from rank_comparia.plot import plot_elo_against_frugal_elo\n",
    "\n",
    "conversations = load_comparia(\"ministere-culture/comparia-conversations\", token=token)\n",
    "conversations = conversations.rename({\"model_a_name\": \"model_a\", \"model_b_name\": \"model_b\"})\n",
    "\n",
    "frugality_score = calculate_frugality_score(conversations, None)\n",
    "graph = plot_elo_against_frugal_elo(\n",
    "    frugal_log_score=get_normalized_log_cost(frugality_score, mean=\"token\"), bootstraped_scores=scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-bcaa14c51249456b942467d6eea37ea0.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-bcaa14c51249456b942467d6eea37ea0.vega-embed details,\n",
       "  #altair-viz-bcaa14c51249456b942467d6eea37ea0.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-bcaa14c51249456b942467d6eea37ea0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bcaa14c51249456b942467d6eea37ea0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bcaa14c51249456b942467d6eea37ea0\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"legend\": {\"labelLimit\": 300}}, \"data\": {\"name\": \"data-7f059a8b15ed40e22dcdb883052e08ad\"}, \"mark\": {\"type\": \"point\", \"filled\": true}, \"encoding\": {\"color\": {\"field\": \"organization\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"model_name\", \"type\": \"nominal\"}, {\"field\": \"organization\", \"type\": \"nominal\"}, {\"field\": \"license\", \"type\": \"nominal\"}, {\"field\": \"median\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"median\", \"scale\": {\"domainMin\": 800.0, \"domainMax\": 1200.0}, \"title\": \"elo score\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"scale\": {\"domainMin\": 300.0, \"domainMax\": 1200.0}, \"title\": \"frugality elo score\", \"type\": \"quantitative\"}}, \"height\": 450, \"params\": [{\"name\": \"param_1\", \"bind\": {\"input\": \"range\", \"max\": 1, \"min\": 0, \"name\": \"frugality coefficient:  \"}, \"value\": 1}], \"title\": \"frugality elo ranking\", \"transform\": [{\"calculate\": \"(datum.median - (param_1 * (datum.cost * 366)))\", \"as\": \"y\"}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-7f059a8b15ed40e22dcdb883052e08ad\": [{\"model_name\": \"aya-expanse-8b\", \"median\": 961.3315238378282, \"cost\": -0.3022517911358076, \"name\": \"Aya-Expanse-8B\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\"}, {\"model_name\": \"c4ai-command-r-08-2024\", \"median\": 935.5973415090896, \"cost\": 8.881784197001252e-16, \"name\": \"Command R (08-2024)\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\"}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"median\": 830.8992047702302, \"cost\": -0.31873633411705615, \"name\": \"Chocolatine-2-14b Instruct\", \"organization\": \"jpacifico (individual)\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"median\": 1003.3937579374892, \"cost\": 1.2495305418937188, \"name\": \"Claude 3.5 Sonnet V2\", \"organization\": \"Anthropic\", \"license\": \"Proprietary\"}, {\"model_name\": \"command-a\", \"median\": 1101.8879646698401, \"cost\": 0.38226228402165763, \"name\": \"Command A\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\"}, {\"model_name\": \"deepseek-r1\", \"median\": 1063.973069893364, \"cost\": 0.7939890896114425, \"name\": \"DeepSeek-R1\", \"organization\": \"DeepSeek\", \"license\": \"MIT\"}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"median\": 960.5224773537311, \"cost\": 0.21747578810586354, \"name\": \"DeepSeek-R1 distiil\", \"organization\": \"DeepSeek\", \"license\": \"MIT\"}, {\"model_name\": \"deepseek-v3-chat\", \"median\": 1112.3832481945362, \"cost\": 0.7939890896114425, \"name\": \"DeepSeek-V3 Chat\", \"organization\": \"DeepSeek\", \"license\": \"DeepSeek\"}, {\"model_name\": \"gemini-1.5-pro-001\", \"median\": 1038.6027981154557, \"cost\": 1.2466857817034946, \"name\": \"Gemini 1.5 pro 001\", \"organization\": \"Google\", \"license\": \"Proprietary\"}, {\"model_name\": \"gemini-1.5-pro-002\", \"median\": 1048.1660462140144, \"cost\": 1.2490075192751404, \"name\": \"Gemini 1.5 pro 002\", \"organization\": \"Google\", \"license\": \"Proprietary\"}, {\"model_name\": \"gemini-2.0-flash-001\", \"median\": 1133.6270556059862, \"cost\": 0.038561635991759324, \"name\": \"Gemini 2.0 Flash\", \"organization\": \"Google\", \"license\": \"Proprietary\"}, {\"model_name\": \"gemini-2.0-flash-exp\", \"median\": 1144.7291137301058, \"cost\": 0.038561635991759324, \"name\": \"Gemini 2.0 Flash\", \"organization\": \"Google\", \"license\": \"Proprietary\"}, {\"model_name\": \"gemma-2-27b-it-q8\", \"median\": 967.7714986113629, \"cost\": -0.06984816755027978, \"name\": \"Gemma 2 27B q8\", \"organization\": \"Google\", \"license\": \"Gemma license\"}, {\"model_name\": \"gemma-2-9b-it\", \"median\": 967.8226197708026, \"cost\": -0.286745539169897, \"name\": \"Gemma 2 9B\", \"organization\": \"Google\", \"license\": \"Gemma license\"}, {\"model_name\": \"gemma-3-12b\", \"median\": 1079.9228844956692, \"cost\": -0.24193823019243688, \"name\": \"Gemma 3 12B\", \"organization\": \"Google\", \"license\": \"Gemma license\"}, {\"model_name\": \"gemma-3-27b\", \"median\": 1132.5788402262474, \"cost\": -0.06984816755027978, \"name\": \"Gemma-3 27B\", \"organization\": \"Google\", \"license\": \"Gemma\"}, {\"model_name\": \"gemma-3-4b\", \"median\": 1056.5754542677164, \"cost\": -0.3723134986083796, \"name\": \"Gemma 3 4B\", \"organization\": \"Google\", \"license\": \"Gemma license\"}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"median\": 998.9113614490789, \"cost\": -3.565993747489671e-05, \"name\": \"GPT-4o mini\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\"}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"median\": 939.2073661710292, \"cost\": 1.4980954762605334, \"name\": \"Hermes 3\", \"organization\": \"Nous Research\", \"license\": \"llama3\"}, {\"model_name\": \"jamba-1.5-large\", \"median\": 985.6650830029937, \"cost\": 0.7984425037421774, \"name\": \"Jamba Large\", \"organization\": \"AI21 Labs\", \"license\": \"Jamba Open Model License\"}, {\"model_name\": \"lfm-40b\", \"median\": 894.4991178132465, \"cost\": 0.038561635991759324, \"name\": \"Liquid Foundation Model\", \"organization\": \"Liquid\", \"license\": \"Unknown\"}, {\"model_name\": \"llama-3.1-405b\", \"median\": 990.6843923193517, \"cost\": 1.4980954762605325, \"name\": \"Llama 3.1 405B\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\"}, {\"model_name\": \"llama-3.1-70b\", \"median\": 969.349628009368, \"cost\": 0.21747578810586354, \"name\": \"Llama-3.1-70B\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\"}, {\"model_name\": \"llama-3.1-8b\", \"median\": 928.0453942391575, \"cost\": -0.3022517911358076, \"name\": \"Llama 3.1 8B\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\"}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"median\": 1079.5626888213055, \"cost\": 0.21747578810586354, \"name\": \"Nemotron 70B Instruct\", \"organization\": \"Nvidia\", \"license\": \"Llama 3.1 Community\"}, {\"model_name\": \"llama-3.3-70b\", \"median\": 989.3094068040612, \"cost\": 0.21747578810586354, \"name\": \"Llama 3.3 70B\", \"organization\": \"Meta\", \"license\": \"Llama 3.3 Community\"}, {\"model_name\": \"ministral-8b-instruct-2410\", \"median\": 957.6434641056844, \"cost\": -0.3022517911358076, \"name\": \"Ministral 8B-Instruct\", \"organization\": \"Mistral\", \"license\": \"MRL\"}, {\"model_name\": \"mistral-large-2411\", \"median\": 1028.845524203143, \"cost\": 0.42065003209076757, \"name\": \"Mistral-Large-2411\", \"organization\": \"Mistral\", \"license\": \"Mistral Research\"}, {\"model_name\": \"mistral-nemo-2407\", \"median\": 854.5362474637091, \"cost\": -0.24193823019243688, \"name\": \"Mistral Nemo Instruct\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"median\": 987.0104898715072, \"cost\": -0.09923752954196008, \"name\": \"Mistral-Small-24B-Instruct-2501\", \"organization\": \"Mistral\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"mistral-small-3.1-24b\", \"median\": 1030.034852857581, \"cost\": -0.09923752954196008, \"name\": \"Mistral Small-3.1 24B\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"median\": 859.8897211048012, \"cost\": 0.36807215387247894, \"name\": \"Mixtral 8x22B Instruct\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"median\": 881.9766926453476, \"cost\": -0.2147255847840155, \"name\": \"Mixtral 8x7B Instruct\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"o3-mini\", \"median\": 1007.3586721746212, \"cost\": 0.9099986164021123, \"name\": \"o3-mini\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\"}, {\"model_name\": \"phi-3.5-mini-instruct\", \"median\": 889.187149259044, \"cost\": -0.3917493743738376, \"name\": \"Phi-3.5 Mini Instruct\", \"organization\": \"Microsoft\", \"license\": \"MIT\"}, {\"model_name\": \"phi-4\", \"median\": 980.0997427869235, \"cost\": -0.2146569283530111, \"name\": \"Phi 4\", \"organization\": \"Microsoft\", \"license\": \"MIT\"}, {\"model_name\": \"qwen2.5-7b-instruct\", \"median\": 910.9539012183977, \"cost\": -0.31873633411705615, \"name\": \"Qwen2.5-7B\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"median\": 925.3653942620382, \"cost\": -0.024895358976453785, \"name\": \"Qwen2.5-Coder-32B-Instruct\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"qwq-32b\", \"median\": 955.9479999393401, \"cost\": -0.024895358976453785, \"name\": \"QwQ 32B\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
